==================== FedPer ====================                               
Experiment Arguments:                                                          
{
â”‚   'method': 'fedper',
â”‚   'dataset': {
â”‚   â”‚   'name': 'medmnistC',
â”‚   â”‚   'client_num': 100,
â”‚   â”‚   'test_ratio': 0.25,
â”‚   â”‚   'val_ratio': 0.0,
â”‚   â”‚   'seed': 42,
â”‚   â”‚   'split': 'sample',
â”‚   â”‚   'IID_ratio': 0.0,
â”‚   â”‚   'monitor_window_name_suffix': 'medmnistC-100clients-0%IID-Dir(1.0)-seed42',
â”‚   â”‚   'alpha': 1.0,
â”‚   â”‚   'min_samples_per_client': 10
â”‚   },
â”‚   'model': {
â”‚   â”‚   'name': 'lenet5',
â”‚   â”‚   'use_torchvision_pretrained_weights': True,
â”‚   â”‚   'external_model_weights_path': None
â”‚   },
â”‚   'optimizer': {
â”‚   â”‚   'lr': 0.01,
â”‚   â”‚   'dampening': 0,
â”‚   â”‚   'weight_decay': 0,
â”‚   â”‚   'momentum': 0,
â”‚   â”‚   'nesterov': False,
â”‚   â”‚   'name': 'sgd'
â”‚   },
â”‚   'mode': 'serial',
â”‚   'parallel': {
â”‚   â”‚   'ray_cluster_addr': None,
â”‚   â”‚   'num_cpus': None,
â”‚   â”‚   'num_gpus': None,
â”‚   â”‚   'num_workers': 2
â”‚   },
â”‚   'common': {
â”‚   â”‚   'seed': 42,
â”‚   â”‚   'join_ratio': 0.1,
â”‚   â”‚   'global_epoch': 400,
â”‚   â”‚   'local_epoch': 5,
â”‚   â”‚   'batch_size': 32,
â”‚   â”‚   'reset_optimizer_on_global_epoch': True,
â”‚   â”‚   'straggler_ratio': 0,
â”‚   â”‚   'straggler_min_local_epoch': 0,
â”‚   â”‚   'buffers': 'global',
â”‚   â”‚   'client_side_evaluation': True,
â”‚   â”‚   'test': {
â”‚   â”‚   â”‚   'client': {
â”‚   â”‚   â”‚   â”‚   'interval': 100,
â”‚   â”‚   â”‚   â”‚   'finetune_epoch': 0,
â”‚   â”‚   â”‚   â”‚   'train': False,
â”‚   â”‚   â”‚   â”‚   'val': False,
â”‚   â”‚   â”‚   â”‚   'test': True
â”‚   â”‚   â”‚   },
â”‚   â”‚   â”‚   'server': {
â”‚   â”‚   â”‚   â”‚   'interval': -1,
â”‚   â”‚   â”‚   â”‚   'train': False,
â”‚   â”‚   â”‚   â”‚   'val': False,
â”‚   â”‚   â”‚   â”‚   'test': False,
â”‚   â”‚   â”‚   â”‚   'model_in_train_mode': False
â”‚   â”‚   â”‚   }
â”‚   â”‚   },
â”‚   â”‚   'verbose_gap': 10,
â”‚   â”‚   'monitor': None,
â”‚   â”‚   'use_cuda': True,
â”‚   â”‚   'save_log': True,
â”‚   â”‚   'save_model': False,
â”‚   â”‚   'save_learning_curve_plot': False,
â”‚   â”‚   'save_metrics': True,
â”‚   â”‚   'delete_useless_run': True
â”‚   }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 2.0939 -> 2.0332  accuracy: 16.67% -> 16.67%     
client [81] (testset)   loss: 2.0798 -> 1.9897  accuracy: 35.14% -> 35.14%     
client [21] (testset)   loss: 2.3477 -> 1.9560  accuracy: 24.56% -> 26.32%     
client [68] (testset)   loss: 1.9005 -> 1.7862  accuracy: 37.78% -> 37.78%     
client [93] (testset)   loss: 1.7718 -> 1.6993  accuracy: 45.65% -> 45.65%     
client [31] (testset)   loss: 2.2835 -> 1.8591  accuracy: 22.22% -> 44.44%     
client [20] (testset)   loss: 2.1828 -> 2.1678  accuracy: 18.03% -> 18.03%     
client [59] (testset)   loss: 2.4537 -> 2.1270  accuracy: 24.14% -> 24.14%     
client [48] (testset)   loss: 2.3011 -> 2.3377  accuracy: 17.39% -> 8.70%      
client [34] (testset)   loss: 1.9920 -> 1.9389  accuracy: 31.15% -> 24.59%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 2.0903 -> 2.0236  accuracy: 29.41% -> 29.41%     
client [99] (testset)   loss: 2.1305 -> 2.0644  accuracy: 20.51% -> 20.51%     
client [67] (testset)   loss: 2.1217 -> 2.1044  accuracy: 22.81% -> 22.81%     
client [0]  (testset)   loss: 1.7979 -> 1.7057  accuracy: 20.55% -> 36.99%     
client [76] (testset)   loss: 1.9755 -> 1.8615  accuracy: 27.78% -> 27.78%     
client [41] (testset)   loss: 2.0727 -> 2.0281  accuracy: 26.92% -> 26.92%     
client [62] (testset)   loss: 2.4720 -> 1.8516  accuracy: 3.45% -> 41.38%      
client [2]  (testset)   loss: 2.1689 -> 1.7735  accuracy: 49.40% -> 49.40%     
client [14] (testset)   loss: 2.0618 -> 2.0775  accuracy: 31.88% -> 31.88%     
client [46] (testset)   loss: 1.9039 -> 1.8373  accuracy: 48.94% -> 48.94%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 2.2242 -> 2.3252  accuracy: 36.00% -> 20.00%     
client [68] (testset)   loss: 1.7691 -> 1.7820  accuracy: 37.78% -> 37.78%     
client [57] (testset)   loss: 2.0768 -> 2.1042  accuracy: 34.78% -> 34.78%     
client [17] (testset)   loss: 1.9966 -> 1.9848  accuracy: 32.00% -> 32.00%     
client [54] (testset)   loss: 2.4150 -> 2.5212  accuracy: 18.75% -> 18.75%     
client [23] (testset)   loss: 2.3719 -> 2.0820  accuracy: 20.59% -> 20.59%     
client [35] (testset)   loss: 2.0187 -> 1.9602  accuracy: 33.33% -> 33.33%     
client [59] (testset)   loss: 2.1150 -> 2.0982  accuracy: 24.14% -> 24.14%     
client [31] (testset)   loss: 1.8936 -> 1.8273  accuracy: 44.44% -> 44.44%     
client [9]  (testset)   loss: 2.2878 -> 2.3573  accuracy: 13.33% -> 13.33%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 2.1795 -> 2.1783  accuracy: 20.00% -> 20.00%     
client [33] (testset)   loss: 1.7968 -> 1.8642  accuracy: 22.22% -> 22.22%     
client [16] (testset)   loss: 2.0536 -> 2.0178  accuracy: 26.67% -> 26.67%     
client [44] (testset)   loss: 2.1916 -> 2.1458  accuracy: 12.50% -> 23.21%     
client [8]  (testset)   loss: 1.9113 -> 1.9628  accuracy: 34.17% -> 34.17%     
client [31] (testset)   loss: 1.8405 -> 1.9430  accuracy: 44.44% -> 44.44%     
client [47] (testset)   loss: 1.8060 -> 1.7043  accuracy: 16.67% -> 47.22%     
client [36] (testset)   loss: 2.2322 -> 2.0600  accuracy: 4.08% -> 24.49%      
client [20] (testset)   loss: 2.1764 -> 2.1732  accuracy: 18.03% -> 18.03%     
client [56] (testset)   loss: 2.2337 -> 2.1922  accuracy: 7.27% -> 7.27%       
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 2.0408 -> 2.0427  accuracy: 30.19% -> 18.87%     
client [60] (testset)   loss: 2.2437 -> 2.2125  accuracy: 28.57% -> 28.57%     
client [28] (testset)   loss: 2.1948 -> 2.1864  accuracy: 12.33% -> 12.33%     
client [25] (testset)   loss: 2.3737 -> 2.4550  accuracy: 12.00% -> 12.00%     
client [58] (testset)   loss: 1.6910 -> 1.6912  accuracy: 42.47% -> 42.47%     
client [44] (testset)   loss: 2.1363 -> 2.1659  accuracy: 12.50% -> 23.21%     
client [39] (testset)   loss: 1.4386 -> 1.4077  accuracy: 53.77% -> 53.77%     
client [29] (testset)   loss: 1.7852 -> 1.7799  accuracy: 37.66% -> 37.66%     
client [3]  (testset)   loss: 2.4016 -> 2.6313  accuracy: 9.26% -> 9.26%       
client [84] (testset)   loss: 1.6420 -> 1.6732  accuracy: 38.53% -> 38.53%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 1.9989 -> 1.9720  accuracy: 24.56% -> 26.32%     
client [84] (testset)   loss: 1.6936 -> 1.6776  accuracy: 38.53% -> 38.53%     
client [10] (testset)   loss: 2.1593 -> 2.0816  accuracy: 38.89% -> 38.89%     
client [36] (testset)   loss: 2.0628 -> 2.0772  accuracy: 24.49% -> 24.49%     
client [65] (testset)   loss: 1.9842 -> 2.0760  accuracy: 37.74% -> 13.21%     
client [81] (testset)   loss: 2.0027 -> 1.9978  accuracy: 35.14% -> 35.14%     
client [79] (testset)   loss: 2.2375 -> 2.2556  accuracy: 21.15% -> 21.15%     
client [42] (testset)   loss: 2.2852 -> 2.2504  accuracy: 7.14% -> 7.14%       
client [11] (testset)   loss: 1.9724 -> 1.9747  accuracy: 30.36% -> 21.43%     
client [96] (testset)   loss: 2.0894 -> 2.0981  accuracy: 30.36% -> 30.36%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 1.9004 -> 1.9187  accuracy: 34.17% -> 34.17%     
client [53] (testset)   loss: 2.0733 -> 2.0849  accuracy: 38.71% -> 38.71%     
client [52] (testset)   loss: 1.3386 -> 1.3026  accuracy: 57.14% -> 57.14%     
client [42] (testset)   loss: 2.2384 -> 2.2684  accuracy: 17.86% -> 8.93%      
client [69] (testset)   loss: 2.0311 -> 2.0164  accuracy: 29.41% -> 29.41%     
client [59] (testset)   loss: 2.1061 -> 2.1353  accuracy: 24.14% -> 24.14%     
client [7]  (testset)   loss: 1.9468 -> 1.9281  accuracy: 32.79% -> 32.79%     
client [26] (testset)   loss: 2.1792 -> 2.1719  accuracy: 22.81% -> 22.81%     
client [49] (testset)   loss: 1.9606 -> 1.9206  accuracy: 15.15% -> 24.24%     
client [98] (testset)   loss: 2.0509 -> 2.0566  accuracy: 37.74% -> 37.74%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 2.0483 -> 2.0574  accuracy: 37.74% -> 37.74%     
client [47] (testset)   loss: 1.7904 -> 1.7162  accuracy: 16.67% -> 47.22%     
client [21] (testset)   loss: 1.9822 -> 1.9512  accuracy: 26.32% -> 26.32%     
client [77] (testset)   loss: 1.9953 -> 1.9791  accuracy: 30.00% -> 30.00%     
client [95] (testset)   loss: 1.9896 -> 2.0215  accuracy: 34.25% -> 34.25%     
client [91] (testset)   loss: 1.9960 -> 2.0096  accuracy: 37.93% -> 37.93%     
client [14] (testset)   loss: 2.0447 -> 2.0439  accuracy: 31.88% -> 31.88%     
client [99] (testset)   loss: 2.0717 -> 2.0722  accuracy: 20.51% -> 12.82%     
client [20] (testset)   loss: 2.1760 -> 2.1923  accuracy: 18.03% -> 18.03%     
client [39] (testset)   loss: 1.4448 -> 1.4005  accuracy: 53.77% -> 53.77%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 1.3740 -> 1.2976  accuracy: 57.14% -> 57.14%     
client [62] (testset)   loss: 1.8854 -> 1.8645  accuracy: 41.38% -> 41.38%     
client [71] (testset)   loss: 2.0231 -> 2.0761  accuracy: 23.33% -> 23.33%     
client [97] (testset)   loss: 1.8563 -> 1.8619  accuracy: 25.76% -> 31.82%     
client [30] (testset)   loss: 2.3591 -> 2.3540  accuracy: 15.15% -> 15.15%     
client [88] (testset)   loss: 2.1703 -> 2.1711  accuracy: 22.81% -> 22.81%     
client [60] (testset)   loss: 2.2027 -> 2.1967  accuracy: 28.57% -> 28.57%     
client [82] (testset)   loss: 1.9330 -> 1.9379  accuracy: 11.94% -> 11.94%     
client [91] (testset)   loss: 2.0016 -> 2.0315  accuracy: 37.93% -> 13.79%     
client [57] (testset)   loss: 2.0699 -> 2.1084  accuracy: 34.78% -> 34.78%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 1.8376 -> 1.8823  accuracy: 44.44% -> 44.44%     
client [15] (testset)   loss: 1.5443 -> 1.4679  accuracy: 61.04% -> 61.04%     
client [71] (testset)   loss: 2.0392 -> 2.0417  accuracy: 23.33% -> 23.33%     
client [97] (testset)   loss: 1.8526 -> 1.9691  accuracy: 25.76% -> 25.76%     
client [53] (testset)   loss: 2.0711 -> 2.0933  accuracy: 38.71% -> 38.71%     
client [77] (testset)   loss: 1.9814 -> 1.9821  accuracy: 30.00% -> 30.00%     
client [76] (testset)   loss: 1.9246 -> 1.8918  accuracy: 27.78% -> 27.78%     
client [79] (testset)   loss: 2.2709 -> 2.2931  accuracy: 21.15% -> 21.15%     
client [28] (testset)   loss: 2.2089 -> 2.1884  accuracy: 12.33% -> 12.33%     
client [99] (testset)   loss: 2.0675 -> 2.0782  accuracy: 20.51% -> 10.26%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 1.8489 -> 1.8964  accuracy: 31.82% -> 25.76%     
client [86] (testset)   loss: 1.7018 -> 1.7436  accuracy: 48.44% -> 48.44%     
client [34] (testset)   loss: 1.9157 -> 1.9029  accuracy: 24.59% -> 31.15%     
client [73] (testset)   loss: 2.3447 -> 2.3345  accuracy: 12.28% -> 12.28%     
client [5]  (testset)   loss: 2.1920 -> 2.1883  accuracy: 26.09% -> 26.09%     
client [96] (testset)   loss: 2.0854 -> 2.1000  accuracy: 30.36% -> 30.36%     
client [22] (testset)   loss: 1.8846 -> 1.8500  accuracy: 46.00% -> 46.00%     
client [60] (testset)   loss: 2.1919 -> 2.1740  accuracy: 28.57% -> 28.57%     
client [66] (testset)   loss: 2.1749 -> 2.1768  accuracy: 19.05% -> 19.05%     
client [83] (testset)   loss: 2.1204 -> 2.1350  accuracy: 19.57% -> 19.57%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 1.9038 -> 1.9044  accuracy: 27.78% -> 27.78%     
client [65] (testset)   loss: 1.9999 -> 2.0592  accuracy: 37.74% -> 37.74%     
client [95] (testset)   loss: 1.9972 -> 2.0015  accuracy: 34.25% -> 34.25%     
client [17] (testset)   loss: 1.9801 -> 2.0133  accuracy: 32.00% -> 32.00%     
client [8]  (testset)   loss: 1.8783 -> 1.8907  accuracy: 34.17% -> 34.17%     
client [35] (testset)   loss: 2.0034 -> 1.9818  accuracy: 33.33% -> 33.33%     
client [98] (testset)   loss: 2.0505 -> 2.0533  accuracy: 37.74% -> 37.74%     
client [53] (testset)   loss: 2.0841 -> 2.1021  accuracy: 38.71% -> 38.71%     
client [43] (testset)   loss: 1.5067 -> 1.4980  accuracy: 57.89% -> 57.89%     
client [64] (testset)   loss: 2.1871 -> 2.1931  accuracy: 20.00% -> 20.00%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 1.9634 -> 2.0238  accuracy: 26.32% -> 26.32%     
client [88] (testset)   loss: 2.1738 -> 2.1648  accuracy: 15.79% -> 22.81%     
client [38] (testset)   loss: 2.1933 -> 2.1935  accuracy: 18.92% -> 18.92%     
client [3]  (testset)   loss: 2.4866 -> 2.5097  accuracy: 9.26% -> 9.26%       
client [5]  (testset)   loss: 2.1660 -> 2.1667  accuracy: 26.09% -> 26.09%     
client [41] (testset)   loss: 2.0105 -> 2.0142  accuracy: 26.92% -> 26.92%     
client [7]  (testset)   loss: 1.9430 -> 1.9377  accuracy: 32.79% -> 32.79%     
client [37] (testset)   loss: 1.9299 -> 1.9445  accuracy: 40.48% -> 40.48%     
client [45] (testset)   loss: 2.0434 -> 2.0679  accuracy: 34.78% -> 34.78%     
client [47] (testset)   loss: 1.7889 -> 1.6923  accuracy: 16.67% -> 47.22%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 2.0335 -> 2.0390  accuracy: 26.67% -> 26.67%     
client [11] (testset)   loss: 1.9793 -> 1.9936  accuracy: 30.36% -> 30.36%     
client [37] (testset)   loss: 1.9402 -> 1.9597  accuracy: 40.48% -> 40.48%     
client [41] (testset)   loss: 2.0135 -> 2.0154  accuracy: 26.92% -> 26.92%     
client [95] (testset)   loss: 2.0192 -> 2.0124  accuracy: 34.25% -> 34.25%     
client [53] (testset)   loss: 2.0959 -> 2.0968  accuracy: 38.71% -> 38.71%     
client [22] (testset)   loss: 1.8572 -> 1.8563  accuracy: 46.00% -> 46.00%     
client [25] (testset)   loss: 2.4473 -> 2.4758  accuracy: 12.00% -> 12.00%     
client [69] (testset)   loss: 2.0171 -> 2.0287  accuracy: 29.41% -> 29.41%     
client [46] (testset)   loss: 1.8288 -> 1.8417  accuracy: 48.94% -> 48.94%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 1.7172 -> 1.7363  accuracy: 47.22% -> 16.67%     
client [69] (testset)   loss: 2.0214 -> 2.0199  accuracy: 29.41% -> 29.41%     
client [82] (testset)   loss: 1.9482 -> 1.8925  accuracy: 11.94% -> 40.30%     
client [45] (testset)   loss: 2.0366 -> 2.0627  accuracy: 34.78% -> 34.78%     
client [7]  (testset)   loss: 1.9374 -> 1.9395  accuracy: 32.79% -> 32.79%     
client [50] (testset)   loss: 2.1338 -> 2.0809  accuracy: 29.87% -> 29.87%     
client [35] (testset)   loss: 1.9904 -> 1.9930  accuracy: 33.33% -> 33.33%     
client [24] (testset)   loss: 2.2101 -> 2.2033  accuracy: 36.00% -> 36.00%     
client [15] (testset)   loss: 1.5042 -> 1.4904  accuracy: 61.04% -> 61.04%     
client [58] (testset)   loss: 1.6766 -> 1.6748  accuracy: 42.47% -> 42.47%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 2.2836 -> 2.2886  accuracy: 17.39% -> 17.39%     
client [76] (testset)   loss: 1.8973 -> 1.9093  accuracy: 27.78% -> 27.78%     
client [67] (testset)   loss: 2.0748 -> 2.0662  accuracy: 17.54% -> 17.54%     
client [37] (testset)   loss: 1.9382 -> 1.9379  accuracy: 40.48% -> 40.48%     
client [58] (testset)   loss: 1.6768 -> 1.6774  accuracy: 42.47% -> 42.47%     
client [64] (testset)   loss: 2.1862 -> 2.1823  accuracy: 20.00% -> 20.00%     
client [77] (testset)   loss: 1.9860 -> 1.9759  accuracy: 30.00% -> 30.00%     
client [55] (testset)   loss: 1.8953 -> 1.8973  accuracy: 42.62% -> 42.62%     
client [12] (testset)   loss: 1.8991 -> 1.8888  accuracy: 22.03% -> 23.73%     
client [89] (testset)   loss: 1.8749 -> 1.8698  accuracy: 46.88% -> 46.88%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 1.6370 -> 1.6324  accuracy: 38.53% -> 38.53%     
client [51] (testset)   loss: 1.7946 -> 1.8043  accuracy: 47.42% -> 47.42%     
client [8]  (testset)   loss: 1.8971 -> 1.8728  accuracy: 34.17% -> 34.17%     
client [18] (testset)   loss: 2.3236 -> 2.3598  accuracy: 6.98% -> 20.93%      
client [94] (testset)   loss: 1.7916 -> 1.7750  accuracy: 31.71% -> 31.71%     
client [81] (testset)   loss: 2.0053 -> 2.0090  accuracy: 35.14% -> 35.14%     
client [3]  (testset)   loss: 2.4711 -> 2.3903  accuracy: 9.26% -> 9.26%       
client [11] (testset)   loss: 1.9779 -> 1.9820  accuracy: 30.36% -> 30.36%     
client [95] (testset)   loss: 2.0205 -> 2.0184  accuracy: 34.25% -> 34.25%     
client [67] (testset)   loss: 2.0763 -> 2.0774  accuracy: 17.54% -> 19.30%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 1.9598 -> 1.9585  accuracy: 26.32% -> 26.32%     
client [79] (testset)   loss: 2.2760 -> 2.2885  accuracy: 21.15% -> 21.15%     
client [58] (testset)   loss: 1.6787 -> 1.6773  accuracy: 42.47% -> 42.47%     
client [88] (testset)   loss: 2.1601 -> 2.1898  accuracy: 22.81% -> 22.81%     
client [46] (testset)   loss: 1.8361 -> 1.8360  accuracy: 48.94% -> 48.94%     
client [11] (testset)   loss: 1.9844 -> 1.9874  accuracy: 30.36% -> 30.36%     
client [55] (testset)   loss: 1.9009 -> 1.9060  accuracy: 42.62% -> 42.62%     
client [13] (testset)   loss: 2.4658 -> 2.4899  accuracy: 22.22% -> 22.22%     
client [31] (testset)   loss: 1.8646 -> 1.8694  accuracy: 44.44% -> 44.44%     
client [75] (testset)   loss: 2.1693 -> 2.1648  accuracy: 24.07% -> 22.22%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 2.1721 -> 2.1802  accuracy: 23.21% -> 23.21%     
client [7]  (testset)   loss: 1.9358 -> 1.9313  accuracy: 32.79% -> 32.79%     
client [57] (testset)   loss: 2.0858 -> 2.1116  accuracy: 34.78% -> 34.78%     
client [13] (testset)   loss: 2.4683 -> 2.4694  accuracy: 22.22% -> 22.22%     
client [43] (testset)   loss: 1.4876 -> 1.4932  accuracy: 57.89% -> 57.89%     
client [91] (testset)   loss: 1.9987 -> 2.0441  accuracy: 37.93% -> 13.79%     
client [10] (testset)   loss: 2.0976 -> 2.0940  accuracy: 38.89% -> 38.89%     
client [64] (testset)   loss: 2.1875 -> 2.1922  accuracy: 20.00% -> 20.00%     
client [82] (testset)   loss: 1.8882 -> 1.9059  accuracy: 40.30% -> 11.94%     
client [22] (testset)   loss: 1.8757 -> 1.8558  accuracy: 46.00% -> 46.00%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 2.1937 -> 2.1879  accuracy: 18.03% -> 18.03%     
client [23] (testset)   loss: 2.1505 -> 2.1495  accuracy: 20.59% -> 23.53%     
client [88] (testset)   loss: 2.1817 -> 2.1532  accuracy: 22.81% -> 15.79%     
client [98] (testset)   loss: 2.0554 -> 2.0555  accuracy: 37.74% -> 37.74%     
client [79] (testset)   loss: 2.2908 -> 2.2797  accuracy: 21.15% -> 21.15%     
client [21] (testset)   loss: 1.9698 -> 1.9528  accuracy: 26.32% -> 26.32%     
client [92] (testset)   loss: 2.1092 -> 2.1018  accuracy: 26.47% -> 26.47%     
client [56] (testset)   loss: 2.1049 -> 2.1667  accuracy: 7.27% -> 7.27%       
client [5]  (testset)   loss: 2.1972 -> 2.2391  accuracy: 26.09% -> 26.09%     
client [52] (testset)   loss: 1.3046 -> 1.2668  accuracy: 57.14% -> 57.14%     
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 2.0632 -> 2.0747  accuracy: 19.30% -> 19.30%     
client [54] (testset)   loss: 2.4458 -> 2.9173  accuracy: 18.75% -> 18.75%     
client [14] (testset)   loss: 2.0483 -> 2.0545  accuracy: 31.88% -> 31.88%     
client [99] (testset)   loss: 2.0808 -> 2.0687  accuracy: 10.26% -> 10.26%     
client [36] (testset)   loss: 2.0441 -> 2.0516  accuracy: 24.49% -> 24.49%     
client [30] (testset)   loss: 2.3621 -> 2.3618  accuracy: 15.15% -> 15.15%     
client [38] (testset)   loss: 2.1837 -> 2.1930  accuracy: 18.92% -> 18.92%     
client [15] (testset)   loss: 1.5365 -> 1.5149  accuracy: 61.04% -> 61.04%     
client [6]  (testset)   loss: 2.0296 -> 2.0413  accuracy: 21.54% -> 21.54%     
client [53] (testset)   loss: 2.0751 -> 2.0838  accuracy: 38.71% -> 38.71%     
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [99] (testset)   loss: 2.0687 -> 2.0798  accuracy: 20.51% -> 10.26%     
client [6]  (testset)   loss: 2.0351 -> 2.0267  accuracy: 21.54% -> 21.54%     
client [83] (testset)   loss: 2.1410 -> 2.1296  accuracy: 19.57% -> 19.57%     
client [42] (testset)   loss: 2.2872 -> 2.3019  accuracy: 17.86% -> 17.86%     
client [34] (testset)   loss: 1.9102 -> 1.9055  accuracy: 24.59% -> 24.59%     
client [15] (testset)   loss: 1.5238 -> 1.5071  accuracy: 61.04% -> 61.04%     
client [47] (testset)   loss: 1.7155 -> 1.7091  accuracy: 47.22% -> 47.22%     
client [55] (testset)   loss: 1.8993 -> 1.9017  accuracy: 42.62% -> 42.62%     
client [51] (testset)   loss: 1.7948 -> 1.8080  accuracy: 47.42% -> 47.42%     
client [95] (testset)   loss: 2.0116 -> 2.0030  accuracy: 34.25% -> 34.25%     
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 2.0190 -> 2.0098  accuracy: 23.33% -> 23.33%     
client [15] (testset)   loss: 1.5342 -> 1.4790  accuracy: 61.04% -> 61.04%     
client [33] (testset)   loss: 1.7733 -> 1.8204  accuracy: 44.44% -> 22.22%     
client [99] (testset)   loss: 2.0703 -> 2.0799  accuracy: 20.51% -> 10.26%     
client [90] (testset)   loss: 1.9791 -> 1.9741  accuracy: 25.00% -> 25.00%     
client [57] (testset)   loss: 2.0921 -> 2.0803  accuracy: 34.78% -> 34.78%     
client [27] (testset)   loss: 1.9751 -> 1.9919  accuracy: 38.75% -> 38.75%     
client [78] (testset)   loss: 1.9051 -> 1.9231  accuracy: 22.73% -> 22.73%     
client [36] (testset)   loss: 2.0579 -> 2.0547  accuracy: 24.49% -> 24.49%     
client [88] (testset)   loss: 2.1621 -> 2.1925  accuracy: 22.81% -> 15.79%     
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 2.2640 -> 2.2223  accuracy: 25.00% -> 25.00%     
client [35] (testset)   loss: 2.0139 -> 2.0136  accuracy: 33.33% -> 33.33%     
client [16] (testset)   loss: 2.0262 -> 2.0249  accuracy: 26.67% -> 26.67%     
client [80] (testset)   loss: 2.1672 -> 2.1861  accuracy: 38.18% -> 38.18%     
client [38] (testset)   loss: 2.1892 -> 2.1947  accuracy: 18.92% -> 18.92%     
client [78] (testset)   loss: 1.9103 -> 1.9223  accuracy: 22.73% -> 22.73%     
client [68] (testset)   loss: 1.7465 -> 1.7561  accuracy: 37.78% -> 37.78%     
client [11] (testset)   loss: 1.9974 -> 2.0056  accuracy: 30.36% -> 30.36%     
client [64] (testset)   loss: 2.1945 -> 2.1928  accuracy: 20.00% -> 20.00%     
client [82] (testset)   loss: 1.9095 -> 1.8907  accuracy: 40.30% -> 40.30%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 2.3507 -> 2.3438  accuracy: 15.15% -> 15.15%     
client [27] (testset)   loss: 1.9734 -> 1.9817  accuracy: 38.75% -> 38.75%     
client [74] (testset)   loss: 1.9942 -> 2.0082  accuracy: 28.07% -> 19.30%     
client [45] (testset)   loss: 2.0365 -> 2.0452  accuracy: 34.78% -> 34.78%     
client [6]  (testset)   loss: 2.0560 -> 2.0558  accuracy: 21.54% -> 21.54%     
client [36] (testset)   loss: 2.0602 -> 2.0585  accuracy: 24.49% -> 24.49%     
client [63] (testset)   loss: 1.9778 -> 1.9863  accuracy: 31.67% -> 31.67%     
client [76] (testset)   loss: 1.9002 -> 1.8775  accuracy: 27.78% -> 27.78%     
client [83] (testset)   loss: 2.1487 -> 2.1314  accuracy: 19.57% -> 19.57%     
client [86] (testset)   loss: 1.6967 -> 1.6955  accuracy: 48.44% -> 48.44%     
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 2.1409 -> 2.1299  accuracy: 19.57% -> 19.57%     
client [99] (testset)   loss: 2.0737 -> 2.0732  accuracy: 20.51% -> 10.26%     
client [74] (testset)   loss: 1.9956 -> 1.9992  accuracy: 28.07% -> 19.30%     
client [73] (testset)   loss: 2.3507 -> 2.3343  accuracy: 12.28% -> 21.05%     
client [29] (testset)   loss: 1.7819 -> 1.7604  accuracy: 37.66% -> 37.66%     
client [92] (testset)   loss: 2.1040 -> 2.1105  accuracy: 26.47% -> 26.47%     
client [6]  (testset)   loss: 2.0160 -> 2.0177  accuracy: 21.54% -> 21.54%     
client [61] (testset)   loss: 2.2134 -> 2.2673  accuracy: 26.67% -> 26.67%     
client [21] (testset)   loss: 1.9538 -> 1.9620  accuracy: 26.32% -> 26.32%     
client [67] (testset)   loss: 2.0734 -> 2.0845  accuracy: 19.30% -> 17.54%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 2.1348 -> 2.1176  accuracy: 19.57% -> 19.57%     
client [32] (testset)   loss: 1.9870 -> 1.9922  accuracy: 30.43% -> 30.43%     
client [95] (testset)   loss: 2.0014 -> 2.0060  accuracy: 34.25% -> 34.25%     
client [61] (testset)   loss: 2.2297 -> 2.2106  accuracy: 26.67% -> 26.67%     
client [27] (testset)   loss: 1.9782 -> 2.0136  accuracy: 38.75% -> 38.75%     
client [25] (testset)   loss: 2.4549 -> 2.4626  accuracy: 12.00% -> 12.00%     
client [68] (testset)   loss: 1.7590 -> 1.7542  accuracy: 37.78% -> 37.78%     
client [34] (testset)   loss: 1.9114 -> 1.9104  accuracy: 24.59% -> 24.59%     
client [71] (testset)   loss: 2.0145 -> 2.0293  accuracy: 23.33% -> 23.33%     
client [89] (testset)   loss: 1.8578 -> 1.9669  accuracy: 46.88% -> 46.88%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 1.9129 -> 1.9196  accuracy: 22.73% -> 22.73%     
client [81] (testset)   loss: 2.0108 -> 2.0151  accuracy: 35.14% -> 35.14%     
client [51] (testset)   loss: 1.7789 -> 1.7980  accuracy: 47.42% -> 47.42%     
client [54] (testset)   loss: 2.4616 -> 2.3423  accuracy: 18.75% -> 18.75%     
client [65] (testset)   loss: 2.0170 -> 2.0010  accuracy: 37.74% -> 37.74%     
client [41] (testset)   loss: 2.0187 -> 2.0180  accuracy: 26.92% -> 26.92%     
client [11] (testset)   loss: 1.9812 -> 1.9898  accuracy: 30.36% -> 30.36%     
client [85] (testset)   loss: 2.0636 -> 2.0535  accuracy: 29.33% -> 29.33%     
client [12] (testset)   loss: 1.8817 -> 1.9019  accuracy: 23.73% -> 23.73%     
client [23] (testset)   loss: 2.1724 -> 2.1854  accuracy: 20.59% -> 20.59%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 2.0328 -> 2.0331  accuracy: 26.67% -> 26.67%     
client [65] (testset)   loss: 2.0055 -> 1.9909  accuracy: 37.74% -> 37.74%     
client [53] (testset)   loss: 2.0917 -> 2.0936  accuracy: 38.71% -> 38.71%     
client [58] (testset)   loss: 1.6752 -> 1.6821  accuracy: 42.47% -> 42.47%     
client [72] (testset)   loss: 1.7825 -> 1.7839  accuracy: 53.70% -> 53.70%     
client [7]  (testset)   loss: 1.9334 -> 1.9340  accuracy: 32.79% -> 32.79%     
client [71] (testset)   loss: 2.0198 -> 2.0238  accuracy: 23.33% -> 23.33%     
client [59] (testset)   loss: 2.0991 -> 2.1101  accuracy: 24.14% -> 24.14%     
client [86] (testset)   loss: 1.6941 -> 1.6934  accuracy: 48.44% -> 48.44%     
client [39] (testset)   loss: 1.4119 -> 1.4078  accuracy: 53.77% -> 53.77%     
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 2.0725 -> 2.0761  accuracy: 20.51% -> 10.26%     
client [7]  (testset)   loss: 1.9314 -> 1.9318  accuracy: 32.79% -> 32.79%     
client [17] (testset)   loss: 1.9995 -> 1.9946  accuracy: 32.00% -> 32.00%     
client [64] (testset)   loss: 2.1919 -> 2.1868  accuracy: 20.00% -> 20.00%     
client [37] (testset)   loss: 1.9427 -> 1.9494  accuracy: 40.48% -> 40.48%     
client [29] (testset)   loss: 1.7719 -> 1.7790  accuracy: 37.66% -> 37.66%     
client [93] (testset)   loss: 1.7001 -> 1.7020  accuracy: 45.65% -> 45.65%     
client [73] (testset)   loss: 2.3423 -> 2.3343  accuracy: 12.28% -> 12.28%     
client [40] (testset)   loss: 2.1604 -> 2.1475  accuracy: 21.74% -> 21.74%     
client [76] (testset)   loss: 1.8907 -> 1.8807  accuracy: 27.78% -> 27.78%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 1.8701 -> 1.8632  accuracy: 44.44% -> 44.44%     
client [89] (testset)   loss: 1.8611 -> 1.8463  accuracy: 46.88% -> 46.88%     
client [77] (testset)   loss: 1.9836 -> 1.9782  accuracy: 30.00% -> 30.00%     
client [90] (testset)   loss: 1.9845 -> 1.9808  accuracy: 25.00% -> 25.00%     
client [26] (testset)   loss: 2.1791 -> 2.1815  accuracy: 22.81% -> 22.81%     
client [50] (testset)   loss: 2.1198 -> 2.0941  accuracy: 29.87% -> 29.87%     
client [30] (testset)   loss: 2.3629 -> 2.3515  accuracy: 15.15% -> 15.15%     
client [70] (testset)   loss: 2.2779 -> 2.2194  accuracy: 25.00% -> 25.00%     
client [41] (testset)   loss: 2.0195 -> 2.0207  accuracy: 26.92% -> 26.92%     
client [99] (testset)   loss: 2.0779 -> 2.0633  accuracy: 10.26% -> 20.51%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [68] (testset)   loss: 1.7564 -> 1.7600  accuracy: 37.78% -> 37.78%     
client [70] (testset)   loss: 2.2977 -> 2.2762  accuracy: 25.00% -> 25.00%     
client [52] (testset)   loss: 1.2962 -> 1.3410  accuracy: 57.14% -> 57.14%     
client [1]  (testset)   loss: 2.4201 -> 2.3918  accuracy: 4.17% -> 12.50%      
client [2]  (testset)   loss: 1.7836 -> 1.7743  accuracy: 49.40% -> 49.40%     
client [67] (testset)   loss: 2.0811 -> 2.0890  accuracy: 19.30% -> 19.30%     
client [92] (testset)   loss: 2.1053 -> 2.1079  accuracy: 26.47% -> 26.47%     
client [35] (testset)   loss: 1.9984 -> 2.0042  accuracy: 33.33% -> 33.33%     
client [36] (testset)   loss: 2.0557 -> 2.0573  accuracy: 24.49% -> 24.49%     
client [64] (testset)   loss: 2.1903 -> 2.1862  accuracy: 20.00% -> 20.00%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 2.1253 -> 2.1192  accuracy: 23.21% -> 23.21%     
client [6]  (testset)   loss: 2.0300 -> 2.0083  accuracy: 21.54% -> 21.54%     
client [12] (testset)   loss: 1.8957 -> 1.8804  accuracy: 22.03% -> 22.03%     
client [55] (testset)   loss: 1.9018 -> 1.9029  accuracy: 42.62% -> 42.62%     
client [29] (testset)   loss: 1.7683 -> 1.8061  accuracy: 37.66% -> 37.66%     
client [9]  (testset)   loss: 2.3551 -> 2.3644  accuracy: 13.33% -> 13.33%     
client [43] (testset)   loss: 1.4881 -> 1.4973  accuracy: 57.89% -> 57.89%     
client [77] (testset)   loss: 1.9828 -> 1.9801  accuracy: 30.00% -> 30.00%     
client [98] (testset)   loss: 2.0571 -> 2.0561  accuracy: 37.74% -> 37.74%     
client [78] (testset)   loss: 1.9194 -> 1.9266  accuracy: 22.73% -> 22.73%     
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 2.1099 -> 2.1040  accuracy: 26.47% -> 26.47%     
client [80] (testset)   loss: 2.1594 -> 2.1558  accuracy: 38.18% -> 38.18%     
client [63] (testset)   loss: 1.9888 -> 1.9766  accuracy: 31.67% -> 31.67%     
client [76] (testset)   loss: 1.8912 -> 1.8914  accuracy: 27.78% -> 27.78%     
client [78] (testset)   loss: 1.9224 -> 1.9144  accuracy: 22.73% -> 22.73%     
client [25] (testset)   loss: 2.4610 -> 2.4616  accuracy: 12.00% -> 12.00%     
client [58] (testset)   loss: 1.6733 -> 1.6762  accuracy: 42.47% -> 42.47%     
client [13] (testset)   loss: 2.4923 -> 2.5217  accuracy: 22.22% -> 22.22%     
client [17] (testset)   loss: 2.0027 -> 2.0362  accuracy: 32.00% -> 32.00%     
client [38] (testset)   loss: 2.1888 -> 2.1864  accuracy: 18.92% -> 18.92%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 1.7777 -> 1.8023  accuracy: 53.70% -> 53.70%     
client [82] (testset)   loss: 1.9542 -> 1.9290  accuracy: 11.94% -> 11.94%     
client [86] (testset)   loss: 1.6946 -> 1.6932  accuracy: 48.44% -> 48.44%     
client [51] (testset)   loss: 1.7913 -> 1.7897  accuracy: 47.42% -> 47.42%     
client [96] (testset)   loss: 2.0895 -> 2.0825  accuracy: 30.36% -> 30.36%     
client [42] (testset)   loss: 2.2902 -> 2.2817  accuracy: 7.14% -> 7.14%       
client [55] (testset)   loss: 1.9000 -> 1.9029  accuracy: 42.62% -> 42.62%     
client [13] (testset)   loss: 2.5163 -> 2.4983  accuracy: 22.22% -> 22.22%     
client [1]  (testset)   loss: 2.4071 -> 2.4299  accuracy: 12.50% -> 4.17%      
client [12] (testset)   loss: 1.8897 -> 1.8968  accuracy: 23.73% -> 23.73%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 1.7686 -> 1.7803  accuracy: 37.78% -> 37.78%     
client [23] (testset)   loss: 2.1631 -> 2.1546  accuracy: 20.59% -> 20.59%     
client [46] (testset)   loss: 1.8627 -> 1.8539  accuracy: 48.94% -> 48.94%     
client [41] (testset)   loss: 2.0219 -> 2.0202  accuracy: 26.92% -> 26.92%     
client [25] (testset)   loss: 2.4607 -> 2.4656  accuracy: 12.00% -> 12.00%     
client [58] (testset)   loss: 1.6801 -> 1.6863  accuracy: 42.47% -> 42.47%     
client [14] (testset)   loss: 2.0508 -> 2.0485  accuracy: 31.88% -> 31.88%     
client [33] (testset)   loss: 1.8265 -> 1.7576  accuracy: 22.22% -> 44.44%     
client [85] (testset)   loss: 2.0780 -> 2.0412  accuracy: 29.33% -> 29.33%     
client [62] (testset)   loss: 1.8956 -> 1.8867  accuracy: 41.38% -> 41.38%     
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 2.0544 -> 2.0557  accuracy: 37.74% -> 37.74%     
client [63] (testset)   loss: 1.9722 -> 1.9840  accuracy: 31.67% -> 31.67%     
client [70] (testset)   loss: 2.2315 -> 2.2285  accuracy: 25.00% -> 25.00%     
client [65] (testset)   loss: 1.9907 -> 2.0316  accuracy: 37.74% -> 37.74%     
client [14] (testset)   loss: 2.0452 -> 2.0556  accuracy: 31.88% -> 31.88%     
client [73] (testset)   loss: 2.3379 -> 2.3357  accuracy: 21.05% -> 21.05%     
client [34] (testset)   loss: 1.9084 -> 1.9048  accuracy: 24.59% -> 24.59%     
client [99] (testset)   loss: 2.0731 -> 2.0678  accuracy: 20.51% -> 20.51%     
client [69] (testset)   loss: 2.0207 -> 2.0203  accuracy: 29.41% -> 29.41%     
client [46] (testset)   loss: 1.8511 -> 1.8492  accuracy: 48.94% -> 48.94%     
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [99] (testset)   loss: 2.0721 -> 2.0725  accuracy: 20.51% -> 10.26%     
client [93] (testset)   loss: 1.6996 -> 1.7124  accuracy: 45.65% -> 45.65%     
client [11] (testset)   loss: 1.9925 -> 2.0047  accuracy: 30.36% -> 30.36%     
client [58] (testset)   loss: 1.6765 -> 1.6776  accuracy: 42.47% -> 42.47%     
client [81] (testset)   loss: 2.0148 -> 2.0127  accuracy: 35.14% -> 35.14%     
client [85] (testset)   loss: 2.0576 -> 2.1032  accuracy: 29.33% -> 29.33%     
client [89] (testset)   loss: 1.8455 -> 1.8986  accuracy: 46.88% -> 46.88%     
client [45] (testset)   loss: 2.0372 -> 2.0548  accuracy: 34.78% -> 34.78%     
client [8]  (testset)   loss: 1.8753 -> 1.8828  accuracy: 34.17% -> 34.17%     
client [68] (testset)   loss: 1.7308 -> 1.7416  accuracy: 37.78% -> 37.78%     
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 2.0685 -> 2.0809  accuracy: 19.30% -> 19.30%     
client [72] (testset)   loss: 1.7754 -> 1.8115  accuracy: 53.70% -> 53.70%     
client [1]  (testset)   loss: 2.4240 -> 2.4341  accuracy: 4.17% -> 4.17%       
client [78] (testset)   loss: 1.9203 -> 1.9163  accuracy: 22.73% -> 22.73%     
client [83] (testset)   loss: 2.1485 -> 2.1244  accuracy: 19.57% -> 19.57%     
client [21] (testset)   loss: 1.9469 -> 1.9616  accuracy: 26.32% -> 26.32%     
client [56] (testset)   loss: 2.1340 -> 2.0929  accuracy: 7.27% -> 7.27%       
client [44] (testset)   loss: 2.1329 -> 2.1398  accuracy: 23.21% -> 23.21%     
client [92] (testset)   loss: 2.1094 -> 2.0996  accuracy: 26.47% -> 26.47%     
client [27] (testset)   loss: 1.9967 -> 2.0261  accuracy: 38.75% -> 38.75%     
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 2.0987 -> 2.0958  accuracy: 38.89% -> 38.89%     
client [39] (testset)   loss: 1.4226 -> 1.4407  accuracy: 53.77% -> 53.77%     
client [65] (testset)   loss: 2.0213 -> 2.0274  accuracy: 37.74% -> 37.74%     
client [26] (testset)   loss: 2.1772 -> 2.1714  accuracy: 19.30% -> 22.81%     
client [19] (testset)   loss: 2.1985 -> 2.2151  accuracy: 23.21% -> 23.21%     
client [68] (testset)   loss: 1.7467 -> 1.7905  accuracy: 37.78% -> 37.78%     
client [41] (testset)   loss: 2.0216 -> 2.0202  accuracy: 26.92% -> 26.92%     
client [50] (testset)   loss: 2.1330 -> 2.0995  accuracy: 29.87% -> 29.87%     
client [75] (testset)   loss: 2.1544 -> 2.1368  accuracy: 24.07% -> 22.22%     
client [81] (testset)   loss: 2.0072 -> 2.0050  accuracy: 35.14% -> 35.14%     
Training... ---------------------------------------- 100% 0:07:02
FedPer's average time taken by each global epoch: 0 min 1.05 sec.              
FedPer's total running time: 0 h 7 m 2 s.                                      
==================== FedPer Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9846 -> 0.0000",                                    
                "accuracy": "30.71% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9838 -> 0.0000",                                    
                "accuracy": "30.99% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9827 -> 0.0000",                                    
                "accuracy": "31.55% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9822 -> 0.0000",                                    
                "accuracy": "31.21% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedPer Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 31.55% at epoch 300                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
[0m