==================== FedALA ====================                               
Experiment Arguments:                                                          
{
│   'method': 'fedala',
│   'dataset': {
│   │   'name': 'emnist',
│   │   'client_num': 100,
│   │   'test_ratio': 0.25,
│   │   'val_ratio': 0.0,
│   │   'seed': 42,
│   │   'split': 'sample',
│   │   'IID_ratio': 0.0,
│   │   'monitor_window_name_suffix': 'emnist-100clients-0%IID-Dir(1.0)-seed42',
│   │   'emnist_split': 'byclass',
│   │   'alpha': 1.0,
│   │   'min_samples_per_client': 10
│   },
│   'model': {
│   │   'name': 'avgcnn',
│   │   'use_torchvision_pretrained_weights': True,
│   │   'external_model_weights_path': None
│   },
│   'optimizer': {
│   │   'lr': 0.01,
│   │   'dampening': 0,
│   │   'weight_decay': 0,
│   │   'momentum': 0,
│   │   'nesterov': False,
│   │   'name': 'sgd'
│   },
│   'mode': 'serial',
│   'parallel': {
│   │   'ray_cluster_addr': None,
│   │   'num_cpus': None,
│   │   'num_gpus': None,
│   │   'num_workers': 2
│   },
│   'common': {
│   │   'seed': 42,
│   │   'join_ratio': 0.1,
│   │   'global_epoch': 400,
│   │   'local_epoch': 5,
│   │   'batch_size': 32,
│   │   'reset_optimizer_on_global_epoch': True,
│   │   'straggler_ratio': 0,
│   │   'straggler_min_local_epoch': 0,
│   │   'buffers': 'global',
│   │   'client_side_evaluation': True,
│   │   'test': {
│   │   │   'client': {
│   │   │   │   'interval': 100,
│   │   │   │   'finetune_epoch': 0,
│   │   │   │   'train': False,
│   │   │   │   'val': False,
│   │   │   │   'test': True
│   │   │   },
│   │   │   'server': {
│   │   │   │   'interval': -1,
│   │   │   │   'train': False,
│   │   │   │   'val': False,
│   │   │   │   'test': False,
│   │   │   │   'model_in_train_mode': False
│   │   │   }
│   │   },
│   │   'verbose_gap': 10,
│   │   'monitor': None,
│   │   'use_cuda': True,
│   │   'save_log': True,
│   │   'save_model': False,
│   │   'save_learning_curve_plot': False,
│   │   'save_metrics': True,
│   │   'delete_useless_run': True
│   },
│   'fedala': {
│   │   'layer_idx': 2,
│   │   'num_pre_loss': 10,
│   │   'eta': 1.0,
│   │   'threshold': 0.1,
│   │   'rand_percent': 0.8
│   }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 0.4313 -> 0.4364  accuracy: 83.92% -> 84.83%     
client [81] (testset)   loss: 0.3923 -> 0.3531  accuracy: 86.87% -> 88.16%     
client [21] (testset)   loss: 0.5249 -> 0.5440  accuracy: 82.96% -> 82.06%     
client [68] (testset)   loss: 0.4547 -> 0.4977  accuracy: 84.10% -> 84.15%     
client [93] (testset)   loss: 0.5044 -> 0.5070  accuracy: 81.25% -> 83.21%     
client [31] (testset)   loss: 0.5301 -> 0.5069  accuracy: 81.05% -> 82.91%     
client [20] (testset)   loss: 0.5931 -> 0.5858  accuracy: 80.15% -> 81.53%     
client [59] (testset)   loss: 0.3776 -> 0.3550  accuracy: 88.41% -> 89.80%     
client [48] (testset)   loss: 0.4744 -> 0.5032  accuracy: 84.45% -> 83.46%     
client [34] (testset)   loss: 0.4926 -> 0.4674  accuracy: 79.48% -> 82.99%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 0.5072 -> 0.3767  accuracy: 80.03% -> 87.31%     
client [99] (testset)   loss: 0.4975 -> 0.7685  accuracy: 82.36% -> 78.88%     
client [67] (testset)   loss: 0.4253 -> 0.3398  accuracy: 86.17% -> 89.80%     
client [0]  (testset)   loss: 0.3972 -> 0.3985  accuracy: 85.65% -> 87.51%     
client [76] (testset)   loss: 0.5255 -> 0.4641  accuracy: 84.14% -> 85.99%     
client [41] (testset)   loss: 0.5228 -> 0.5347  accuracy: 81.05% -> 80.17%     
client [62] (testset)   loss: 0.3894 -> 0.3554  accuracy: 89.26% -> 90.25%     
client [2]  (testset)   loss: 0.3783 -> 0.3900  accuracy: 86.75% -> 88.90%     
client [14] (testset)   loss: 0.4840 -> 0.4821  accuracy: 84.02% -> 84.77%     
client [46] (testset)   loss: 0.5097 -> 0.3641  accuracy: 77.45% -> 89.01%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 0.4012 -> 0.4341  accuracy: 84.19% -> 83.59%     
client [68] (testset)   loss: 0.3917 -> 0.3977  accuracy: 86.84% -> 87.59%     
client [57] (testset)   loss: 0.3577 -> 0.3402  accuracy: 88.16% -> 88.73%     
client [17] (testset)   loss: 0.4534 -> 0.4716  accuracy: 85.21% -> 85.43%     
client [54] (testset)   loss: 0.4258 -> 0.4552  accuracy: 84.52% -> 84.28%     
client [23] (testset)   loss: 0.4697 -> 0.4709  accuracy: 85.16% -> 85.16%     
client [35] (testset)   loss: 0.4890 -> 0.4734  accuracy: 83.73% -> 84.90%     
client [59] (testset)   loss: 0.3411 -> 0.3003  accuracy: 88.71% -> 91.35%     
client [31] (testset)   loss: 0.4383 -> 0.5660  accuracy: 84.01% -> 82.71%     
client [9]  (testset)   loss: 0.4791 -> 0.4087  accuracy: 85.96% -> 86.19%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 0.3671 -> 0.3652  accuracy: 87.91% -> 89.06%     
client [33] (testset)   loss: 0.4039 -> 0.3947  accuracy: 84.55% -> 86.71%     
client [16] (testset)   loss: 0.4501 -> 0.4739  accuracy: 84.86% -> 84.86%     
client [44] (testset)   loss: 0.5106 -> 0.5021  accuracy: 83.66% -> 82.13%     
client [8]  (testset)   loss: 0.4096 -> 0.3887  accuracy: 87.86% -> 88.14%     
client [31] (testset)   loss: 0.4524 -> 0.5034  accuracy: 84.16% -> 83.36%     
client [47] (testset)   loss: 0.4125 -> 0.3648  accuracy: 85.66% -> 89.64%     
client [36] (testset)   loss: 0.2739 -> 0.2677  accuracy: 89.66% -> 91.67%     
client [20] (testset)   loss: 0.5517 -> 0.5292  accuracy: 81.80% -> 83.62%     
client [56] (testset)   loss: 0.4568 -> 0.4602  accuracy: 83.77% -> 82.64%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 0.3262 -> 0.3176  accuracy: 88.78% -> 88.78%     
client [60] (testset)   loss: 0.3972 -> 0.4171  accuracy: 87.52% -> 86.19%     
client [28] (testset)   loss: 0.3811 -> 0.3357  accuracy: 87.56% -> 89.24%     
client [25] (testset)   loss: 0.3932 -> 0.3975  accuracy: 86.88% -> 86.96%     
client [58] (testset)   loss: 0.4044 -> 0.3966  accuracy: 87.52% -> 88.49%     
client [44] (testset)   loss: 0.4950 -> 0.5111  accuracy: 83.47% -> 81.68%     
client [39] (testset)   loss: 0.4134 -> 0.4015  accuracy: 83.97% -> 86.04%     
client [29] (testset)   loss: 0.5025 -> 0.4852  accuracy: 83.63% -> 84.80%     
client [3]  (testset)   loss: 0.3813 -> 0.3891  accuracy: 85.99% -> 86.12%     
client [84] (testset)   loss: 0.4651 -> 0.4549  accuracy: 84.91% -> 86.19%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 0.5171 -> 0.5258  accuracy: 83.33% -> 84.59%     
client [84] (testset)   loss: 0.4773 -> 0.4558  accuracy: 84.00% -> 86.50%     
client [10] (testset)   loss: 0.4417 -> 0.3891  accuracy: 84.77% -> 88.73%     
client [36] (testset)   loss: 0.2553 -> 0.2681  accuracy: 90.87% -> 91.46%     
client [65] (testset)   loss: 0.3274 -> 0.3548  accuracy: 89.13% -> 89.39%     
client [81] (testset)   loss: 0.3330 -> 0.3184  accuracy: 89.67% -> 90.63%     
client [79] (testset)   loss: 0.3139 -> 0.3222  accuracy: 90.40% -> 91.47%     
client [42] (testset)   loss: 0.4550 -> 0.3885  accuracy: 82.42% -> 87.73%     
client [11] (testset)   loss: 0.4218 -> 0.4443  accuracy: 87.19% -> 86.59%     
client [96] (testset)   loss: 0.3801 -> 0.3747  accuracy: 86.65% -> 87.09%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 0.4281 -> 0.7808  accuracy: 86.97% -> 84.34%     
client [53] (testset)   loss: 0.3742 -> 0.3491  accuracy: 88.60% -> 90.20%     
client [52] (testset)   loss: 0.5149 -> 0.3744  accuracy: 81.13% -> 88.14%     
client [42] (testset)   loss: 0.3646 -> 0.3681  accuracy: 87.79% -> 89.21%     
client [69] (testset)   loss: 0.4343 -> 0.3903  accuracy: 84.60% -> 88.20%     
client [59] (testset)   loss: 0.3325 -> 0.3088  accuracy: 89.67% -> 91.39%     
client [7]  (testset)   loss: 0.5110 -> 0.4746  accuracy: 81.21% -> 83.41%     
client [26] (testset)   loss: 0.3156 -> 0.3084  accuracy: 89.72% -> 90.85%     
client [49] (testset)   loss: 0.4333 -> 0.3966  accuracy: 85.48% -> 86.53%     
client [98] (testset)   loss: 0.4428 -> 0.4534  accuracy: 86.04% -> 86.64%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 0.5122 -> 0.4772  accuracy: 84.24% -> 85.99%     
client [47] (testset)   loss: 0.4252 -> 0.3882  accuracy: 85.83% -> 88.72%     
client [21] (testset)   loss: 0.5110 -> 0.5281  accuracy: 83.73% -> 84.73%     
client [77] (testset)   loss: 0.4001 -> 0.3874  accuracy: 85.42% -> 87.59%     
client [95] (testset)   loss: 0.3964 -> 0.4086  accuracy: 89.11% -> 90.10%     
client [91] (testset)   loss: 0.5631 -> 0.5111  accuracy: 82.63% -> 83.86%     
client [14] (testset)   loss: 0.4662 -> 0.4902  accuracy: 85.18% -> 85.79%     
client [99] (testset)   loss: 0.4983 -> 0.5333  accuracy: 82.94% -> 83.46%     
client [20] (testset)   loss: 0.5780 -> 0.5407  accuracy: 81.62% -> 83.67%     
client [39] (testset)   loss: 0.4174 -> 0.4194  accuracy: 83.97% -> 85.03%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 0.5115 -> 0.3773  accuracy: 80.89% -> 87.96%     
client [62] (testset)   loss: 0.4147 -> 0.3440  accuracy: 88.62% -> 91.00%     
client [71] (testset)   loss: 0.4217 -> 0.4326  accuracy: 86.74% -> 86.79%     
client [97] (testset)   loss: 0.4185 -> 0.4470  accuracy: 85.95% -> 86.46%     
client [30] (testset)   loss: 0.4111 -> 0.4167  accuracy: 84.69% -> 87.85%     
client [88] (testset)   loss: 0.4541 -> 0.3908  accuracy: 84.98% -> 88.09%     
client [60] (testset)   loss: 0.4016 -> 0.4440  accuracy: 87.92% -> 86.23%     
client [82] (testset)   loss: 0.4128 -> 0.4092  accuracy: 85.47% -> 86.70%     
client [91] (testset)   loss: 0.5672 -> 0.5072  accuracy: 81.79% -> 85.29%     
client [57] (testset)   loss: 0.3678 -> 0.3674  accuracy: 88.34% -> 89.73%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 0.4913 -> 0.5171  accuracy: 82.01% -> 85.01%     
client [15] (testset)   loss: 0.4120 -> 0.4400  accuracy: 85.19% -> 84.35%     
client [71] (testset)   loss: 0.4715 -> 0.4442  accuracy: 85.50% -> 87.22%     
client [97] (testset)   loss: 0.4031 -> 0.4154  accuracy: 87.24% -> 89.00%     
client [53] (testset)   loss: 0.3925 -> 0.3698  accuracy: 88.76% -> 89.48%     
client [77] (testset)   loss: 0.4114 -> 0.4238  accuracy: 84.47% -> 87.04%     
client [76] (testset)   loss: 0.4954 -> 0.4371  accuracy: 85.29% -> 87.39%     
client [79] (testset)   loss: 0.3511 -> 0.3228  accuracy: 89.60% -> 90.89%     
client [28] (testset)   loss: 0.3802 -> 0.3616  accuracy: 89.24% -> 89.96%     
client [99] (testset)   loss: 0.4991 -> 0.5307  accuracy: 84.62% -> 84.25%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 0.4066 -> 0.5226  accuracy: 87.32% -> 85.00%     
client [86] (testset)   loss: 0.3536 -> 0.3694  accuracy: 88.81% -> 89.90%     
client [34] (testset)   loss: 0.5113 -> 0.4394  accuracy: 80.13% -> 87.15%     
client [73] (testset)   loss: 0.3935 -> 0.4332  accuracy: 87.13% -> 88.25%     
client [5]  (testset)   loss: 0.4749 -> 0.3663  accuracy: 85.98% -> 90.33%     
client [96] (testset)   loss: 0.4156 -> 0.4196  accuracy: 85.39% -> 87.29%     
client [22] (testset)   loss: 0.5134 -> 0.4546  accuracy: 84.29% -> 89.14%     
client [60] (testset)   loss: 0.4232 -> 0.4470  accuracy: 86.95% -> 87.56%     
client [66] (testset)   loss: 0.5180 -> 0.4299  accuracy: 82.83% -> 86.47%     
client [83] (testset)   loss: 0.5030 -> 0.3666  accuracy: 84.75% -> 89.82%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 0.4921 -> 0.4507  accuracy: 85.79% -> 88.04%     
client [65] (testset)   loss: 0.3691 -> 0.4009  accuracy: 88.56% -> 88.95%     
client [95] (testset)   loss: 0.3904 -> 0.4007  accuracy: 89.53% -> 90.58%     
client [17] (testset)   loss: 0.5167 -> 0.5225  accuracy: 84.27% -> 85.94%     
client [8]  (testset)   loss: 0.4398 -> 0.4421  accuracy: 87.44% -> 87.95%     
client [35] (testset)   loss: 0.5720 -> 0.5304  accuracy: 84.72% -> 86.44%     
client [98] (testset)   loss: 0.5086 -> 0.4688  accuracy: 86.25% -> 86.55%     
client [53] (testset)   loss: 0.3650 -> 0.3731  accuracy: 89.96% -> 89.72%     
client [43] (testset)   loss: 0.4038 -> 0.4086  accuracy: 87.42% -> 87.47%     
client [64] (testset)   loss: 0.3799 -> 0.3809  accuracy: 89.18% -> 89.52%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 0.5667 -> 0.5330  accuracy: 84.78% -> 84.78%     
client [88] (testset)   loss: 0.4802 -> 0.4219  accuracy: 85.39% -> 87.54%     
client [38] (testset)   loss: 0.4438 -> 0.4439  accuracy: 87.34% -> 87.58%     
client [3]  (testset)   loss: 0.4439 -> 0.4312  accuracy: 86.12% -> 86.21%     
client [5]  (testset)   loss: 0.4348 -> 0.3558  accuracy: 87.96% -> 90.65%     
client [41] (testset)   loss: 0.6069 -> 0.5721  accuracy: 80.64% -> 81.78%     
client [7]  (testset)   loss: 0.6009 -> 0.4943  accuracy: 79.85% -> 84.51%     
client [37] (testset)   loss: 0.5382 -> 0.5238  accuracy: 83.18% -> 84.23%     
client [45] (testset)   loss: 0.4050 -> 0.4121  accuracy: 86.53% -> 86.92%     
client [47] (testset)   loss: 0.4394 -> 0.4172  accuracy: 86.96% -> 88.85%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 0.5452 -> 0.5387  accuracy: 82.01% -> 85.56%     
client [11] (testset)   loss: 0.4704 -> 0.5210  accuracy: 85.81% -> 88.12%     
client [37] (testset)   loss: 0.5268 -> 0.5233  accuracy: 82.98% -> 84.69%     
client [41] (testset)   loss: 0.5455 -> 0.5746  accuracy: 81.05% -> 82.20%     
client [95] (testset)   loss: 0.4292 -> 0.3824  accuracy: 87.44% -> 91.06%     
client [53] (testset)   loss: 0.4069 -> 0.3775  accuracy: 88.36% -> 90.08%     
client [22] (testset)   loss: 0.5342 -> 0.4809  accuracy: 84.34% -> 88.16%     
client [25] (testset)   loss: 0.4229 -> 0.3958  accuracy: 87.33% -> 88.27%     
client [69] (testset)   loss: 0.5165 -> 0.4365  accuracy: 82.82% -> 87.91%     
client [46] (testset)   loss: 0.4619 -> 0.3984  accuracy: 84.12% -> 89.71%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 0.4638 -> 0.4519  accuracy: 85.28% -> 87.97%     
client [69] (testset)   loss: 0.5194 -> 0.4428  accuracy: 83.14% -> 87.63%     
client [82] (testset)   loss: 0.4508 -> 0.4244  accuracy: 85.47% -> 86.93%     
client [45] (testset)   loss: 0.4044 -> 0.4315  accuracy: 86.34% -> 87.26%     
client [7]  (testset)   loss: 0.5513 -> 0.5137  accuracy: 81.63% -> 84.14%     
client [50] (testset)   loss: 0.3537 -> 0.3889  accuracy: 89.43% -> 91.00%     
client [35] (testset)   loss: 0.5488 -> 0.5604  accuracy: 84.53% -> 86.63%     
client [24] (testset)   loss: 0.4654 -> 0.4931  accuracy: 83.63% -> 84.76%     
client [15] (testset)   loss: 0.4257 -> 0.4402  accuracy: 85.34% -> 85.83%     
client [58] (testset)   loss: 0.4551 -> 0.5953  accuracy: 87.22% -> 83.84%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 0.4755 -> 0.4685  accuracy: 85.61% -> 87.92%     
client [76] (testset)   loss: 0.5425 -> 0.4582  accuracy: 84.49% -> 87.89%     
client [67] (testset)   loss: 0.4277 -> 0.4012  accuracy: 88.47% -> 90.18%     
client [37] (testset)   loss: 0.5312 -> 0.5412  accuracy: 83.90% -> 84.42%     
client [58] (testset)   loss: 0.4621 -> 0.4425  accuracy: 87.35% -> 88.97%     
client [64] (testset)   loss: 0.4234 -> 0.4095  accuracy: 86.99% -> 89.52%     
client [77] (testset)   loss: 0.4679 -> 0.4429  accuracy: 83.45% -> 86.72%     
client [55] (testset)   loss: 0.4310 -> 0.4510  accuracy: 87.16% -> 87.79%     
client [12] (testset)   loss: 0.4073 -> 0.3910  accuracy: 88.35% -> 90.36%     
client [89] (testset)   loss: 0.4674 -> 0.4350  accuracy: 87.16% -> 89.72%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 0.5854 -> 0.5414  accuracy: 80.09% -> 85.95%     
client [51] (testset)   loss: 0.5802 -> 0.6103  accuracy: 80.68% -> 82.19%     
client [8]  (testset)   loss: 0.4570 -> 0.4413  accuracy: 87.39% -> 88.47%     
client [18] (testset)   loss: 0.4601 -> 0.4478  accuracy: 85.22% -> 88.51%     
client [94] (testset)   loss: 0.5250 -> 0.4937  accuracy: 83.05% -> 85.28%     
client [81] (testset)   loss: 0.4002 -> 0.4781  accuracy: 87.60% -> 86.87%     
client [3]  (testset)   loss: 0.4476 -> 0.4630  accuracy: 85.44% -> 87.30%     
client [11] (testset)   loss: 0.4871 -> 0.4898  accuracy: 85.56% -> 87.63%     
client [95] (testset)   loss: 0.4304 -> 0.3920  accuracy: 88.01% -> 90.06%     
client [67] (testset)   loss: 0.4655 -> 0.3996  accuracy: 87.00% -> 90.68%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 0.5711 -> 0.5589  accuracy: 84.50% -> 84.73%     
client [79] (testset)   loss: 0.3707 -> 0.3557  accuracy: 89.56% -> 91.51%     
client [58] (testset)   loss: 0.4868 -> 0.4771  accuracy: 87.04% -> 88.18%     
client [88] (testset)   loss: 0.5027 -> 0.4692  accuracy: 85.49% -> 86.79%     
client [46] (testset)   loss: 0.5443 -> 0.4250  accuracy: 80.05% -> 88.95%     
client [11] (testset)   loss: 0.4976 -> 0.5280  accuracy: 85.26% -> 88.32%     
client [55] (testset)   loss: 0.4272 -> 0.4815  accuracy: 87.63% -> 87.21%     
client [13] (testset)   loss: 0.4952 -> 0.3745  accuracy: 85.48% -> 90.64%     
client [31] (testset)   loss: 0.4966 -> 0.5332  accuracy: 83.81% -> 84.81%     
client [75] (testset)   loss: 0.4775 -> 0.4741  accuracy: 86.77% -> 88.96%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 0.4361 -> 0.4064  accuracy: 88.33% -> 89.18%     
client [7]  (testset)   loss: 0.6160 -> 0.5404  accuracy: 80.53% -> 84.04%     
client [57] (testset)   loss: 0.4320 -> 0.4228  accuracy: 88.42% -> 88.95%     
client [13] (testset)   loss: 0.5020 -> 0.3692  accuracy: 84.88% -> 90.14%     
client [43] (testset)   loss: 0.4457 -> 0.4309  accuracy: 86.87% -> 88.56%     
client [91] (testset)   loss: 0.6237 -> 0.5850  accuracy: 83.54% -> 85.42%     
client [10] (testset)   loss: 0.5206 -> 0.4480  accuracy: 85.26% -> 88.87%     
client [64] (testset)   loss: 0.4363 -> 0.4475  accuracy: 86.76% -> 90.50%     
client [82] (testset)   loss: 0.4418 -> 0.4435  accuracy: 87.29% -> 88.24%     
client [22] (testset)   loss: 0.5739 -> 0.5067  accuracy: 84.81% -> 88.45%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 0.7350 -> 0.6743  accuracy: 80.69% -> 83.53%     
client [23] (testset)   loss: 0.5453 -> 0.5595  accuracy: 86.07% -> 85.73%     
client [88] (testset)   loss: 0.5425 -> 0.4821  accuracy: 85.94% -> 87.29%     
client [98] (testset)   loss: 0.5313 -> 0.5383  accuracy: 86.46% -> 85.99%     
client [79] (testset)   loss: 0.3586 -> 0.3830  accuracy: 90.80% -> 91.65%     
client [21] (testset)   loss: 0.6437 -> 0.5706  accuracy: 83.24% -> 85.18%     
client [92] (testset)   loss: 0.5886 -> 0.5543  accuracy: 85.86% -> 88.22%     
client [56] (testset)   loss: 0.5834 -> 0.6054  accuracy: 84.27% -> 83.23%     
client [5]  (testset)   loss: 0.4672 -> 0.3731  accuracy: 87.13% -> 91.17%     
client [52] (testset)   loss: 0.6509 -> 0.4324  accuracy: 80.83% -> 87.90%     
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 0.5632 -> 0.4213  accuracy: 84.12% -> 90.05%     
client [54] (testset)   loss: 0.5103 -> 0.5304  accuracy: 84.96% -> 85.24%     
client [14] (testset)   loss: 0.5573 -> 0.5596  accuracy: 84.67% -> 85.58%     
client [99] (testset)   loss: 0.5990 -> 0.6291  accuracy: 82.62% -> 84.15%     
client [36] (testset)   loss: 0.2994 -> 0.3360  accuracy: 89.97% -> 92.05%     
client [30] (testset)   loss: 0.5104 -> 0.4659  accuracy: 84.77% -> 87.77%     
client [38] (testset)   loss: 0.4609 -> 0.5041  accuracy: 87.22% -> 86.85%     
client [15] (testset)   loss: 0.4317 -> 0.4915  accuracy: 85.44% -> 84.95%     
client [6]  (testset)   loss: 0.4670 -> 0.4717  accuracy: 86.11% -> 86.83%     
client [53] (testset)   loss: 0.4777 -> 0.4176  accuracy: 84.97% -> 89.24%     
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [99] (testset)   loss: 0.5667 -> 0.6246  accuracy: 83.78% -> 83.89%     
client [6]  (testset)   loss: 0.5079 -> 0.4914  accuracy: 83.90% -> 87.66%     
client [83] (testset)   loss: 0.6284 -> 0.4339  accuracy: 83.80% -> 88.65%     
client [42] (testset)   loss: 0.5170 -> 0.4685  accuracy: 85.16% -> 88.55%     
client [34] (testset)   loss: 0.5536 -> 0.5121  accuracy: 82.18% -> 86.18%     
client [15] (testset)   loss: 0.4413 -> 0.4932  accuracy: 85.39% -> 85.59%     
client [47] (testset)   loss: 0.5047 -> 0.4836  accuracy: 85.62% -> 88.30%     
client [55] (testset)   loss: 0.4504 -> 0.4898  accuracy: 87.11% -> 87.21%     
client [51] (testset)   loss: 0.6347 -> 0.6429  accuracy: 80.06% -> 82.13%     
client [95] (testset)   loss: 0.4493 -> 0.4421  accuracy: 88.01% -> 90.34%     
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 0.4972 -> 0.5276  accuracy: 86.95% -> 86.74%     
client [15] (testset)   loss: 0.4825 -> 0.4821  accuracy: 84.75% -> 85.54%     
client [33] (testset)   loss: 0.4802 -> 0.4848  accuracy: 84.86% -> 88.07%     
client [99] (testset)   loss: 0.5725 -> 0.6457  accuracy: 83.10% -> 83.73%     
client [90] (testset)   loss: 0.6120 -> 0.5999  accuracy: 80.23% -> 82.84%     
client [57] (testset)   loss: 0.4725 -> 0.4276  accuracy: 87.55% -> 88.90%     
client [27] (testset)   loss: 0.4802 -> 0.4934  accuracy: 85.86% -> 87.04%     
client [78] (testset)   loss: 0.4702 -> 0.4463  accuracy: 84.85% -> 85.98%     
client [36] (testset)   loss: 0.3665 -> 0.3405  accuracy: 88.52% -> 91.84%     
client [88] (testset)   loss: 0.5183 -> 0.4743  accuracy: 85.84% -> 86.94%     
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 0.4466 -> 0.4967  accuracy: 86.63% -> 87.31%     
client [35] (testset)   loss: 0.5756 -> 0.6144  accuracy: 85.58% -> 84.97%     
client [16] (testset)   loss: 0.6712 -> 0.6257  accuracy: 78.40% -> 84.93%     
client [80] (testset)   loss: 0.5090 -> 0.5040  accuracy: 86.00% -> 87.09%     
client [38] (testset)   loss: 0.4683 -> 0.5155  accuracy: 87.83% -> 86.73%     
client [78] (testset)   loss: 0.4973 -> 0.4731  accuracy: 84.49% -> 86.47%     
client [68] (testset)   loss: 0.4946 -> 0.4689  accuracy: 85.79% -> 88.63%     
client [11] (testset)   loss: 0.5305 -> 0.5128  accuracy: 86.10% -> 88.22%     
client [64] (testset)   loss: 0.4877 -> 0.4649  accuracy: 86.36% -> 89.41%     
client [82] (testset)   loss: 0.4630 -> 0.4550  accuracy: 86.75% -> 87.93%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 0.5265 -> 0.4662  accuracy: 84.39% -> 88.37%     
client [27] (testset)   loss: 0.5136 -> 0.5062  accuracy: 85.82% -> 87.25%     
client [74] (testset)   loss: 0.4327 -> 0.3895  accuracy: 87.84% -> 89.60%     
client [45] (testset)   loss: 0.4570 -> 0.4647  accuracy: 86.97% -> 87.85%     
client [6]  (testset)   loss: 0.5150 -> 0.5009  accuracy: 84.78% -> 88.27%     
client [36] (testset)   loss: 0.3120 -> 0.3523  accuracy: 90.53% -> 91.91%     
client [63] (testset)   loss: 0.4315 -> 0.4037  accuracy: 89.43% -> 90.88%     
client [76] (testset)   loss: 0.5972 -> 0.5016  accuracy: 84.69% -> 87.69%     
client [83] (testset)   loss: 0.6341 -> 0.4375  accuracy: 83.85% -> 89.59%     
client [86] (testset)   loss: 0.4158 -> 0.4066  accuracy: 88.46% -> 89.99%     
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 0.5915 -> 0.4498  accuracy: 83.09% -> 88.69%     
client [99] (testset)   loss: 0.5793 -> 0.6396  accuracy: 82.36% -> 84.10%     
client [74] (testset)   loss: 0.4019 -> 0.3955  accuracy: 88.51% -> 90.07%     
client [73] (testset)   loss: 0.4927 -> 0.4849  accuracy: 85.18% -> 89.53%     
client [29] (testset)   loss: 0.6749 -> 0.5972  accuracy: 81.55% -> 85.59%     
client [92] (testset)   loss: 0.5920 -> 0.5965  accuracy: 85.36% -> 87.82%     
client [6]  (testset)   loss: 0.6686 -> 0.5009  accuracy: 79.52% -> 87.66%     
client [61] (testset)   loss: 0.5599 -> 0.5965  accuracy: 84.05% -> 83.73%     
client [21] (testset)   loss: 0.6212 -> 0.6142  accuracy: 83.01% -> 84.05%     
client [67] (testset)   loss: 0.5356 -> 0.4638  accuracy: 86.21% -> 90.05%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 0.6906 -> 0.4475  accuracy: 81.52% -> 89.41%     
client [32] (testset)   loss: 0.5547 -> 0.5826  accuracy: 82.26% -> 83.08%     
client [95] (testset)   loss: 0.4855 -> 0.4620  accuracy: 87.92% -> 90.29%     
client [61] (testset)   loss: 0.6162 -> 0.5987  accuracy: 83.66% -> 84.58%     
client [27] (testset)   loss: 0.5239 -> 0.5195  accuracy: 84.90% -> 86.62%     
client [25] (testset)   loss: 0.4882 -> 0.4373  accuracy: 86.51% -> 88.55%     
client [68] (testset)   loss: 0.5490 -> 0.5026  accuracy: 85.00% -> 87.74%     
client [34] (testset)   loss: 0.6045 -> 0.5567  accuracy: 81.43% -> 85.26%     
client [71] (testset)   loss: 0.5660 -> 0.5426  accuracy: 85.88% -> 87.01%     
client [89] (testset)   loss: 0.5220 -> 0.4790  accuracy: 87.55% -> 88.90%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 0.4758 -> 0.4777  accuracy: 85.08% -> 86.43%     
client [81] (testset)   loss: 0.4458 -> 0.4064  accuracy: 88.27% -> 90.63%     
client [51] (testset)   loss: 0.6544 -> 0.6643  accuracy: 80.88% -> 82.26%     
client [54] (testset)   loss: 0.5572 -> 0.5855  accuracy: 84.32% -> 84.32%     
client [65] (testset)   loss: 0.4463 -> 0.4543  accuracy: 88.13% -> 88.17%     
client [41] (testset)   loss: 0.5964 -> 0.6765  accuracy: 82.25% -> 81.78%     
client [11] (testset)   loss: 0.5548 -> 0.5290  accuracy: 85.81% -> 87.73%     
client [85] (testset)   loss: 0.3501 -> 0.4106  accuracy: 91.63% -> 90.65%     
client [12] (testset)   loss: 0.4428 -> 0.4475  accuracy: 88.17% -> 89.36%     
client [23] (testset)   loss: 0.5871 -> 0.5988  accuracy: 84.31% -> 86.41%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 0.6969 -> 0.6225  accuracy: 79.03% -> 85.62%     
client [65] (testset)   loss: 0.4304 -> 0.4719  accuracy: 89.43% -> 89.00%     
client [53] (testset)   loss: 0.5157 -> 0.4345  accuracy: 85.13% -> 88.32%     
client [58] (testset)   loss: 0.5072 -> 0.5200  accuracy: 86.87% -> 89.45%     
client [72] (testset)   loss: 0.5072 -> 0.5720  accuracy: 85.61% -> 86.27%     
client [7]  (testset)   loss: 0.6068 -> 0.6143  accuracy: 82.00% -> 84.56%     
client [71] (testset)   loss: 0.6371 -> 0.5593  accuracy: 83.61% -> 86.68%     
client [59] (testset)   loss: 0.5052 -> 0.3794  accuracy: 85.81% -> 91.18%     
client [86] (testset)   loss: 0.4248 -> 0.4357  accuracy: 88.42% -> 89.86%     
client [39] (testset)   loss: 0.5614 -> 0.5281  accuracy: 82.23% -> 84.87%     
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 0.5975 -> 0.6741  accuracy: 83.36% -> 83.41%     
client [7]  (testset)   loss: 0.6859 -> 0.5793  accuracy: 79.75% -> 84.72%     
client [17] (testset)   loss: 0.6279 -> 0.6720  accuracy: 82.78% -> 86.92%     
client [64] (testset)   loss: 0.4636 -> 0.4830  accuracy: 87.85% -> 89.35%     
client [37] (testset)   loss: 0.5893 -> 0.5927  accuracy: 82.72% -> 84.95%     
client [29] (testset)   loss: 0.6313 -> 0.6248  accuracy: 83.52% -> 86.02%     
client [93] (testset)   loss: 0.5609 -> 0.5701  accuracy: 83.50% -> 85.63%     
client [73] (testset)   loss: 0.5293 -> 0.5082  accuracy: 85.85% -> 88.69%     
client [40] (testset)   loss: 0.6144 -> 0.6245  accuracy: 80.41% -> 81.77%     
client [76] (testset)   loss: 0.6037 -> 0.5194  accuracy: 83.44% -> 87.89%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 0.5658 -> 0.6102  accuracy: 83.76% -> 85.06%     
client [89] (testset)   loss: 0.5586 -> 0.4994  accuracy: 87.45% -> 88.90%     
client [77] (testset)   loss: 0.5042 -> 0.5757  accuracy: 84.08% -> 87.71%     
client [90] (testset)   loss: 0.6549 -> 0.6514  accuracy: 80.57% -> 83.09%     
client [26] (testset)   loss: 0.4502 -> 0.4136  accuracy: 88.62% -> 91.09%     
client [50] (testset)   loss: 0.4217 -> 0.4639  accuracy: 89.79% -> 91.20%     
client [30] (testset)   loss: 0.5633 -> 0.5253  accuracy: 84.69% -> 87.77%     
client [70] (testset)   loss: 0.5020 -> 0.5183  accuracy: 85.60% -> 87.99%     
client [41] (testset)   loss: 0.6336 -> 0.7000  accuracy: 80.17% -> 80.58%     
client [99] (testset)   loss: 0.6283 -> 0.6997  accuracy: 83.04% -> 83.46%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [68] (testset)   loss: 0.5559 -> 0.5013  accuracy: 84.90% -> 88.43%     
client [70] (testset)   loss: 0.4780 -> 0.5265  accuracy: 86.67% -> 87.59%     
client [52] (testset)   loss: 0.6638 -> 0.5102  accuracy: 81.37% -> 87.60%     
client [1]  (testset)   loss: 0.5142 -> 0.5061  accuracy: 87.12% -> 89.12%     
client [2]  (testset)   loss: 0.4935 -> 0.5327  accuracy: 87.34% -> 88.70%     
client [67] (testset)   loss: 0.5583 -> 0.4812  accuracy: 85.37% -> 89.93%     
client [92] (testset)   loss: 0.6214 -> 0.6425  accuracy: 85.91% -> 87.27%     
client [35] (testset)   loss: 0.6342 -> 0.6412  accuracy: 85.21% -> 85.27%     
client [36] (testset)   loss: 0.3430 -> 0.3623  accuracy: 90.21% -> 91.91%     
client [64] (testset)   loss: 0.5006 -> 0.4822  accuracy: 87.33% -> 88.89%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 0.6911 -> 0.6675  accuracy: 83.34% -> 82.00%     
client [6]  (testset)   loss: 0.6196 -> 0.5253  accuracy: 82.73% -> 87.55%     
client [12] (testset)   loss: 0.4806 -> 0.4479  accuracy: 88.04% -> 90.04%     
client [55] (testset)   loss: 0.5273 -> 0.5612  accuracy: 86.54% -> 87.37%     
client [29] (testset)   loss: 0.6745 -> 0.6337  accuracy: 83.47% -> 85.54%     
client [9]  (testset)   loss: 0.6681 -> 0.5913  accuracy: 85.60% -> 85.55%     
client [43] (testset)   loss: 0.5055 -> 0.4792  accuracy: 86.37% -> 88.46%     
client [77] (testset)   loss: 0.5359 -> 0.5582  accuracy: 83.76% -> 87.36%     
client [98] (testset)   loss: 0.6249 -> 0.6052  accuracy: 85.01% -> 85.91%     
client [78] (testset)   loss: 0.5193 -> 0.5105  accuracy: 84.99% -> 86.47%     
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 0.6386 -> 0.6477  accuracy: 85.41% -> 87.97%     
client [80] (testset)   loss: 0.5593 -> 0.5628  accuracy: 85.65% -> 87.09%     
client [63] (testset)   loss: 0.4976 -> 0.4445  accuracy: 87.63% -> 90.94%     
client [76] (testset)   loss: 0.6289 -> 0.5311  accuracy: 83.94% -> 88.04%     
client [78] (testset)   loss: 0.5346 -> 0.5227  accuracy: 84.27% -> 86.02%     
client [25] (testset)   loss: 0.5277 -> 0.4801  accuracy: 85.98% -> 88.14%     
client [58] (testset)   loss: 0.5493 -> 0.5551  accuracy: 86.87% -> 88.88%     
client [13] (testset)   loss: 0.5562 -> 0.4339  accuracy: 85.21% -> 90.25%     
client [17] (testset)   loss: 0.6650 -> 0.6822  accuracy: 83.29% -> 86.97%     
client [38] (testset)   loss: 0.5034 -> 0.5466  accuracy: 87.09% -> 87.46%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 0.5531 -> 0.6105  accuracy: 84.11% -> 86.18%     
client [82] (testset)   loss: 0.5324 -> 0.5285  accuracy: 85.52% -> 87.24%     
client [86] (testset)   loss: 0.4356 -> 0.4498  accuracy: 88.94% -> 89.77%     
client [51] (testset)   loss: 0.7036 -> 0.7252  accuracy: 79.85% -> 81.30%     
client [96] (testset)   loss: 0.5323 -> 0.5895  accuracy: 85.19% -> 86.36%     
client [42] (testset)   loss: 0.5784 -> 0.5113  accuracy: 84.72% -> 88.88%     
client [55] (testset)   loss: 0.5026 -> 0.5626  accuracy: 87.42% -> 87.53%     
client [13] (testset)   loss: 0.5474 -> 0.4472  accuracy: 85.43% -> 90.64%     
client [1]  (testset)   loss: 0.5742 -> 0.5188  accuracy: 86.33% -> 88.97%     
client [12] (testset)   loss: 0.4898 -> 0.4622  accuracy: 87.91% -> 89.42%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 0.5918 -> 0.5261  accuracy: 84.30% -> 88.04%     
client [23] (testset)   loss: 0.6629 -> 0.6124  accuracy: 83.40% -> 86.70%     
client [46] (testset)   loss: 0.7589 -> 0.4989  accuracy: 75.92% -> 88.37%     
client [41] (testset)   loss: 0.6896 -> 0.7184  accuracy: 79.75% -> 81.16%     
client [25] (testset)   loss: 0.5309 -> 0.4944  accuracy: 85.61% -> 88.68%     
client [58] (testset)   loss: 0.5326 -> 0.5530  accuracy: 87.22% -> 88.53%     
client [14] (testset)   loss: 0.6093 -> 0.6697  accuracy: 84.67% -> 84.98%     
client [33] (testset)   loss: 0.5227 -> 0.5563  accuracy: 85.23% -> 88.01%     
client [85] (testset)   loss: 0.4019 -> 0.4212  accuracy: 91.02% -> 90.83%     
client [62] (testset)   loss: 0.5375 -> 0.4901  accuracy: 88.04% -> 89.61%     
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 0.6602 -> 0.6359  accuracy: 86.51% -> 85.57%     
client [63] (testset)   loss: 0.4785 -> 0.4817  accuracy: 89.75% -> 90.78%     
client [70] (testset)   loss: 0.5307 -> 0.5358  accuracy: 86.04% -> 87.63%     
client [65] (testset)   loss: 0.5058 -> 0.4937  accuracy: 89.26% -> 89.21%     
client [14] (testset)   loss: 0.6776 -> 0.6561  accuracy: 83.66% -> 85.99%     
client [73] (testset)   loss: 0.5744 -> 0.5563  accuracy: 85.79% -> 89.03%     
client [34] (testset)   loss: 0.6701 -> 0.5796  accuracy: 80.94% -> 85.26%     
client [99] (testset)   loss: 0.6396 -> 0.7140  accuracy: 83.62% -> 83.57%     
client [69] (testset)   loss: 0.7080 -> 0.5630  accuracy: 82.26% -> 88.04%     
client [46] (testset)   loss: 0.6860 -> 0.5292  accuracy: 79.67% -> 88.31%     
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [99] (testset)   loss: 0.6312 -> 0.7275  accuracy: 82.68% -> 83.57%     
client [93] (testset)   loss: 0.6310 -> 0.6096  accuracy: 83.04% -> 84.88%     
client [11] (testset)   loss: 0.5763 -> 0.6052  accuracy: 86.25% -> 86.94%     
client [58] (testset)   loss: 0.5347 -> 0.5583  accuracy: 87.04% -> 89.40%     
client [81] (testset)   loss: 0.4778 -> 0.4713  accuracy: 88.66% -> 90.35%     
client [85] (testset)   loss: 0.4119 -> 0.4247  accuracy: 90.77% -> 90.95%     
client [89] (testset)   loss: 0.5810 -> 0.5103  accuracy: 87.07% -> 88.95%     
client [45] (testset)   loss: 0.4902 -> 0.5377  accuracy: 86.68% -> 87.26%     
client [8]  (testset)   loss: 0.5530 -> 0.5397  accuracy: 86.69% -> 88.56%     
client [68] (testset)   loss: 0.5995 -> 0.5532  accuracy: 85.34% -> 88.38%     
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 0.5883 -> 0.5111  accuracy: 86.38% -> 90.10%     
client [72] (testset)   loss: 0.5781 -> 0.6135  accuracy: 84.46% -> 86.27%     
client [1]  (testset)   loss: 0.5682 -> 0.5520  accuracy: 86.27% -> 89.65%     
client [78] (testset)   loss: 0.5772 -> 0.5521  accuracy: 84.27% -> 86.07%     
client [83] (testset)   loss: 0.7414 -> 0.4933  accuracy: 83.58% -> 89.10%     
client [21] (testset)   loss: 0.6989 -> 0.6804  accuracy: 83.55% -> 84.41%     
client [56] (testset)   loss: 0.6492 -> 0.7274  accuracy: 83.81% -> 83.63%     
client [44] (testset)   loss: 0.7133 -> 0.7439  accuracy: 83.54% -> 82.07%     
client [92] (testset)   loss: 0.6989 -> 0.6694  accuracy: 85.51% -> 87.07%     
client [27] (testset)   loss: 0.5564 -> 0.5730  accuracy: 85.23% -> 86.24%     
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 0.5975 -> 0.5610  accuracy: 85.46% -> 88.92%     
client [39] (testset)   loss: 0.5555 -> 0.5485  accuracy: 83.30% -> 85.48%     
client [65] (testset)   loss: 0.4811 -> 0.4939  accuracy: 88.13% -> 89.00%     
client [26] (testset)   loss: 0.4720 -> 0.4355  accuracy: 88.42% -> 90.81%     
client [19] (testset)   loss: 0.4864 -> 0.5037  accuracy: 88.60% -> 88.73%     
client [68] (testset)   loss: 0.5828 -> 0.5937  accuracy: 84.90% -> 87.19%     
client [41] (testset)   loss: 0.7257 -> 0.7417  accuracy: 79.49% -> 81.16%     
client [50] (testset)   loss: 0.4414 -> 0.4998  accuracy: 89.28% -> 91.25%     
client [75] (testset)   loss: 0.6147 -> 0.5879  accuracy: 86.10% -> 88.25%     
client [81] (testset)   loss: 0.4622 -> 0.4847  accuracy: 89.17% -> 90.68%     
Training... ---------------------------------------- 100% 3:00:04
FedALA's average time taken by each global epoch: 0 min 26.58 sec.             
FedALA's total running time: 3 h 0 m 4 s.                                      
==================== FedALA Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.4645 -> 0.0000",                                    
                "accuracy": "85.09% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.5155 -> 0.0000",                                    
                "accuracy": "84.78% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.5587 -> 0.0000",                                    
                "accuracy": "84.79% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.6156 -> 0.0000",                                    
                "accuracy": "84.58% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedALA Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 85.09% at epoch 100                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
[0m