==================== FedPer ====================                               
Experiment Arguments:                                                          
{
â”‚   'method': 'fedper',
â”‚   'dataset': {
â”‚   â”‚   'name': 'medmnistA',
â”‚   â”‚   'client_num': 100,
â”‚   â”‚   'test_ratio': 0.25,
â”‚   â”‚   'val_ratio': 0.0,
â”‚   â”‚   'seed': 42,
â”‚   â”‚   'split': 'sample',
â”‚   â”‚   'IID_ratio': 0.0,
â”‚   â”‚   'monitor_window_name_suffix': 'medmnistA-100clients-0%IID-Dir(1.0)-seed42',
â”‚   â”‚   'alpha': 1.0,
â”‚   â”‚   'min_samples_per_client': 10
â”‚   },
â”‚   'model': {
â”‚   â”‚   'name': 'lenet5',
â”‚   â”‚   'use_torchvision_pretrained_weights': True,
â”‚   â”‚   'external_model_weights_path': None
â”‚   },
â”‚   'optimizer': {
â”‚   â”‚   'lr': 0.01,
â”‚   â”‚   'dampening': 0,
â”‚   â”‚   'weight_decay': 0,
â”‚   â”‚   'momentum': 0,
â”‚   â”‚   'nesterov': False,
â”‚   â”‚   'name': 'sgd'
â”‚   },
â”‚   'mode': 'serial',
â”‚   'parallel': {
â”‚   â”‚   'ray_cluster_addr': None,
â”‚   â”‚   'num_cpus': None,
â”‚   â”‚   'num_gpus': None,
â”‚   â”‚   'num_workers': 2
â”‚   },
â”‚   'common': {
â”‚   â”‚   'seed': 42,
â”‚   â”‚   'join_ratio': 0.1,
â”‚   â”‚   'global_epoch': 400,
â”‚   â”‚   'local_epoch': 5,
â”‚   â”‚   'batch_size': 32,
â”‚   â”‚   'reset_optimizer_on_global_epoch': True,
â”‚   â”‚   'straggler_ratio': 0,
â”‚   â”‚   'straggler_min_local_epoch': 0,
â”‚   â”‚   'buffers': 'global',
â”‚   â”‚   'client_side_evaluation': True,
â”‚   â”‚   'test': {
â”‚   â”‚   â”‚   'client': {
â”‚   â”‚   â”‚   â”‚   'interval': 100,
â”‚   â”‚   â”‚   â”‚   'finetune_epoch': 0,
â”‚   â”‚   â”‚   â”‚   'train': False,
â”‚   â”‚   â”‚   â”‚   'val': False,
â”‚   â”‚   â”‚   â”‚   'test': True
â”‚   â”‚   â”‚   },
â”‚   â”‚   â”‚   'server': {
â”‚   â”‚   â”‚   â”‚   'interval': -1,
â”‚   â”‚   â”‚   â”‚   'train': False,
â”‚   â”‚   â”‚   â”‚   'val': False,
â”‚   â”‚   â”‚   â”‚   'test': False,
â”‚   â”‚   â”‚   â”‚   'model_in_train_mode': False
â”‚   â”‚   â”‚   }
â”‚   â”‚   },
â”‚   â”‚   'verbose_gap': 10,
â”‚   â”‚   'monitor': None,
â”‚   â”‚   'use_cuda': True,
â”‚   â”‚   'save_log': True,
â”‚   â”‚   'save_model': False,
â”‚   â”‚   'save_learning_curve_plot': False,
â”‚   â”‚   'save_metrics': True,
â”‚   â”‚   'delete_useless_run': True
â”‚   }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 2.1403 -> 2.0619  accuracy: 19.61% -> 24.84%     
client [81] (testset)   loss: 2.3150 -> 2.2046  accuracy: 5.21% -> 25.00%      
client [21] (testset)   loss: 2.3442 -> 2.0147  accuracy: 27.10% -> 27.10%     
client [68] (testset)   loss: 2.1916 -> 2.1052  accuracy: 16.80% -> 16.80%     
client [93] (testset)   loss: 1.4481 -> 1.1902  accuracy: 69.57% -> 69.57%     
client [31] (testset)   loss: 2.3464 -> 2.2174  accuracy: 4.12% -> 18.56%      
client [20] (testset)   loss: 1.9992 -> 1.9861  accuracy: 32.42% -> 32.42%     
client [59] (testset)   loss: 2.5341 -> 2.0612  accuracy: 7.48% -> 21.77%      
client [48] (testset)   loss: 2.1437 -> 2.1585  accuracy: 21.98% -> 21.98%     
client [34] (testset)   loss: 2.0203 -> 2.0196  accuracy: 32.74% -> 32.74%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 1.9843 -> 1.9114  accuracy: 30.13% -> 25.64%     
client [99] (testset)   loss: 2.0014 -> 1.9774  accuracy: 32.79% -> 32.79%     
client [67] (testset)   loss: 2.1202 -> 2.1128  accuracy: 20.18% -> 19.27%     
client [0]  (testset)   loss: 2.1454 -> 2.1024  accuracy: 17.28% -> 17.28%     
client [76] (testset)   loss: 2.1929 -> 2.1560  accuracy: 10.53% -> 20.39%     
client [41] (testset)   loss: 2.3152 -> 1.8965  accuracy: 8.85% -> 44.25%      
client [62] (testset)   loss: 2.3600 -> 2.0465  accuracy: 7.06% -> 33.83%      
client [2]  (testset)   loss: 2.4428 -> 2.0502  accuracy: 11.98% -> 11.98%     
client [14] (testset)   loss: 1.9815 -> 1.9577  accuracy: 35.56% -> 35.56%     
client [46] (testset)   loss: 2.0040 -> 1.9718  accuracy: 30.39% -> 30.39%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 1.7675 -> 1.7398  accuracy: 39.88% -> 39.88%     
client [68] (testset)   loss: 2.0771 -> 2.0680  accuracy: 23.20% -> 23.20%     
client [57] (testset)   loss: 2.2788 -> 2.2277  accuracy: 19.75% -> 19.75%     
client [17] (testset)   loss: 2.1411 -> 2.1774  accuracy: 20.00% -> 20.00%     
client [54] (testset)   loss: 2.0319 -> 2.0394  accuracy: 20.00% -> 20.00%     
client [23] (testset)   loss: 2.3077 -> 2.0585  accuracy: 24.23% -> 24.23%     
client [35] (testset)   loss: 2.0648 -> 2.0387  accuracy: 17.78% -> 23.33%     
client [59] (testset)   loss: 2.0883 -> 2.0579  accuracy: 24.49% -> 24.49%     
client [31] (testset)   loss: 2.1732 -> 2.1764  accuracy: 18.56% -> 18.56%     
client [9]  (testset)   loss: 2.1032 -> 2.0935  accuracy: 31.11% -> 31.11%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 2.1275 -> 2.1280  accuracy: 11.11% -> 15.87%     
client [33] (testset)   loss: 2.1229 -> 2.1226  accuracy: 28.82% -> 28.82%     
client [16] (testset)   loss: 1.4388 -> 1.3988  accuracy: 59.84% -> 59.84%     
client [44] (testset)   loss: 2.1047 -> 2.0742  accuracy: 28.38% -> 28.38%     
client [8]  (testset)   loss: 1.8528 -> 1.8602  accuracy: 46.10% -> 46.10%     
client [31] (testset)   loss: 2.1872 -> 2.1804  accuracy: 11.34% -> 18.56%     
client [47] (testset)   loss: 1.7740 -> 1.7631  accuracy: 27.97% -> 27.97%     
client [36] (testset)   loss: 1.8836 -> 1.8289  accuracy: 36.54% -> 36.54%     
client [20] (testset)   loss: 1.9787 -> 1.9979  accuracy: 32.42% -> 32.42%     
client [56] (testset)   loss: 1.9213 -> 1.9257  accuracy: 32.58% -> 32.58%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 1.9385 -> 1.9427  accuracy: 32.92% -> 32.92%     
client [60] (testset)   loss: 1.9584 -> 1.9173  accuracy: 28.35% -> 28.35%     
client [28] (testset)   loss: 2.1515 -> 2.1457  accuracy: 18.58% -> 18.58%     
client [25] (testset)   loss: 1.8322 -> 1.8280  accuracy: 40.30% -> 40.30%     
client [58] (testset)   loss: 1.7297 -> 1.7200  accuracy: 31.11% -> 31.11%     
client [44] (testset)   loss: 2.0721 -> 2.0672  accuracy: 28.38% -> 28.38%     
client [39] (testset)   loss: 2.0080 -> 1.9853  accuracy: 19.53% -> 20.12%     
client [29] (testset)   loss: 2.2936 -> 2.2955  accuracy: 24.04% -> 24.04%     
client [3]  (testset)   loss: 1.4535 -> 1.4209  accuracy: 62.66% -> 62.66%     
client [84] (testset)   loss: 2.1703 -> 2.2037  accuracy: 21.93% -> 21.93%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 2.0131 -> 2.0076  accuracy: 27.10% -> 27.10%     
client [84] (testset)   loss: 2.1972 -> 2.1892  accuracy: 21.93% -> 21.93%     
client [10] (testset)   loss: 1.8171 -> 1.8450  accuracy: 36.94% -> 36.94%     
client [36] (testset)   loss: 1.8217 -> 1.8417  accuracy: 36.54% -> 36.54%     
client [65] (testset)   loss: 1.9703 -> 1.9864  accuracy: 28.26% -> 28.26%     
client [81] (testset)   loss: 2.2562 -> 2.2373  accuracy: 14.58% -> 20.83%     
client [79] (testset)   loss: 2.0431 -> 2.0292  accuracy: 21.78% -> 21.78%     
client [42] (testset)   loss: 2.0684 -> 2.0695  accuracy: 20.95% -> 21.62%     
client [11] (testset)   loss: 2.0139 -> 2.0143  accuracy: 36.28% -> 36.28%     
client [96] (testset)   loss: 2.0200 -> 2.0191  accuracy: 22.41% -> 22.41%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 1.8656 -> 1.8707  accuracy: 46.10% -> 46.10%     
client [53] (testset)   loss: 1.8691 -> 1.8483  accuracy: 28.70% -> 32.41%     
client [52] (testset)   loss: 1.8916 -> 1.8848  accuracy: 28.38% -> 28.38%     
client [42] (testset)   loss: 2.0720 -> 2.0672  accuracy: 20.95% -> 20.95%     
client [69] (testset)   loss: 1.9248 -> 1.9181  accuracy: 25.64% -> 25.64%     
client [59] (testset)   loss: 2.0519 -> 2.0535  accuracy: 24.49% -> 24.49%     
client [7]  (testset)   loss: 1.8499 -> 1.8373  accuracy: 41.94% -> 41.94%     
client [26] (testset)   loss: 1.4771 -> 1.4721  accuracy: 54.98% -> 54.98%     
client [49] (testset)   loss: 1.7091 -> 1.7109  accuracy: 48.28% -> 48.28%     
client [98] (testset)   loss: 2.1445 -> 2.1506  accuracy: 28.74% -> 28.74%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 2.1408 -> 2.1739  accuracy: 28.74% -> 28.74%     
client [47] (testset)   loss: 1.7693 -> 1.7575  accuracy: 27.97% -> 27.97%     
client [21] (testset)   loss: 2.0059 -> 1.9900  accuracy: 27.10% -> 27.10%     
client [77] (testset)   loss: 2.0593 -> 2.0689  accuracy: 24.84% -> 19.61%     
client [95] (testset)   loss: 2.1861 -> 2.1772  accuracy: 12.84% -> 20.18%     
client [91] (testset)   loss: 2.2566 -> 2.2571  accuracy: 13.10% -> 13.10%     
client [14] (testset)   loss: 1.9577 -> 1.9650  accuracy: 35.56% -> 35.56%     
client [99] (testset)   loss: 1.9841 -> 1.9791  accuracy: 32.79% -> 32.79%     
client [20] (testset)   loss: 1.9801 -> 1.9859  accuracy: 32.42% -> 32.42%     
client [39] (testset)   loss: 1.9922 -> 1.9893  accuracy: 19.53% -> 19.53%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 1.8890 -> 1.8943  accuracy: 28.38% -> 28.38%     
client [62] (testset)   loss: 2.0501 -> 2.0669  accuracy: 33.83% -> 33.83%     
client [71] (testset)   loss: 1.7543 -> 1.7410  accuracy: 40.35% -> 40.35%     
client [97] (testset)   loss: 1.9305 -> 1.9377  accuracy: 21.26% -> 21.26%     
client [30] (testset)   loss: 1.7907 -> 1.7908  accuracy: 32.47% -> 32.47%     
client [88] (testset)   loss: 1.8679 -> 1.8829  accuracy: 41.42% -> 41.42%     
client [60] (testset)   loss: 1.9157 -> 1.9292  accuracy: 28.35% -> 25.77%     
client [82] (testset)   loss: 1.8374 -> 1.8408  accuracy: 38.26% -> 38.26%     
client [91] (testset)   loss: 2.2578 -> 2.2585  accuracy: 13.10% -> 13.10%     
client [57] (testset)   loss: 2.2340 -> 2.2244  accuracy: 19.75% -> 19.75%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 2.1808 -> 2.1785  accuracy: 18.56% -> 18.56%     
client [15] (testset)   loss: 1.9450 -> 1.9582  accuracy: 35.54% -> 35.54%     
client [71] (testset)   loss: 1.7583 -> 1.7339  accuracy: 40.35% -> 40.35%     
client [97] (testset)   loss: 1.9243 -> 1.9251  accuracy: 18.36% -> 21.26%     
client [53] (testset)   loss: 1.8575 -> 1.8888  accuracy: 32.41% -> 32.41%     
client [77] (testset)   loss: 2.0616 -> 2.0631  accuracy: 19.61% -> 24.84%     
client [76] (testset)   loss: 2.1328 -> 2.1290  accuracy: 20.39% -> 20.39%     
client [79] (testset)   loss: 2.0443 -> 2.0324  accuracy: 21.78% -> 21.78%     
client [28] (testset)   loss: 2.1196 -> 2.1189  accuracy: 18.58% -> 23.01%     
client [99] (testset)   loss: 1.9815 -> 1.9833  accuracy: 32.79% -> 32.79%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 1.9343 -> 1.9202  accuracy: 21.26% -> 21.26%     
client [86] (testset)   loss: 1.9967 -> 1.9969  accuracy: 22.62% -> 22.62%     
client [34] (testset)   loss: 1.9939 -> 1.9900  accuracy: 32.74% -> 32.74%     
client [73] (testset)   loss: 1.8505 -> 1.8537  accuracy: 27.18% -> 27.18%     
client [5]  (testset)   loss: 1.6204 -> 1.6585  accuracy: 51.79% -> 51.79%     
client [96] (testset)   loss: 2.0229 -> 2.0174  accuracy: 22.41% -> 22.41%     
client [22] (testset)   loss: 2.0778 -> 2.0778  accuracy: 30.86% -> 30.86%     
client [60] (testset)   loss: 1.9189 -> 1.9315  accuracy: 28.35% -> 25.77%     
client [66] (testset)   loss: 2.0389 -> 2.0336  accuracy: 30.23% -> 30.23%     
client [83] (testset)   loss: 1.7710 -> 1.7703  accuracy: 30.82% -> 30.82%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 2.1432 -> 2.1247  accuracy: 20.39% -> 20.39%     
client [65] (testset)   loss: 1.9714 -> 1.9788  accuracy: 28.26% -> 28.26%     
client [95] (testset)   loss: 2.1809 -> 2.1752  accuracy: 12.84% -> 12.84%     
client [17] (testset)   loss: 2.1220 -> 2.1105  accuracy: 23.08% -> 20.00%     
client [8]  (testset)   loss: 1.8490 -> 1.8632  accuracy: 46.10% -> 46.10%     
client [35] (testset)   loss: 2.0357 -> 2.0428  accuracy: 23.33% -> 23.33%     
client [98] (testset)   loss: 2.1375 -> 2.1938  accuracy: 28.74% -> 28.74%     
client [53] (testset)   loss: 1.8620 -> 1.8834  accuracy: 28.70% -> 32.41%     
client [43] (testset)   loss: 2.1525 -> 2.1465  accuracy: 24.17% -> 24.17%     
client [64] (testset)   loss: 2.1205 -> 2.1211  accuracy: 15.87% -> 15.87%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 1.9984 -> 1.9999  accuracy: 27.10% -> 27.10%     
client [88] (testset)   loss: 1.8721 -> 1.8789  accuracy: 41.42% -> 41.42%     
client [38] (testset)   loss: 1.9305 -> 1.9415  accuracy: 39.31% -> 39.31%     
client [3]  (testset)   loss: 1.4283 -> 1.4229  accuracy: 62.66% -> 62.66%     
client [5]  (testset)   loss: 1.6175 -> 1.6178  accuracy: 51.79% -> 51.79%     
client [41] (testset)   loss: 1.8801 -> 1.8781  accuracy: 44.25% -> 44.25%     
client [7]  (testset)   loss: 1.8596 -> 1.8467  accuracy: 41.94% -> 41.94%     
client [37] (testset)   loss: 2.2705 -> 2.2716  accuracy: 13.01% -> 13.01%     
client [45] (testset)   loss: 1.8716 -> 1.9039  accuracy: 33.57% -> 33.57%     
client [47] (testset)   loss: 1.7602 -> 1.7487  accuracy: 27.97% -> 27.97%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 1.3982 -> 1.3958  accuracy: 59.84% -> 59.84%     
client [11] (testset)   loss: 2.0185 -> 2.0131  accuracy: 36.28% -> 36.28%     
client [37] (testset)   loss: 2.2729 -> 2.2724  accuracy: 13.01% -> 13.01%     
client [41] (testset)   loss: 1.8798 -> 1.8774  accuracy: 44.25% -> 44.25%     
client [95] (testset)   loss: 2.1813 -> 2.1764  accuracy: 12.84% -> 20.18%     
client [53] (testset)   loss: 1.8465 -> 1.8791  accuracy: 32.41% -> 32.41%     
client [22] (testset)   loss: 2.0826 -> 2.0752  accuracy: 30.86% -> 30.86%     
client [25] (testset)   loss: 1.8286 -> 1.8366  accuracy: 40.30% -> 40.30%     
client [69] (testset)   loss: 1.9204 -> 1.9253  accuracy: 25.64% -> 25.64%     
client [46] (testset)   loss: 1.9497 -> 1.9534  accuracy: 30.39% -> 30.39%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 1.7522 -> 1.7532  accuracy: 27.97% -> 27.97%     
client [69] (testset)   loss: 1.9183 -> 1.9148  accuracy: 25.64% -> 25.64%     
client [82] (testset)   loss: 1.8333 -> 1.8340  accuracy: 38.26% -> 38.26%     
client [45] (testset)   loss: 1.8691 -> 1.8695  accuracy: 33.57% -> 33.57%     
client [7]  (testset)   loss: 1.8630 -> 1.8617  accuracy: 41.94% -> 41.94%     
client [50] (testset)   loss: 2.1208 -> 2.1249  accuracy: 17.09% -> 23.08%     
client [35] (testset)   loss: 2.0385 -> 2.0366  accuracy: 23.33% -> 23.33%     
client [24] (testset)   loss: 1.7349 -> 1.7264  accuracy: 39.88% -> 39.88%     
client [15] (testset)   loss: 1.9499 -> 1.9601  accuracy: 35.54% -> 35.54%     
client [58] (testset)   loss: 1.7217 -> 1.7323  accuracy: 31.11% -> 31.11%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 2.1404 -> 2.1522  accuracy: 21.98% -> 21.98%     
client [76] (testset)   loss: 2.1287 -> 2.1250  accuracy: 20.39% -> 20.39%     
client [67] (testset)   loss: 2.0006 -> 2.0553  accuracy: 19.27% -> 14.68%     
client [37] (testset)   loss: 2.2697 -> 2.2783  accuracy: 13.01% -> 13.01%     
client [58] (testset)   loss: 1.7217 -> 1.7227  accuracy: 31.11% -> 31.11%     
client [64] (testset)   loss: 2.1283 -> 2.1236  accuracy: 15.87% -> 15.87%     
client [77] (testset)   loss: 2.0559 -> 2.0722  accuracy: 24.84% -> 24.84%     
client [55] (testset)   loss: 2.0831 -> 2.1078  accuracy: 13.92% -> 13.92%     
client [12] (testset)   loss: 2.2139 -> 2.2238  accuracy: 27.27% -> 27.27%     
client [89] (testset)   loss: 2.0152 -> 2.0079  accuracy: 21.60% -> 21.60%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 2.1881 -> 2.1874  accuracy: 21.93% -> 21.93%     
client [51] (testset)   loss: 2.0131 -> 2.0259  accuracy: 36.19% -> 36.19%     
client [8]  (testset)   loss: 1.8543 -> 1.8675  accuracy: 46.10% -> 46.10%     
client [18] (testset)   loss: 1.6135 -> 1.6180  accuracy: 32.46% -> 32.46%     
client [94] (testset)   loss: 1.8819 -> 1.8965  accuracy: 38.84% -> 38.84%     
client [81] (testset)   loss: 2.1876 -> 2.2067  accuracy: 20.83% -> 20.83%     
client [3]  (testset)   loss: 1.4172 -> 1.4202  accuracy: 62.66% -> 62.66%     
client [11] (testset)   loss: 2.0145 -> 2.0126  accuracy: 36.28% -> 36.28%     
client [95] (testset)   loss: 2.1841 -> 2.1815  accuracy: 12.84% -> 12.84%     
client [67] (testset)   loss: 2.0089 -> 2.0400  accuracy: 14.68% -> 19.27%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 1.9956 -> 1.9897  accuracy: 27.10% -> 27.10%     
client [79] (testset)   loss: 2.0262 -> 2.0363  accuracy: 21.78% -> 21.78%     
client [58] (testset)   loss: 1.7229 -> 1.7374  accuracy: 31.11% -> 31.11%     
client [88] (testset)   loss: 1.8748 -> 1.8783  accuracy: 41.42% -> 41.42%     
client [46] (testset)   loss: 1.9573 -> 1.9516  accuracy: 30.39% -> 30.39%     
client [11] (testset)   loss: 2.0128 -> 2.0245  accuracy: 36.28% -> 36.28%     
client [55] (testset)   loss: 2.0973 -> 2.0962  accuracy: 13.92% -> 17.72%     
client [13] (testset)   loss: 2.1444 -> 2.1306  accuracy: 19.30% -> 19.30%     
client [31] (testset)   loss: 2.1707 -> 2.1752  accuracy: 18.56% -> 18.56%     
client [75] (testset)   loss: 1.7876 -> 1.7721  accuracy: 22.62% -> 22.62%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 2.0690 -> 2.1114  accuracy: 34.16% -> 34.16%     
client [7]  (testset)   loss: 1.8484 -> 1.8506  accuracy: 41.94% -> 41.94%     
client [57] (testset)   loss: 2.2298 -> 2.2273  accuracy: 19.75% -> 19.75%     
client [13] (testset)   loss: 2.1356 -> 2.1289  accuracy: 19.30% -> 19.30%     
client [43] (testset)   loss: 2.1524 -> 2.1480  accuracy: 24.17% -> 24.17%     
client [91] (testset)   loss: 2.2581 -> 2.2562  accuracy: 13.10% -> 16.67%     
client [10] (testset)   loss: 1.8145 -> 1.8304  accuracy: 36.94% -> 36.94%     
client [64] (testset)   loss: 2.1200 -> 2.1210  accuracy: 15.87% -> 15.87%     
client [82] (testset)   loss: 1.8345 -> 1.8376  accuracy: 38.26% -> 38.26%     
client [22] (testset)   loss: 2.0831 -> 2.0786  accuracy: 30.86% -> 30.86%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 1.9776 -> 1.9861  accuracy: 32.42% -> 32.42%     
client [23] (testset)   loss: 2.0331 -> 2.0323  accuracy: 24.23% -> 24.23%     
client [88] (testset)   loss: 1.8663 -> 1.8798  accuracy: 41.42% -> 41.42%     
client [98] (testset)   loss: 2.1376 -> 2.1642  accuracy: 28.74% -> 28.74%     
client [79] (testset)   loss: 2.0360 -> 2.0382  accuracy: 21.78% -> 21.78%     
client [21] (testset)   loss: 1.9992 -> 1.9951  accuracy: 27.10% -> 27.10%     
client [92] (testset)   loss: 2.1026 -> 2.1150  accuracy: 21.49% -> 21.49%     
client [56] (testset)   loss: 1.9135 -> 1.9047  accuracy: 32.58% -> 32.58%     
client [5]  (testset)   loss: 1.6138 -> 1.7042  accuracy: 51.79% -> 51.79%     
client [52] (testset)   loss: 1.8941 -> 1.8950  accuracy: 28.38% -> 28.38%     
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 2.0037 -> 2.0039  accuracy: 19.27% -> 19.27%     
client [54] (testset)   loss: 2.0295 -> 2.0294  accuracy: 20.00% -> 20.00%     
client [14] (testset)   loss: 1.9618 -> 1.9632  accuracy: 35.56% -> 35.56%     
client [99] (testset)   loss: 1.9848 -> 1.9893  accuracy: 32.79% -> 32.79%     
client [36] (testset)   loss: 1.8420 -> 1.8276  accuracy: 36.54% -> 36.54%     
client [30] (testset)   loss: 1.7921 -> 1.7977  accuracy: 32.47% -> 32.47%     
client [38] (testset)   loss: 1.9290 -> 1.9240  accuracy: 39.31% -> 39.31%     
client [15] (testset)   loss: 1.9458 -> 1.9469  accuracy: 35.54% -> 35.54%     
client [6]  (testset)   loss: 2.0685 -> 2.0767  accuracy: 24.72% -> 24.72%     
client [53] (testset)   loss: 1.8616 -> 1.8701  accuracy: 32.41% -> 32.41%     
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [99] (testset)   loss: 1.9808 -> 1.9772  accuracy: 32.79% -> 32.79%     
client [6]  (testset)   loss: 2.0675 -> 2.0754  accuracy: 24.72% -> 24.72%     
client [83] (testset)   loss: 1.7718 -> 1.7701  accuracy: 30.82% -> 30.82%     
client [42] (testset)   loss: 2.0686 -> 2.0674  accuracy: 20.95% -> 20.95%     
client [34] (testset)   loss: 1.9871 -> 1.9803  accuracy: 32.74% -> 32.74%     
client [15] (testset)   loss: 1.9441 -> 1.9630  accuracy: 35.54% -> 35.54%     
client [47] (testset)   loss: 1.7538 -> 1.7489  accuracy: 27.97% -> 27.97%     
client [55] (testset)   loss: 2.0916 -> 2.0955  accuracy: 13.92% -> 13.92%     
client [51] (testset)   loss: 2.0125 -> 2.0180  accuracy: 36.19% -> 36.19%     
client [95] (testset)   loss: 2.1783 -> 2.1864  accuracy: 12.84% -> 12.84%     
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 1.7387 -> 1.7418  accuracy: 40.35% -> 40.35%     
client [15] (testset)   loss: 1.9495 -> 1.9538  accuracy: 35.54% -> 35.54%     
client [33] (testset)   loss: 2.1254 -> 2.1241  accuracy: 28.82% -> 28.82%     
client [99] (testset)   loss: 1.9748 -> 1.9761  accuracy: 32.79% -> 32.79%     
client [90] (testset)   loss: 1.8029 -> 1.7946  accuracy: 30.90% -> 30.90%     
client [57] (testset)   loss: 2.2259 -> 2.2292  accuracy: 19.75% -> 19.75%     
client [27] (testset)   loss: 1.9571 -> 1.9566  accuracy: 30.83% -> 30.83%     
client [78] (testset)   loss: 2.0535 -> 2.0706  accuracy: 26.23% -> 26.23%     
client [36] (testset)   loss: 1.8401 -> 1.8346  accuracy: 36.54% -> 36.54%     
client [88] (testset)   loss: 1.8763 -> 1.8685  accuracy: 41.42% -> 41.42%     
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 1.7807 -> 1.7761  accuracy: 30.17% -> 30.17%     
client [35] (testset)   loss: 2.0374 -> 2.0384  accuracy: 23.33% -> 23.33%     
client [16] (testset)   loss: 1.3969 -> 1.3983  accuracy: 59.84% -> 59.84%     
client [80] (testset)   loss: 1.9992 -> 1.9973  accuracy: 35.71% -> 35.71%     
client [38] (testset)   loss: 1.9236 -> 1.9217  accuracy: 39.31% -> 39.31%     
client [78] (testset)   loss: 2.0591 -> 2.0581  accuracy: 26.23% -> 26.23%     
client [68] (testset)   loss: 2.0678 -> 2.0781  accuracy: 16.80% -> 16.80%     
client [11] (testset)   loss: 2.0130 -> 2.0119  accuracy: 36.28% -> 36.28%     
client [64] (testset)   loss: 2.1202 -> 2.1208  accuracy: 15.87% -> 15.87%     
client [82] (testset)   loss: 1.8348 -> 1.8362  accuracy: 38.26% -> 38.26%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 1.7898 -> 1.7940  accuracy: 32.47% -> 30.52%     
client [27] (testset)   loss: 1.9619 -> 1.9562  accuracy: 30.83% -> 30.83%     
client [74] (testset)   loss: 2.1431 -> 2.1428  accuracy: 27.37% -> 27.37%     
client [45] (testset)   loss: 1.8682 -> 1.8811  accuracy: 33.57% -> 33.57%     
client [6]  (testset)   loss: 2.0689 -> 2.0698  accuracy: 24.72% -> 24.72%     
client [36] (testset)   loss: 1.8376 -> 1.8369  accuracy: 36.54% -> 36.54%     
client [63] (testset)   loss: 2.0444 -> 2.0355  accuracy: 14.84% -> 14.84%     
client [76] (testset)   loss: 2.1289 -> 2.1302  accuracy: 20.39% -> 20.39%     
client [83] (testset)   loss: 1.7722 -> 1.7683  accuracy: 30.82% -> 30.82%     
client [86] (testset)   loss: 2.0000 -> 1.9956  accuracy: 22.62% -> 22.62%     
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 1.7698 -> 1.7679  accuracy: 30.82% -> 30.82%     
client [99] (testset)   loss: 1.9726 -> 1.9819  accuracy: 32.79% -> 32.79%     
client [74] (testset)   loss: 2.1406 -> 2.1398  accuracy: 27.37% -> 27.37%     
client [73] (testset)   loss: 1.8479 -> 1.8553  accuracy: 27.18% -> 27.18%     
client [29] (testset)   loss: 2.2959 -> 2.2959  accuracy: 24.04% -> 24.04%     
client [92] (testset)   loss: 2.1013 -> 2.1051  accuracy: 19.83% -> 21.49%     
client [6]  (testset)   loss: 2.0713 -> 2.0705  accuracy: 24.72% -> 24.72%     
client [61] (testset)   loss: 1.9896 -> 1.9959  accuracy: 15.08% -> 15.08%     
client [21] (testset)   loss: 1.9929 -> 1.9957  accuracy: 27.10% -> 27.10%     
client [67] (testset)   loss: 2.0021 -> 2.0141  accuracy: 19.27% -> 19.27%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 1.7696 -> 1.7683  accuracy: 30.82% -> 30.82%     
client [32] (testset)   loss: 1.9678 -> 1.9644  accuracy: 26.51% -> 26.51%     
client [95] (testset)   loss: 2.1790 -> 2.1855  accuracy: 12.84% -> 12.84%     
client [61] (testset)   loss: 1.9801 -> 1.9842  accuracy: 31.75% -> 15.08%     
client [27] (testset)   loss: 1.9598 -> 1.9526  accuracy: 30.83% -> 30.83%     
client [25] (testset)   loss: 1.8268 -> 1.8451  accuracy: 40.30% -> 40.30%     
client [68] (testset)   loss: 2.0684 -> 2.0801  accuracy: 23.20% -> 23.20%     
client [34] (testset)   loss: 1.9982 -> 2.0049  accuracy: 32.74% -> 32.74%     
client [71] (testset)   loss: 1.7310 -> 1.7330  accuracy: 40.35% -> 40.35%     
client [89] (testset)   loss: 2.0101 -> 1.9934  accuracy: 23.46% -> 23.46%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 2.0580 -> 2.0665  accuracy: 26.23% -> 26.23%     
client [81] (testset)   loss: 2.2144 -> 2.2230  accuracy: 20.83% -> 20.83%     
client [51] (testset)   loss: 2.0115 -> 2.0223  accuracy: 36.19% -> 36.19%     
client [54] (testset)   loss: 2.0364 -> 2.0295  accuracy: 20.00% -> 20.00%     
client [65] (testset)   loss: 1.9722 -> 1.9770  accuracy: 28.26% -> 28.26%     
client [41] (testset)   loss: 1.8818 -> 1.8838  accuracy: 44.25% -> 44.25%     
client [11] (testset)   loss: 2.0128 -> 2.0145  accuracy: 36.28% -> 36.28%     
client [85] (testset)   loss: 2.0910 -> 2.0935  accuracy: 27.76% -> 27.76%     
client [12] (testset)   loss: 2.2070 -> 2.2272  accuracy: 27.27% -> 27.27%     
client [23] (testset)   loss: 2.0341 -> 2.0415  accuracy: 24.23% -> 16.54%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 1.4027 -> 1.3991  accuracy: 59.84% -> 59.84%     
client [65] (testset)   loss: 1.9755 -> 1.9728  accuracy: 28.26% -> 28.26%     
client [53] (testset)   loss: 1.8463 -> 1.8552  accuracy: 32.41% -> 32.41%     
client [58] (testset)   loss: 1.7283 -> 1.7245  accuracy: 31.11% -> 31.11%     
client [72] (testset)   loss: 2.0930 -> 2.0959  accuracy: 26.63% -> 26.63%     
client [7]  (testset)   loss: 1.8533 -> 1.8437  accuracy: 41.94% -> 41.94%     
client [71] (testset)   loss: 1.7394 -> 1.7356  accuracy: 40.35% -> 40.35%     
client [59] (testset)   loss: 2.0521 -> 2.0537  accuracy: 24.49% -> 24.49%     
client [86] (testset)   loss: 1.9998 -> 1.9958  accuracy: 22.62% -> 22.62%     
client [39] (testset)   loss: 1.9878 -> 1.9886  accuracy: 20.12% -> 19.53%     
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 1.9823 -> 1.9772  accuracy: 32.79% -> 32.79%     
client [7]  (testset)   loss: 1.8408 -> 1.8398  accuracy: 41.94% -> 41.94%     
client [17] (testset)   loss: 2.1125 -> 2.1046  accuracy: 20.00% -> 23.08%     
client [64] (testset)   loss: 2.1189 -> 2.1190  accuracy: 15.87% -> 15.87%     
client [37] (testset)   loss: 2.2681 -> 2.2713  accuracy: 13.01% -> 13.01%     
client [29] (testset)   loss: 2.3043 -> 2.2893  accuracy: 24.04% -> 24.04%     
client [93] (testset)   loss: 1.2065 -> 1.1958  accuracy: 69.57% -> 69.57%     
client [73] (testset)   loss: 1.8472 -> 1.8549  accuracy: 27.18% -> 27.18%     
client [40] (testset)   loss: 1.8647 -> 1.8496  accuracy: 31.25% -> 31.25%     
client [76] (testset)   loss: 2.1280 -> 2.1313  accuracy: 20.39% -> 20.39%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 2.1775 -> 2.1746  accuracy: 18.56% -> 18.56%     
client [89] (testset)   loss: 2.0145 -> 2.0135  accuracy: 23.46% -> 21.60%     
client [77] (testset)   loss: 2.0559 -> 2.0571  accuracy: 24.84% -> 24.84%     
client [90] (testset)   loss: 1.7915 -> 1.7925  accuracy: 30.90% -> 30.90%     
client [26] (testset)   loss: 1.4707 -> 1.4703  accuracy: 54.98% -> 54.98%     
client [50] (testset)   loss: 2.1274 -> 2.1317  accuracy: 23.08% -> 23.08%     
client [30] (testset)   loss: 1.7922 -> 1.7922  accuracy: 32.47% -> 32.47%     
client [70] (testset)   loss: 1.7800 -> 1.7836  accuracy: 30.17% -> 30.17%     
client [41] (testset)   loss: 1.8786 -> 1.8774  accuracy: 44.25% -> 44.25%     
client [99] (testset)   loss: 1.9788 -> 1.9781  accuracy: 32.79% -> 32.79%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [68] (testset)   loss: 2.0640 -> 2.0642  accuracy: 23.20% -> 16.80%     
client [70] (testset)   loss: 1.7921 -> 1.7741  accuracy: 30.17% -> 30.17%     
client [52] (testset)   loss: 1.8862 -> 1.8929  accuracy: 28.38% -> 28.38%     
client [1]  (testset)   loss: 2.0432 -> 2.0344  accuracy: 16.13% -> 16.13%     
client [2]  (testset)   loss: 1.9450 -> 1.9466  accuracy: 33.85% -> 33.85%     
client [67] (testset)   loss: 1.9955 -> 2.0320  accuracy: 19.27% -> 19.27%     
client [92] (testset)   loss: 2.1056 -> 2.1032  accuracy: 19.83% -> 21.49%     
client [35] (testset)   loss: 2.0419 -> 2.0392  accuracy: 23.33% -> 23.33%     
client [36] (testset)   loss: 1.8363 -> 1.8403  accuracy: 36.54% -> 36.54%     
client [64] (testset)   loss: 2.1227 -> 2.1211  accuracy: 15.87% -> 15.87%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 2.0648 -> 2.0656  accuracy: 28.38% -> 28.38%     
client [6]  (testset)   loss: 2.0703 -> 2.0696  accuracy: 24.72% -> 24.72%     
client [12] (testset)   loss: 2.2197 -> 2.2142  accuracy: 27.27% -> 27.27%     
client [55] (testset)   loss: 2.0902 -> 2.0906  accuracy: 13.92% -> 13.92%     
client [29] (testset)   loss: 2.2980 -> 2.3203  accuracy: 24.04% -> 24.04%     
client [9]  (testset)   loss: 2.0946 -> 2.0923  accuracy: 31.11% -> 31.11%     
client [43] (testset)   loss: 2.1486 -> 2.1463  accuracy: 24.17% -> 24.17%     
client [77] (testset)   loss: 2.0553 -> 2.0550  accuracy: 24.84% -> 24.84%     
client [98] (testset)   loss: 2.1473 -> 2.1402  accuracy: 28.74% -> 28.74%     
client [78] (testset)   loss: 2.0671 -> 2.0665  accuracy: 26.23% -> 26.23%     
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 2.1084 -> 2.1151  accuracy: 21.49% -> 19.83%     
client [80] (testset)   loss: 2.0077 -> 2.0055  accuracy: 35.71% -> 35.71%     
client [63] (testset)   loss: 2.0383 -> 2.0301  accuracy: 14.84% -> 14.84%     
client [76] (testset)   loss: 2.1303 -> 2.1378  accuracy: 20.39% -> 20.39%     
client [78] (testset)   loss: 2.0635 -> 2.0693  accuracy: 26.23% -> 26.23%     
client [25] (testset)   loss: 1.8302 -> 1.8335  accuracy: 40.30% -> 40.30%     
client [58] (testset)   loss: 1.7231 -> 1.7246  accuracy: 31.11% -> 31.11%     
client [13] (testset)   loss: 2.1328 -> 2.1337  accuracy: 19.30% -> 19.30%     
client [17] (testset)   loss: 2.1000 -> 2.0992  accuracy: 20.00% -> 20.00%     
client [38] (testset)   loss: 1.9235 -> 1.9481  accuracy: 39.31% -> 39.31%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 2.0924 -> 2.0966  accuracy: 26.63% -> 26.63%     
client [82] (testset)   loss: 1.8352 -> 1.8337  accuracy: 38.26% -> 38.26%     
client [86] (testset)   loss: 1.9966 -> 1.9955  accuracy: 22.62% -> 22.62%     
client [51] (testset)   loss: 2.0129 -> 2.0316  accuracy: 36.19% -> 36.19%     
client [96] (testset)   loss: 2.0235 -> 2.0203  accuracy: 22.41% -> 22.41%     
client [42] (testset)   loss: 2.0674 -> 2.0676  accuracy: 20.95% -> 20.95%     
client [55] (testset)   loss: 2.0893 -> 2.0952  accuracy: 13.92% -> 13.92%     
client [13] (testset)   loss: 2.1420 -> 2.1258  accuracy: 19.30% -> 19.30%     
client [1]  (testset)   loss: 2.0382 -> 2.0353  accuracy: 16.13% -> 16.13%     
client [12] (testset)   loss: 2.2130 -> 2.2373  accuracy: 27.27% -> 27.27%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 2.0684 -> 2.0690  accuracy: 16.80% -> 23.20%     
client [23] (testset)   loss: 2.0349 -> 2.0421  accuracy: 24.23% -> 16.54%     
client [46] (testset)   loss: 1.9546 -> 1.9540  accuracy: 30.39% -> 30.39%     
client [41] (testset)   loss: 1.8753 -> 1.8767  accuracy: 44.25% -> 44.25%     
client [25] (testset)   loss: 1.8277 -> 1.8334  accuracy: 40.30% -> 40.30%     
client [58] (testset)   loss: 1.7243 -> 1.7298  accuracy: 31.11% -> 31.11%     
client [14] (testset)   loss: 1.9569 -> 1.9579  accuracy: 35.56% -> 35.56%     
client [33] (testset)   loss: 2.1208 -> 2.1213  accuracy: 28.82% -> 28.82%     
client [85] (testset)   loss: 2.0919 -> 2.0931  accuracy: 27.76% -> 27.76%     
client [62] (testset)   loss: 2.0375 -> 2.0469  accuracy: 33.83% -> 33.83%     
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 2.1438 -> 2.1322  accuracy: 28.74% -> 28.74%     
client [63] (testset)   loss: 2.0390 -> 2.0322  accuracy: 14.84% -> 14.84%     
client [70] (testset)   loss: 1.7841 -> 1.7818  accuracy: 30.17% -> 30.17%     
client [65] (testset)   loss: 1.9740 -> 1.9755  accuracy: 28.26% -> 28.26%     
client [14] (testset)   loss: 1.9513 -> 1.9611  accuracy: 35.56% -> 35.56%     
client [73] (testset)   loss: 1.8478 -> 1.8589  accuracy: 27.18% -> 27.18%     
client [34] (testset)   loss: 1.9889 -> 2.0106  accuracy: 32.74% -> 32.74%     
client [99] (testset)   loss: 1.9770 -> 1.9735  accuracy: 32.79% -> 32.79%     
client [69] (testset)   loss: 1.9171 -> 1.9233  accuracy: 25.64% -> 25.64%     
client [46] (testset)   loss: 1.9540 -> 1.9560  accuracy: 30.39% -> 30.39%     
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [99] (testset)   loss: 1.9728 -> 1.9768  accuracy: 32.79% -> 32.79%     
client [93] (testset)   loss: 1.2395 -> 1.2506  accuracy: 69.57% -> 69.57%     
client [11] (testset)   loss: 2.0112 -> 2.0147  accuracy: 36.28% -> 36.28%     
client [58] (testset)   loss: 1.7262 -> 1.7278  accuracy: 31.11% -> 31.11%     
client [81] (testset)   loss: 2.2038 -> 2.1923  accuracy: 20.83% -> 20.83%     
client [85] (testset)   loss: 2.0917 -> 2.0906  accuracy: 27.76% -> 27.76%     
client [89] (testset)   loss: 2.0001 -> 2.0413  accuracy: 21.60% -> 23.46%     
client [45] (testset)   loss: 1.8667 -> 1.8719  accuracy: 33.57% -> 33.57%     
client [8]  (testset)   loss: 1.8473 -> 1.8548  accuracy: 46.10% -> 46.10%     
client [68] (testset)   loss: 2.0697 -> 2.0719  accuracy: 23.20% -> 23.20%     
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 2.0054 -> 2.0243  accuracy: 19.27% -> 19.27%     
client [72] (testset)   loss: 2.0934 -> 2.1044  accuracy: 26.63% -> 26.63%     
client [1]  (testset)   loss: 2.0382 -> 2.0375  accuracy: 16.13% -> 16.13%     
client [78] (testset)   loss: 2.0667 -> 2.0677  accuracy: 26.23% -> 26.23%     
client [83] (testset)   loss: 1.7686 -> 1.7674  accuracy: 30.82% -> 30.82%     
client [21] (testset)   loss: 1.9929 -> 1.9903  accuracy: 27.10% -> 27.10%     
client [56] (testset)   loss: 1.9139 -> 1.9077  accuracy: 32.58% -> 32.58%     
client [44] (testset)   loss: 2.0658 -> 2.0713  accuracy: 28.38% -> 28.38%     
client [92] (testset)   loss: 2.1043 -> 2.1020  accuracy: 21.49% -> 21.49%     
client [27] (testset)   loss: 1.9672 -> 1.9637  accuracy: 30.83% -> 30.83%     
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 1.8240 -> 1.8117  accuracy: 36.94% -> 36.94%     
client [39] (testset)   loss: 1.9892 -> 1.9880  accuracy: 20.12% -> 20.12%     
client [65] (testset)   loss: 1.9728 -> 1.9772  accuracy: 28.26% -> 28.26%     
client [26] (testset)   loss: 1.4750 -> 1.4739  accuracy: 54.98% -> 54.98%     
client [19] (testset)   loss: 2.0584 -> 2.0578  accuracy: 34.16% -> 34.16%     
client [68] (testset)   loss: 2.0698 -> 2.0776  accuracy: 23.20% -> 16.80%     
client [41] (testset)   loss: 1.8744 -> 1.8813  accuracy: 44.25% -> 44.25%     
client [50] (testset)   loss: 2.1308 -> 2.1287  accuracy: 23.08% -> 23.08%     
client [75] (testset)   loss: 1.7872 -> 1.7698  accuracy: 22.62% -> 22.62%     
client [81] (testset)   loss: 2.2248 -> 2.2130  accuracy: 20.83% -> 20.83%     
Training... ---------------------------------------- 100% 0:15:39
FedPer's average time taken by each global epoch: 0 min 2.33 sec.              
FedPer's total running time: 0 h 15 m 39 s.                                    
==================== FedPer Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9511 -> 0.0000",                                    
                "accuracy": "30.46% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9497 -> 0.0000",                                    
                "accuracy": "30.55% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9477 -> 0.0000",                                    
                "accuracy": "30.58% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9480 -> 0.0000",                                    
                "accuracy": "30.48% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedPer Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 30.58% at epoch 300                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
[0m