==================== SFL ====================                                  
Experiment Arguments:                                                          
{
â”‚   'method': 'sfl',
â”‚   'dataset': {
â”‚   â”‚   'name': 'medmnistA',
â”‚   â”‚   'client_num': 100,
â”‚   â”‚   'test_ratio': 0.25,
â”‚   â”‚   'val_ratio': 0.0,
â”‚   â”‚   'seed': 42,
â”‚   â”‚   'split': 'sample',
â”‚   â”‚   'IID_ratio': 0.0,
â”‚   â”‚   'monitor_window_name_suffix': 'medmnistA-100clients-0%IID-Dir(1.0)-seed42',
â”‚   â”‚   'alpha': 1.0,
â”‚   â”‚   'min_samples_per_client': 10
â”‚   },
â”‚   'model': {
â”‚   â”‚   'name': 'lenet5',
â”‚   â”‚   'use_torchvision_pretrained_weights': True,
â”‚   â”‚   'external_model_weights_path': None
â”‚   },
â”‚   'optimizer': {
â”‚   â”‚   'lr': 0.01,
â”‚   â”‚   'dampening': 0,
â”‚   â”‚   'weight_decay': 0,
â”‚   â”‚   'momentum': 0,
â”‚   â”‚   'nesterov': False,
â”‚   â”‚   'name': 'sgd'
â”‚   },
â”‚   'mode': 'sequential',
â”‚   'parallel': {
â”‚   â”‚   'ray_cluster_addr': None,
â”‚   â”‚   'num_cpus': None,
â”‚   â”‚   'num_gpus': None,
â”‚   â”‚   'num_workers': 2
â”‚   },
â”‚   'common': {
â”‚   â”‚   'seed': 42,
â”‚   â”‚   'join_ratio': 0.1,
â”‚   â”‚   'global_epoch': 400,
â”‚   â”‚   'local_epoch': 5,
â”‚   â”‚   'batch_size': 32,
â”‚   â”‚   'reset_optimizer_on_global_epoch': True,
â”‚   â”‚   'straggler_ratio': 0,
â”‚   â”‚   'straggler_min_local_epoch': 0,
â”‚   â”‚   'buffers': 'global',
â”‚   â”‚   'client_side_evaluation': True,
â”‚   â”‚   'test': {
â”‚   â”‚   â”‚   'client': {
â”‚   â”‚   â”‚   â”‚   'interval': 100,
â”‚   â”‚   â”‚   â”‚   'finetune_epoch': 0,
â”‚   â”‚   â”‚   â”‚   'train': False,
â”‚   â”‚   â”‚   â”‚   'val': False,
â”‚   â”‚   â”‚   â”‚   'test': True
â”‚   â”‚   â”‚   },
â”‚   â”‚   â”‚   'server': {
â”‚   â”‚   â”‚   â”‚   'interval': -1,
â”‚   â”‚   â”‚   â”‚   'train': False,
â”‚   â”‚   â”‚   â”‚   'val': False,
â”‚   â”‚   â”‚   â”‚   'test': False,
â”‚   â”‚   â”‚   â”‚   'model_in_train_mode': False
â”‚   â”‚   â”‚   }
â”‚   â”‚   },
â”‚   â”‚   'verbose_gap': 10,
â”‚   â”‚   'monitor': None,
â”‚   â”‚   'use_cuda': True,
â”‚   â”‚   'save_log': True,
â”‚   â”‚   'save_model': False,
â”‚   â”‚   'save_learning_curve_plot': False,
â”‚   â”‚   'save_metrics': True,
â”‚   â”‚   'delete_useless_run': True
â”‚   }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 2.5077 -> 2.1223  accuracy: 7.19% -> 24.84%      
client [81] (testset)   loss: 2.7718 -> 2.4092  accuracy: 9.38% -> 9.38%       
client [21] (testset)   loss: 2.4747 -> 2.2669  accuracy: 3.87% -> 21.94%      
client [68] (testset)   loss: 2.5473 -> 2.3566  accuracy: 0.80% -> 16.80%      
client [93] (testset)   loss: 2.2179 -> 1.2004  accuracy: 69.57% -> 69.57%     
client [31] (testset)   loss: 3.6592 -> 2.3685  accuracy: 4.12% -> 4.12%       
client [20] (testset)   loss: 2.3175 -> 2.0692  accuracy: 8.68% -> 32.42%      
client [59] (testset)   loss: 2.3892 -> 2.0583  accuracy: 16.33% -> 24.49%     
client [48] (testset)   loss: 2.5036 -> 2.1738  accuracy: 21.98% -> 21.98%     
client [34] (testset)   loss: 2.2207 -> 2.0051  accuracy: 17.08% -> 32.74%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 2.8359 -> 1.9669  accuracy: 0.64% -> 25.64%      
client [99] (testset)   loss: 2.5212 -> 1.9961  accuracy: 2.46% -> 32.79%      
client [67] (testset)   loss: 2.5408 -> 2.1200  accuracy: 20.18% -> 19.27%     
client [0]  (testset)   loss: 2.8321 -> 2.1009  accuracy: 5.76% -> 17.28%      
client [76] (testset)   loss: 3.0521 -> 2.2216  accuracy: 11.84% -> 20.39%     
client [41] (testset)   loss: 3.0220 -> 1.9187  accuracy: 2.65% -> 44.25%      
client [62] (testset)   loss: 3.0030 -> 2.0389  accuracy: 3.35% -> 33.83%      
client [2]  (testset)   loss: 2.3861 -> 1.9675  accuracy: 8.33% -> 33.85%      
client [14] (testset)   loss: 2.5662 -> 2.0429  accuracy: 1.48% -> 35.56%      
client [46] (testset)   loss: 2.2818 -> 1.9831  accuracy: 30.39% -> 30.39%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 1.7465 -> 1.7341  accuracy: 39.88% -> 39.88%     
client [68] (testset)   loss: 2.7206 -> 2.0926  accuracy: 20.00% -> 16.80%     
client [57] (testset)   loss: 2.7127 -> 2.2905  accuracy: 11.11% -> 19.75%     
client [17] (testset)   loss: 2.2892 -> 2.0986  accuracy: 10.77% -> 20.00%     
client [54] (testset)   loss: 2.7539 -> 2.1247  accuracy: 20.00% -> 20.00%     
client [23] (testset)   loss: 2.5556 -> 2.0764  accuracy: 8.08% -> 24.23%      
client [35] (testset)   loss: 2.4644 -> 2.0559  accuracy: 17.78% -> 23.33%     
client [59] (testset)   loss: 3.0577 -> 2.1357  accuracy: 8.84% -> 24.49%      
client [31] (testset)   loss: 2.5203 -> 2.2345  accuracy: 15.46% -> 15.46%     
client [9]  (testset)   loss: 2.3615 -> 2.0984  accuracy: 6.67% -> 31.11%      
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 2.2724 -> 2.2273  accuracy: 11.11% -> 11.11%     
client [33] (testset)   loss: 2.3022 -> 2.1092  accuracy: 5.29% -> 28.82%      
client [16] (testset)   loss: 2.5407 -> 1.4379  accuracy: 16.54% -> 59.84%     
client [44] (testset)   loss: 2.8054 -> 2.1315  accuracy: 28.38% -> 28.38%     
client [8]  (testset)   loss: 2.6302 -> 1.9095  accuracy: 0.71% -> 46.10%      
client [31] (testset)   loss: 2.8031 -> 2.3382  accuracy: 0.00% -> 18.56%      
client [47] (testset)   loss: 2.1828 -> 1.7723  accuracy: 27.97% -> 27.97%     
client [36] (testset)   loss: 3.1492 -> 1.8173  accuracy: 5.77% -> 36.54%      
client [20] (testset)   loss: 2.9629 -> 2.0233  accuracy: 3.65% -> 32.42%      
client [56] (testset)   loss: 2.3455 -> 1.9510  accuracy: 2.25% -> 32.58%      
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 2.2289 -> 1.9485  accuracy: 14.91% -> 32.92%     
client [60] (testset)   loss: 2.1509 -> 1.9341  accuracy: 25.77% -> 28.35%     
client [28] (testset)   loss: 3.3097 -> 2.4768  accuracy: 2.65% -> 2.65%       
client [25] (testset)   loss: 2.1642 -> 1.8845  accuracy: 40.30% -> 40.30%     
client [58] (testset)   loss: 2.8010 -> 1.7556  accuracy: 1.11% -> 31.11%      
client [44] (testset)   loss: 3.0993 -> 2.1256  accuracy: 2.03% -> 28.38%      
client [39] (testset)   loss: 2.4762 -> 1.9735  accuracy: 10.65% -> 20.12%     
client [29] (testset)   loss: 2.8842 -> 2.3483  accuracy: 3.85% -> 24.04%      
client [3]  (testset)   loss: 2.5053 -> 1.4678  accuracy: 2.53% -> 62.66%      
client [84] (testset)   loss: 2.7717 -> 2.1896  accuracy: 21.93% -> 21.93%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 2.7311 -> 2.0121  accuracy: 3.87% -> 27.10%      
client [84] (testset)   loss: 2.5847 -> 2.1582  accuracy: 13.16% -> 21.93%     
client [10] (testset)   loss: 2.6239 -> 1.9038  accuracy: 2.70% -> 36.94%      
client [36] (testset)   loss: 2.5776 -> 1.8377  accuracy: 5.77% -> 36.54%      
client [65] (testset)   loss: 3.1998 -> 1.9654  accuracy: 6.52% -> 28.26%      
client [81] (testset)   loss: 3.0822 -> 2.2352  accuracy: 5.21% -> 20.83%      
client [79] (testset)   loss: 2.8840 -> 2.2243  accuracy: 6.93% -> 21.78%      
client [42] (testset)   loss: 2.3311 -> 2.2130  accuracy: 14.19% -> 21.62%     
client [11] (testset)   loss: 2.3619 -> 2.0690  accuracy: 36.28% -> 36.28%     
client [96] (testset)   loss: 2.6821 -> 2.1520  accuracy: 13.79% -> 22.41%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 2.4593 -> 1.9446  accuracy: 7.09% -> 46.10%      
client [53] (testset)   loss: 2.9610 -> 1.9869  accuracy: 2.78% -> 28.70%      
client [52] (testset)   loss: 2.0974 -> 1.8972  accuracy: 19.21% -> 28.38%     
client [42] (testset)   loss: 2.7636 -> 2.1201  accuracy: 21.62% -> 21.62%     
client [69] (testset)   loss: 2.0612 -> 1.9304  accuracy: 25.64% -> 25.64%     
client [59] (testset)   loss: 3.2814 -> 2.2166  accuracy: 0.00% -> 24.49%      
client [7]  (testset)   loss: 2.3343 -> 1.9070  accuracy: 6.99% -> 41.94%      
client [26] (testset)   loss: 1.7498 -> 1.4769  accuracy: 54.98% -> 54.98%     
client [49] (testset)   loss: 2.1924 -> 1.7295  accuracy: 48.28% -> 48.28%     
client [98] (testset)   loss: 2.7970 -> 2.1435  accuracy: 3.45% -> 28.74%      
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 2.5353 -> 2.2056  accuracy: 3.45% -> 28.74%      
client [47] (testset)   loss: 2.7603 -> 1.7557  accuracy: 2.10% -> 27.97%      
client [21] (testset)   loss: 3.6597 -> 2.2247  accuracy: 3.87% -> 27.10%      
client [77] (testset)   loss: 2.3515 -> 2.0815  accuracy: 2.61% -> 24.84%      
client [95] (testset)   loss: 2.7666 -> 2.3178  accuracy: 9.17% -> 12.84%      
client [91] (testset)   loss: 2.5092 -> 2.3962  accuracy: 2.38% -> 16.67%      
client [14] (testset)   loss: 2.2948 -> 2.0700  accuracy: 0.00% -> 35.56%      
client [99] (testset)   loss: 2.3635 -> 2.0450  accuracy: 12.30% -> 32.79%     
client [20] (testset)   loss: 2.3947 -> 2.0076  accuracy: 8.68% -> 32.42%      
client [39] (testset)   loss: 2.2593 -> 1.9839  accuracy: 19.53% -> 19.53%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 2.2229 -> 2.0778  accuracy: 19.21% -> 28.38%     
client [62] (testset)   loss: 2.3353 -> 2.1296  accuracy: 11.90% -> 33.83%     
client [71] (testset)   loss: 2.6869 -> 2.5091  accuracy: 0.00% -> 0.00%       
client [97] (testset)   loss: 2.2537 -> 2.1175  accuracy: 3.86% -> 21.26%      
client [30] (testset)   loss: 2.4557 -> 2.2187  accuracy: 1.30% -> 30.52%      
client [88] (testset)   loss: 2.2361 -> 2.0133  accuracy: 15.38% -> 41.42%     
client [60] (testset)   loss: 2.3319 -> 2.1072  accuracy: 1.03% -> 25.77%      
client [82] (testset)   loss: 2.3894 -> 2.1591  accuracy: 2.61% -> 38.26%      
client [91] (testset)   loss: 2.6055 -> 2.5443  accuracy: 11.90% -> 11.90%     
client [57] (testset)   loss: 2.3268 -> 2.3082  accuracy: 19.75% -> 19.75%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 2.5909 -> 2.2190  accuracy: 18.56% -> 18.56%     
client [15] (testset)   loss: 2.7079 -> 1.9668  accuracy: 19.88% -> 35.54%     
client [71] (testset)   loss: 3.6560 -> 2.0595  accuracy: 0.00% -> 40.35%      
client [97] (testset)   loss: 2.3228 -> 1.9372  accuracy: 18.36% -> 21.26%     
client [53] (testset)   loss: 2.5333 -> 1.8626  accuracy: 9.26% -> 32.41%      
client [77] (testset)   loss: 3.1930 -> 2.0986  accuracy: 2.61% -> 24.84%      
client [76] (testset)   loss: 2.5557 -> 2.2202  accuracy: 20.39% -> 20.39%     
client [79] (testset)   loss: 2.3441 -> 2.0869  accuracy: 4.95% -> 21.78%      
client [28] (testset)   loss: 2.7071 -> 2.2148  accuracy: 18.58% -> 18.58%     
client [99] (testset)   loss: 2.8366 -> 2.0361  accuracy: 4.10% -> 32.79%      
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 2.4019 -> 2.1877  accuracy: 2.90% -> 18.36%      
client [86] (testset)   loss: 2.3185 -> 2.2485  accuracy: 22.62% -> 22.62%     
client [34] (testset)   loss: 2.3029 -> 2.0809  accuracy: 17.08% -> 32.74%     
client [73] (testset)   loss: 2.0868 -> 2.0055  accuracy: 26.21% -> 26.21%     
client [5]  (testset)   loss: 2.0730 -> 1.7873  accuracy: 51.79% -> 51.79%     
client [96] (testset)   loss: 2.6671 -> 2.4139  accuracy: 6.90% -> 6.90%       
client [22] (testset)   loss: 2.5353 -> 2.4020  accuracy: 4.94% -> 4.94%       
client [60] (testset)   loss: 2.1781 -> 2.0499  accuracy: 28.35% -> 28.35%     
client [66] (testset)   loss: 2.2888 -> 2.1926  accuracy: 30.23% -> 30.23%     
client [83] (testset)   loss: 2.4886 -> 2.1726  accuracy: 2.52% -> 23.27%      
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 2.9207 -> 2.2368  accuracy: 5.92% -> 20.39%      
client [65] (testset)   loss: 2.6205 -> 2.0082  accuracy: 1.45% -> 28.26%      
client [95] (testset)   loss: 2.5985 -> 2.2546  accuracy: 12.84% -> 12.84%     
client [17] (testset)   loss: 2.5264 -> 2.2915  accuracy: 10.77% -> 20.00%     
client [8]  (testset)   loss: 2.3727 -> 1.8798  accuracy: 9.22% -> 46.10%      
client [35] (testset)   loss: 2.9786 -> 2.0534  accuracy: 9.44% -> 23.33%      
client [98] (testset)   loss: 3.3236 -> 2.2025  accuracy: 0.00% -> 28.74%      
client [53] (testset)   loss: 2.3608 -> 1.8430  accuracy: 32.41% -> 32.41%     
client [43] (testset)   loss: 2.6946 -> 2.1515  accuracy: 12.08% -> 24.17%     
client [64] (testset)   loss: 2.6284 -> 2.2182  accuracy: 7.94% -> 12.70%      
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 2.6232 -> 2.3581  accuracy: 3.87% -> 11.61%      
client [88] (testset)   loss: 2.1578 -> 1.9993  accuracy: 41.42% -> 41.42%     
client [38] (testset)   loss: 2.5818 -> 2.2627  accuracy: 8.67% -> 8.67%       
client [3]  (testset)   loss: 1.9524 -> 1.6158  accuracy: 62.66% -> 62.66%     
client [5]  (testset)   loss: 2.4812 -> 1.8181  accuracy: 6.70% -> 51.79%      
client [41] (testset)   loss: 3.2718 -> 2.7443  accuracy: 0.00% -> 0.00%       
client [7]  (testset)   loss: 2.1388 -> 2.0303  accuracy: 41.94% -> 41.94%     
client [37] (testset)   loss: 2.4485 -> 2.3858  accuracy: 19.51% -> 19.51%     
client [45] (testset)   loss: 2.1062 -> 2.0301  accuracy: 33.57% -> 33.57%     
client [47] (testset)   loss: 2.4412 -> 2.1643  accuracy: 0.70% -> 0.70%       
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 1.6745 -> 1.5875  accuracy: 59.84% -> 59.84%     
client [11] (testset)   loss: 3.0235 -> 2.4608  accuracy: 7.96% -> 7.96%       
client [37] (testset)   loss: 2.4698 -> 2.3994  accuracy: 19.51% -> 19.51%     
client [41] (testset)   loss: 3.0077 -> 2.6527  accuracy: 0.00% -> 0.00%       
client [95] (testset)   loss: 2.4182 -> 2.3577  accuracy: 1.83% -> 1.83%       
client [53] (testset)   loss: 2.2124 -> 2.0756  accuracy: 6.48% -> 32.41%      
client [22] (testset)   loss: 2.4386 -> 2.3435  accuracy: 3.70% -> 18.52%      
client [25] (testset)   loss: 2.2737 -> 2.0550  accuracy: 11.94% -> 40.30%     
client [69] (testset)   loss: 2.1683 -> 2.0660  accuracy: 30.13% -> 30.13%     
client [46] (testset)   loss: 2.3470 -> 2.2211  accuracy: 6.86% -> 6.86%       
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 2.1682 -> 2.0220  accuracy: 27.97% -> 27.97%     
client [69] (testset)   loss: 2.3853 -> 2.1856  accuracy: 14.10% -> 14.10%     
client [82] (testset)   loss: 2.2660 -> 2.0803  accuracy: 23.48% -> 23.48%     
client [45] (testset)   loss: 2.2127 -> 2.0474  accuracy: 9.09% -> 33.57%      
client [7]  (testset)   loss: 2.1984 -> 2.0666  accuracy: 41.94% -> 41.94%     
client [50] (testset)   loss: 2.5717 -> 2.4282  accuracy: 14.53% -> 14.53%     
client [35] (testset)   loss: 2.3277 -> 2.2178  accuracy: 17.78% -> 17.78%     
client [24] (testset)   loss: 2.2258 -> 1.9821  accuracy: 19.63% -> 39.88%     
client [15] (testset)   loss: 2.2533 -> 2.0958  accuracy: 4.22% -> 35.54%      
client [58] (testset)   loss: 2.5246 -> 2.0844  accuracy: 1.11% -> 31.11%      
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 2.3254 -> 2.2414  accuracy: 19.40% -> 16.38%     
client [76] (testset)   loss: 2.2841 -> 2.2502  accuracy: 20.39% -> 20.39%     
client [67] (testset)   loss: 2.2393 -> 2.1928  accuracy: 19.27% -> 19.27%     
client [37] (testset)   loss: 2.4123 -> 2.3814  accuracy: 10.57% -> 10.57%     
client [58] (testset)   loss: 2.5058 -> 2.1408  accuracy: 9.44% -> 9.44%       
client [64] (testset)   loss: 2.1701 -> 2.1641  accuracy: 22.22% -> 22.22%     
client [77] (testset)   loss: 2.3095 -> 2.2386  accuracy: 24.84% -> 24.84%     
client [55] (testset)   loss: 2.5124 -> 2.4345  accuracy: 1.27% -> 1.27%       
client [12] (testset)   loss: 2.3478 -> 2.2972  accuracy: 9.09% -> 9.09%       
client [89] (testset)   loss: 2.2833 -> 2.1618  accuracy: 4.32% -> 21.60%      
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 2.4951 -> 2.3443  accuracy: 5.26% -> 13.16%      
client [51] (testset)   loss: 2.4524 -> 2.2597  accuracy: 8.57% -> 36.19%      
client [8]  (testset)   loss: 2.5894 -> 2.2701  accuracy: 7.09% -> 46.10%      
client [18] (testset)   loss: 2.1338 -> 1.8486  accuracy: 2.09% -> 32.46%      
client [94] (testset)   loss: 2.0787 -> 2.0255  accuracy: 38.84% -> 38.84%     
client [81] (testset)   loss: 2.7407 -> 2.5241  accuracy: 3.12% -> 3.12%       
client [3]  (testset)   loss: 2.2791 -> 1.7754  accuracy: 2.53% -> 62.66%      
client [11] (testset)   loss: 2.7876 -> 2.5029  accuracy: 7.08% -> 7.08%       
client [95] (testset)   loss: 2.3511 -> 2.3115  accuracy: 14.68% -> 14.68%     
client [67] (testset)   loss: 2.4449 -> 2.3515  accuracy: 11.01% -> 11.01%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 2.4964 -> 2.3556  accuracy: 1.94% -> 27.10%      
client [79] (testset)   loss: 2.2987 -> 2.2602  accuracy: 14.85% -> 21.78%     
client [58] (testset)   loss: 2.2687 -> 2.0363  accuracy: 6.11% -> 31.11%      
client [88] (testset)   loss: 2.3038 -> 2.1023  accuracy: 5.33% -> 41.42%      
client [46] (testset)   loss: 2.3169 -> 2.2216  accuracy: 7.84% -> 7.84%       
client [11] (testset)   loss: 2.4736 -> 2.3465  accuracy: 7.08% -> 36.28%      
client [55] (testset)   loss: 2.6097 -> 2.5120  accuracy: 3.80% -> 3.80%       
client [13] (testset)   loss: 2.6057 -> 2.4581  accuracy: 2.92% -> 6.43%       
client [31] (testset)   loss: 2.4383 -> 2.3924  accuracy: 0.00% -> 11.34%      
client [75] (testset)   loss: 2.3001 -> 2.2346  accuracy: 22.62% -> 22.62%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 2.4280 -> 2.2803  accuracy: 11.80% -> 34.16%     
client [7]  (testset)   loss: 2.2416 -> 2.0974  accuracy: 10.22% -> 41.94%     
client [57] (testset)   loss: 2.3848 -> 2.3549  accuracy: 11.11% -> 11.11%     
client [13] (testset)   loss: 2.5377 -> 2.3969  accuracy: 18.71% -> 18.71%     
client [43] (testset)   loss: 2.5096 -> 2.3362  accuracy: 8.33% -> 8.33%       
client [91] (testset)   loss: 2.4779 -> 2.4487  accuracy: 8.33% -> 8.33%       
client [10] (testset)   loss: 2.3561 -> 2.2382  accuracy: 2.70% -> 36.94%      
client [64] (testset)   loss: 2.2880 -> 2.2699  accuracy: 7.94% -> 7.94%       
client [82] (testset)   loss: 2.2527 -> 2.1223  accuracy: 23.48% -> 23.48%     
client [22] (testset)   loss: 2.4128 -> 2.3493  accuracy: 18.52% -> 18.52%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 2.3520 -> 2.2264  accuracy: 8.68% -> 19.18%      
client [23] (testset)   loss: 2.2114 -> 2.1663  accuracy: 16.54% -> 16.54%     
client [88] (testset)   loss: 2.2946 -> 2.1147  accuracy: 8.28% -> 41.42%      
client [98] (testset)   loss: 2.5200 -> 2.4295  accuracy: 2.30% -> 18.39%      
client [79] (testset)   loss: 2.2707 -> 2.2314  accuracy: 1.98% -> 21.78%      
client [21] (testset)   loss: 2.4620 -> 2.3246  accuracy: 11.61% -> 27.10%     
client [92] (testset)   loss: 2.6117 -> 2.5127  accuracy: 2.48% -> 21.49%      
client [56] (testset)   loss: 2.2332 -> 2.1166  accuracy: 7.87% -> 7.87%       
client [5]  (testset)   loss: 2.1168 -> 1.8221  accuracy: 6.70% -> 51.79%      
client [52] (testset)   loss: 2.4123 -> 2.1707  accuracy: 1.31% -> 28.38%      
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 2.3159 -> 2.2491  accuracy: 20.18% -> 20.18%     
client [54] (testset)   loss: 2.6038 -> 2.4644  accuracy: 10.43% -> 10.43%     
client [14] (testset)   loss: 2.2609 -> 2.1846  accuracy: 9.63% -> 9.63%       
client [99] (testset)   loss: 2.1788 -> 2.1219  accuracy: 32.79% -> 32.79%     
client [36] (testset)   loss: 2.5493 -> 2.2311  accuracy: 3.21% -> 3.21%       
client [30] (testset)   loss: 2.4457 -> 2.2188  accuracy: 7.14% -> 32.47%      
client [38] (testset)   loss: 2.6612 -> 2.3832  accuracy: 4.05% -> 11.56%      
client [15] (testset)   loss: 2.2916 -> 2.1650  accuracy: 35.54% -> 35.54%     
client [6]  (testset)   loss: 2.2181 -> 2.1810  accuracy: 24.72% -> 24.72%     
client [53] (testset)   loss: 2.3663 -> 2.2174  accuracy: 6.48% -> 6.48%       
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [99] (testset)   loss: 2.2687 -> 2.1519  accuracy: 2.46% -> 32.79%      
client [6]  (testset)   loss: 2.2813 -> 2.2053  accuracy: 24.72% -> 24.72%     
client [83] (testset)   loss: 2.4010 -> 2.2090  accuracy: 2.52% -> 2.52%       
client [42] (testset)   loss: 2.2498 -> 2.2096  accuracy: 20.95% -> 20.95%     
client [34] (testset)   loss: 2.3020 -> 2.1436  accuracy: 32.74% -> 32.74%     
client [15] (testset)   loss: 2.1680 -> 2.0973  accuracy: 35.54% -> 35.54%     
client [47] (testset)   loss: 2.4850 -> 2.2149  accuracy: 0.70% -> 0.70%       
client [55] (testset)   loss: 2.5969 -> 2.5289  accuracy: 13.92% -> 13.92%     
client [51] (testset)   loss: 2.4454 -> 2.3129  accuracy: 8.57% -> 8.57%       
client [95] (testset)   loss: 2.4529 -> 2.3942  accuracy: 1.83% -> 1.83%       
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 2.6170 -> 2.4795  accuracy: 0.00% -> 0.00%       
client [15] (testset)   loss: 2.2216 -> 2.1358  accuracy: 35.54% -> 35.54%     
client [33] (testset)   loss: 2.4679 -> 2.2944  accuracy: 5.29% -> 5.29%       
client [99] (testset)   loss: 2.2408 -> 2.1794  accuracy: 32.79% -> 32.79%     
client [90] (testset)   loss: 2.5881 -> 2.3362  accuracy: 0.00% -> 0.00%       
client [57] (testset)   loss: 2.4855 -> 2.4419  accuracy: 11.11% -> 11.11%     
client [27] (testset)   loss: 2.3807 -> 2.3033  accuracy: 12.78% -> 12.78%     
client [78] (testset)   loss: 2.2746 -> 2.2382  accuracy: 8.20% -> 8.20%       
client [36] (testset)   loss: 2.2387 -> 2.0309  accuracy: 3.21% -> 36.54%      
client [88] (testset)   loss: 2.1628 -> 2.0224  accuracy: 5.33% -> 41.42%      
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 2.3214 -> 2.2003  accuracy: 30.17% -> 30.17%     
client [35] (testset)   loss: 2.3035 -> 2.1880  accuracy: 17.78% -> 17.78%     
client [16] (testset)   loss: 1.9268 -> 1.5734  accuracy: 59.84% -> 59.84%     
client [80] (testset)   loss: 2.7983 -> 2.3023  accuracy: 7.14% -> 7.14%       
client [38] (testset)   loss: 2.5215 -> 2.2029  accuracy: 11.56% -> 11.56%     
client [78] (testset)   loss: 2.4433 -> 2.2995  accuracy: 8.20% -> 8.20%       
client [68] (testset)   loss: 2.3543 -> 2.2788  accuracy: 16.80% -> 16.80%     
client [11] (testset)   loss: 2.3575 -> 2.2243  accuracy: 7.96% -> 36.28%      
client [64] (testset)   loss: 2.3703 -> 2.3143  accuracy: 12.70% -> 12.70%     
client [82] (testset)   loss: 2.3002 -> 2.0755  accuracy: 16.52% -> 16.52%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 2.5622 -> 2.2637  accuracy: 1.30% -> 32.47%      
client [27] (testset)   loss: 2.5257 -> 2.3660  accuracy: 13.53% -> 13.53%     
client [74] (testset)   loss: 2.3139 -> 2.2865  accuracy: 27.37% -> 27.37%     
client [45] (testset)   loss: 2.1966 -> 2.0802  accuracy: 20.28% -> 20.28%     
client [6]  (testset)   loss: 2.2424 -> 2.1785  accuracy: 16.29% -> 24.72%     
client [36] (testset)   loss: 2.3530 -> 2.1073  accuracy: 3.21% -> 36.54%      
client [63] (testset)   loss: 2.2519 -> 2.2150  accuracy: 21.88% -> 21.88%     
client [76] (testset)   loss: 2.3782 -> 2.3071  accuracy: 5.92% -> 5.92%       
client [83] (testset)   loss: 2.3371 -> 2.1856  accuracy: 23.27% -> 23.27%     
client [86] (testset)   loss: 2.4183 -> 2.3371  accuracy: 3.57% -> 3.57%       
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 2.3495 -> 2.1849  accuracy: 0.00% -> 23.27%      
client [99] (testset)   loss: 2.3635 -> 2.2245  accuracy: 2.46% -> 32.79%      
client [74] (testset)   loss: 2.3978 -> 2.3545  accuracy: 15.79% -> 15.79%     
client [73] (testset)   loss: 2.2030 -> 2.1252  accuracy: 26.21% -> 26.21%     
client [29] (testset)   loss: 2.5938 -> 2.5182  accuracy: 9.62% -> 2.88%       
client [92] (testset)   loss: 2.6200 -> 2.5057  accuracy: 2.48% -> 2.48%       
client [6]  (testset)   loss: 2.2390 -> 2.1805  accuracy: 24.72% -> 24.72%     
client [61] (testset)   loss: 2.3188 -> 2.2498  accuracy: 18.25% -> 18.25%     
client [21] (testset)   loss: 2.4742 -> 2.3550  accuracy: 27.10% -> 27.10%     
client [67] (testset)   loss: 2.2991 -> 2.2422  accuracy: 20.18% -> 20.18%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 2.2676 -> 2.1081  accuracy: 22.01% -> 22.01%     
client [32] (testset)   loss: 2.1682 -> 2.0939  accuracy: 20.48% -> 20.48%     
client [95] (testset)   loss: 2.4042 -> 2.3583  accuracy: 12.84% -> 12.84%     
client [61] (testset)   loss: 2.2997 -> 2.2178  accuracy: 15.08% -> 15.08%     
client [27] (testset)   loss: 2.6593 -> 2.4684  accuracy: 0.00% -> 12.78%      
client [25] (testset)   loss: 2.1652 -> 2.0535  accuracy: 40.30% -> 40.30%     
client [68] (testset)   loss: 2.2702 -> 2.2241  accuracy: 16.80% -> 16.80%     
client [34] (testset)   loss: 2.2608 -> 2.1394  accuracy: 32.74% -> 32.74%     
client [71] (testset)   loss: 2.7017 -> 2.5194  accuracy: 0.00% -> 0.00%       
client [89] (testset)   loss: 2.2943 -> 2.1938  accuracy: 21.60% -> 21.60%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 2.2770 -> 2.2348  accuracy: 8.20% -> 8.20%       
client [81] (testset)   loss: 2.5574 -> 2.5003  accuracy: 4.17% -> 4.17%       
client [51] (testset)   loss: 2.3439 -> 2.2664  accuracy: 8.57% -> 36.19%      
client [54] (testset)   loss: 2.3820 -> 2.3141  accuracy: 0.87% -> 20.00%      
client [65] (testset)   loss: 2.4662 -> 2.3355  accuracy: 6.52% -> 28.26%      
client [41] (testset)   loss: 2.9033 -> 2.6887  accuracy: 4.42% -> 11.50%      
client [11] (testset)   loss: 2.4644 -> 2.3595  accuracy: 7.08% -> 36.28%      
client [85] (testset)   loss: 2.3997 -> 2.2936  accuracy: 2.04% -> 27.76%      
client [12] (testset)   loss: 2.3522 -> 2.3168  accuracy: 12.73% -> 12.73%     
client [23] (testset)   loss: 2.2372 -> 2.1836  accuracy: 24.23% -> 24.23%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 2.0083 -> 1.6916  accuracy: 16.54% -> 59.84%     
client [65] (testset)   loss: 2.5645 -> 2.3062  accuracy: 1.45% -> 1.45%       
client [53] (testset)   loss: 2.3787 -> 2.2156  accuracy: 6.48% -> 32.41%      
client [58] (testset)   loss: 2.1084 -> 1.9304  accuracy: 31.11% -> 31.11%     
client [72] (testset)   loss: 2.6233 -> 2.3705  accuracy: 5.33% -> 5.33%       
client [7]  (testset)   loss: 2.1510 -> 2.0357  accuracy: 12.90% -> 41.94%     
client [71] (testset)   loss: 2.8049 -> 2.5992  accuracy: 0.00% -> 0.00%       
client [59] (testset)   loss: 2.6275 -> 2.4693  accuracy: 7.48% -> 7.48%       
client [86] (testset)   loss: 2.3397 -> 2.2929  accuracy: 7.14% -> 7.14%       
client [39] (testset)   loss: 2.3461 -> 2.2658  accuracy: 10.65% -> 10.65%     
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 2.2976 -> 2.2118  accuracy: 32.79% -> 32.79%     
client [7]  (testset)   loss: 2.0951 -> 2.0131  accuracy: 41.94% -> 41.94%     
client [17] (testset)   loss: 2.5251 -> 2.4670  accuracy: 9.23% -> 9.23%       
client [64] (testset)   loss: 2.2818 -> 2.2638  accuracy: 11.11% -> 11.11%     
client [37] (testset)   loss: 2.4214 -> 2.3901  accuracy: 19.51% -> 19.51%     
client [29] (testset)   loss: 2.5068 -> 2.4496  accuracy: 9.62% -> 9.62%       
client [93] (testset)   loss: 2.0183 -> 1.4883  accuracy: 69.57% -> 69.57%     
client [73] (testset)   loss: 2.2334 -> 2.1209  accuracy: 26.21% -> 26.21%     
client [40] (testset)   loss: 2.1503 -> 2.0839  accuracy: 23.21% -> 23.21%     
client [76] (testset)   loss: 2.3313 -> 2.2750  accuracy: 20.39% -> 20.39%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 2.3824 -> 2.3497  accuracy: 4.12% -> 4.12%       
client [89] (testset)   loss: 2.2903 -> 2.2169  accuracy: 21.60% -> 21.60%     
client [77] (testset)   loss: 2.4510 -> 2.3631  accuracy: 2.61% -> 2.61%       
client [90] (testset)   loss: 2.5138 -> 2.3838  accuracy: 0.00% -> 0.00%       
client [26] (testset)   loss: 2.1513 -> 1.7657  accuracy: 54.98% -> 54.98%     
client [50] (testset)   loss: 2.6146 -> 2.5024  accuracy: 14.53% -> 14.53%     
client [30] (testset)   loss: 2.4804 -> 2.2893  accuracy: 7.14% -> 7.14%       
client [70] (testset)   loss: 2.2703 -> 2.2063  accuracy: 30.17% -> 30.17%     
client [41] (testset)   loss: 2.9072 -> 2.6849  accuracy: 0.00% -> 0.00%       
client [99] (testset)   loss: 2.1883 -> 2.1445  accuracy: 32.79% -> 32.79%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [68] (testset)   loss: 2.3239 -> 2.2718  accuracy: 0.80% -> 16.80%      
client [70] (testset)   loss: 2.3349 -> 2.2499  accuracy: 30.17% -> 30.17%     
client [52] (testset)   loss: 2.2834 -> 2.1694  accuracy: 1.31% -> 28.38%      
client [1]  (testset)   loss: 2.2945 -> 2.2569  accuracy: 18.28% -> 18.28%     
client [2]  (testset)   loss: 2.2110 -> 2.1365  accuracy: 33.85% -> 33.85%     
client [67] (testset)   loss: 2.4484 -> 2.3715  accuracy: 0.00% -> 0.00%       
client [92] (testset)   loss: 2.5714 -> 2.4949  accuracy: 8.26% -> 8.26%       
client [35] (testset)   loss: 2.3634 -> 2.2997  accuracy: 1.67% -> 23.33%      
client [36] (testset)   loss: 2.2251 -> 2.0930  accuracy: 3.85% -> 36.54%      
client [64] (testset)   loss: 2.2291 -> 2.2191  accuracy: 12.70% -> 12.70%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 2.2495 -> 2.2065  accuracy: 21.62% -> 28.38%     
client [6]  (testset)   loss: 2.2421 -> 2.2045  accuracy: 24.72% -> 24.72%     
client [12] (testset)   loss: 2.2241 -> 2.2143  accuracy: 12.73% -> 12.73%     
client [55] (testset)   loss: 2.5470 -> 2.5142  accuracy: 13.92% -> 13.92%     
client [29] (testset)   loss: 2.4816 -> 2.4517  accuracy: 9.62% -> 24.04%      
client [9]  (testset)   loss: 2.3850 -> 2.3231  accuracy: 16.30% -> 16.30%     
client [43] (testset)   loss: 2.3122 -> 2.2751  accuracy: 24.17% -> 24.17%     
client [77] (testset)   loss: 2.4643 -> 2.3811  accuracy: 4.58% -> 4.58%       
client [98] (testset)   loss: 2.4882 -> 2.4383  accuracy: 4.60% -> 4.60%       
client [78] (testset)   loss: 2.3046 -> 2.2772  accuracy: 1.64% -> 1.64%       
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 2.6595 -> 2.5689  accuracy: 6.61% -> 6.61%       
client [80] (testset)   loss: 2.3896 -> 2.3182  accuracy: 2.86% -> 7.14%       
client [63] (testset)   loss: 2.2619 -> 2.2372  accuracy: 16.41% -> 16.41%     
client [76] (testset)   loss: 2.3474 -> 2.3137  accuracy: 20.39% -> 20.39%     
client [78] (testset)   loss: 2.3354 -> 2.3024  accuracy: 8.20% -> 8.20%       
client [25] (testset)   loss: 2.1977 -> 2.1113  accuracy: 40.30% -> 40.30%     
client [58] (testset)   loss: 2.3371 -> 2.1879  accuracy: 1.11% -> 31.11%      
client [13] (testset)   loss: 2.4873 -> 2.4166  accuracy: 2.92% -> 18.71%      
client [17] (testset)   loss: 2.5058 -> 2.4744  accuracy: 9.23% -> 9.23%       
client [38] (testset)   loss: 2.3859 -> 2.2665  accuracy: 11.56% -> 11.56%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 2.3030 -> 2.2656  accuracy: 26.63% -> 26.63%     
client [82] (testset)   loss: 2.3308 -> 2.2033  accuracy: 1.74% -> 1.74%       
client [86] (testset)   loss: 2.4946 -> 2.4222  accuracy: 7.14% -> 7.14%       
client [51] (testset)   loss: 2.4466 -> 2.3631  accuracy: 8.57% -> 8.57%       
client [96] (testset)   loss: 2.4087 -> 2.3661  accuracy: 6.90% -> 6.90%       
client [42] (testset)   loss: 2.2479 -> 2.2238  accuracy: 20.95% -> 20.95%     
client [55] (testset)   loss: 2.6075 -> 2.5619  accuracy: 13.92% -> 13.92%     
client [13] (testset)   loss: 2.5206 -> 2.4549  accuracy: 18.71% -> 18.71%     
client [1]  (testset)   loss: 2.2013 -> 2.1866  accuracy: 23.66% -> 23.66%     
client [12] (testset)   loss: 2.3253 -> 2.3062  accuracy: 12.73% -> 12.73%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 2.3381 -> 2.2964  accuracy: 16.80% -> 16.80%     
client [23] (testset)   loss: 2.1702 -> 2.1534  accuracy: 24.23% -> 24.23%     
client [46] (testset)   loss: 2.1989 -> 2.1615  accuracy: 6.86% -> 6.86%       
client [41] (testset)   loss: 2.9597 -> 2.7979  accuracy: 0.00% -> 0.00%       
client [25] (testset)   loss: 2.0768 -> 2.0218  accuracy: 40.30% -> 40.30%     
client [58] (testset)   loss: 2.4114 -> 2.2719  accuracy: 1.11% -> 1.11%       
client [14] (testset)   loss: 2.2056 -> 2.1704  accuracy: 9.63% -> 35.56%      
client [33] (testset)   loss: 2.2996 -> 2.2492  accuracy: 17.65% -> 17.65%     
client [85] (testset)   loss: 2.3564 -> 2.2940  accuracy: 13.06% -> 27.76%     
client [62] (testset)   loss: 2.1977 -> 2.1348  accuracy: 33.83% -> 33.83%     
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 2.4556 -> 2.4140  accuracy: 3.45% -> 28.74%      
client [63] (testset)   loss: 2.2328 -> 2.2154  accuracy: 21.88% -> 21.88%     
client [70] (testset)   loss: 2.4166 -> 2.3379  accuracy: 0.86% -> 30.17%      
client [65] (testset)   loss: 2.4835 -> 2.4036  accuracy: 1.45% -> 1.45%       
client [14] (testset)   loss: 2.3007 -> 2.2536  accuracy: 9.63% -> 9.63%       
client [73] (testset)   loss: 2.1967 -> 2.1569  accuracy: 26.21% -> 26.21%     
client [34] (testset)   loss: 2.2085 -> 2.1348  accuracy: 32.74% -> 32.74%     
client [99] (testset)   loss: 2.1535 -> 2.1298  accuracy: 32.79% -> 32.79%     
client [69] (testset)   loss: 2.2364 -> 2.1687  accuracy: 30.13% -> 30.13%     
client [46] (testset)   loss: 2.3008 -> 2.2532  accuracy: 6.86% -> 6.86%       
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [99] (testset)   loss: 2.3141 -> 2.2680  accuracy: 4.10% -> 32.79%      
client [93] (testset)   loss: 2.0889 -> 1.8092  accuracy: 69.57% -> 69.57%     
client [11] (testset)   loss: 2.5511 -> 2.4825  accuracy: 7.96% -> 7.96%       
client [58] (testset)   loss: 2.3152 -> 2.2046  accuracy: 1.11% -> 1.11%       
client [81] (testset)   loss: 2.5890 -> 2.5521  accuracy: 4.17% -> 4.17%       
client [85] (testset)   loss: 2.3311 -> 2.2929  accuracy: 27.76% -> 27.76%     
client [89] (testset)   loss: 2.2111 -> 2.1768  accuracy: 21.60% -> 21.60%     
client [45] (testset)   loss: 2.0905 -> 2.0621  accuracy: 33.57% -> 33.57%     
client [8]  (testset)   loss: 2.4812 -> 2.3678  accuracy: 0.71% -> 0.71%       
client [68] (testset)   loss: 2.3010 -> 2.2753  accuracy: 16.80% -> 16.80%     
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 2.2912 -> 2.2676  accuracy: 20.18% -> 20.18%     
client [72] (testset)   loss: 2.2855 -> 2.2606  accuracy: 26.63% -> 26.63%     
client [1]  (testset)   loss: 2.2770 -> 2.2581  accuracy: 23.66% -> 23.66%     
client [78] (testset)   loss: 2.3305 -> 2.3043  accuracy: 8.20% -> 8.20%       
client [83] (testset)   loss: 2.3259 -> 2.2466  accuracy: 2.52% -> 2.52%       
client [21] (testset)   loss: 2.3878 -> 2.3378  accuracy: 27.10% -> 27.10%     
client [56] (testset)   loss: 2.1319 -> 2.0922  accuracy: 21.35% -> 21.35%     
client [44] (testset)   loss: 2.2216 -> 2.2008  accuracy: 28.38% -> 28.38%     
client [92] (testset)   loss: 2.6415 -> 2.5877  accuracy: 2.48% -> 2.48%       
client [27] (testset)   loss: 2.4970 -> 2.4449  accuracy: 12.78% -> 12.78%     
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 2.3702 -> 2.3077  accuracy: 2.70% -> 2.70%       
client [39] (testset)   loss: 2.3555 -> 2.3101  accuracy: 10.65% -> 10.65%     
client [65] (testset)   loss: 2.4290 -> 2.3698  accuracy: 1.45% -> 28.26%      
client [26] (testset)   loss: 2.1323 -> 1.9115  accuracy: 18.82% -> 54.98%     
client [19] (testset)   loss: 2.3626 -> 2.3098  accuracy: 11.80% -> 11.80%     
client [68] (testset)   loss: 2.2619 -> 2.2411  accuracy: 16.80% -> 16.80%     
client [41] (testset)   loss: 2.9668 -> 2.8426  accuracy: 0.00% -> 0.00%       
client [50] (testset)   loss: 2.5236 -> 2.4836  accuracy: 14.53% -> 14.53%     
client [75] (testset)   loss: 2.1199 -> 2.1025  accuracy: 39.29% -> 39.29%     
client [81] (testset)   loss: 2.6460 -> 2.6062  accuracy: 4.17% -> 4.17%       
Training... ---------------------------------------- 100% 0:15:00
SFL's average time taken by each global epoch: 0 min 2.24 sec.                 
SFL's total running time: 0 h 15 m 0 s.                                        
==================== SFL Experiment Results: ====================              
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "2.4946 -> 0.0000",                                    
                "accuracy": "18.16% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "2.3338 -> 0.0000",                                    
                "accuracy": "10.92% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "2.3212 -> 0.0000",                                    
                "accuracy": "18.16% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "2.3086 -> 0.0000",                                    
                "accuracy": "18.16% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== SFL Max Accuracy ====================                     
all_clients:                                                                   
(test) before fine-tuning: 18.16% at epoch 100                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
[0m