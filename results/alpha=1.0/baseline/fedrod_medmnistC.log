==================== FedRoD ====================                               
Experiment Arguments:                                                          
{
│   'method': 'fedrod',
│   'dataset': {
│   │   'name': 'medmnistC',
│   │   'client_num': 100,
│   │   'test_ratio': 0.25,
│   │   'val_ratio': 0.0,
│   │   'seed': 42,
│   │   'split': 'sample',
│   │   'IID_ratio': 0.0,
│   │   'monitor_window_name_suffix': 'medmnistC-100clients-0%IID-Dir(1.0)-seed42',
│   │   'alpha': 1.0,
│   │   'min_samples_per_client': 10
│   },
│   'model': {
│   │   'name': 'lenet5',
│   │   'use_torchvision_pretrained_weights': True,
│   │   'external_model_weights_path': None
│   },
│   'optimizer': {
│   │   'lr': 0.01,
│   │   'dampening': 0,
│   │   'weight_decay': 0,
│   │   'momentum': 0,
│   │   'nesterov': False,
│   │   'name': 'sgd'
│   },
│   'mode': 'serial',
│   'parallel': {
│   │   'ray_cluster_addr': None,
│   │   'num_cpus': None,
│   │   'num_gpus': None,
│   │   'num_workers': 2
│   },
│   'common': {
│   │   'seed': 42,
│   │   'join_ratio': 0.1,
│   │   'global_epoch': 400,
│   │   'local_epoch': 5,
│   │   'batch_size': 32,
│   │   'reset_optimizer_on_global_epoch': True,
│   │   'straggler_ratio': 0,
│   │   'straggler_min_local_epoch': 0,
│   │   'buffers': 'global',
│   │   'client_side_evaluation': True,
│   │   'test': {
│   │   │   'client': {
│   │   │   │   'interval': 100,
│   │   │   │   'finetune_epoch': 0,
│   │   │   │   'train': False,
│   │   │   │   'val': False,
│   │   │   │   'test': True
│   │   │   },
│   │   │   'server': {
│   │   │   │   'interval': -1,
│   │   │   │   'train': False,
│   │   │   │   'val': False,
│   │   │   │   'test': False,
│   │   │   │   'model_in_train_mode': False
│   │   │   }
│   │   },
│   │   'verbose_gap': 10,
│   │   'monitor': None,
│   │   'use_cuda': True,
│   │   'save_log': True,
│   │   'save_model': False,
│   │   'save_learning_curve_plot': False,
│   │   'save_metrics': True,
│   │   'delete_useless_run': True
│   },
│   'fedrod': {
│   │   'gamma': 1,
│   │   'hyper': 0,
│   │   'hyper_lr': 0.1,
│   │   'hyper_hidden_dim': 32,
│   │   'eval_per': 1
│   }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 2.1552 -> 2.0149  accuracy: 16.67% -> 16.67%     
client [81] (testset)   loss: 2.0058 -> 1.9931  accuracy: 35.14% -> 35.14%     
client [21] (testset)   loss: 2.8715 -> 2.0262  accuracy: 1.75% -> 26.32%      
client [68] (testset)   loss: 1.8090 -> 1.7734  accuracy: 31.11% -> 37.78%     
client [93] (testset)   loss: 1.7952 -> 1.6929  accuracy: 45.65% -> 45.65%     
client [31] (testset)   loss: 2.3922 -> 1.8400  accuracy: 22.22% -> 44.44%     
client [20] (testset)   loss: 2.2246 -> 2.1841  accuracy: 18.03% -> 18.03%     
client [59] (testset)   loss: 3.0773 -> 2.1491  accuracy: 1.15% -> 24.14%      
client [48] (testset)   loss: 2.2480 -> 2.2794  accuracy: 17.39% -> 17.39%     
client [34] (testset)   loss: 1.9827 -> 1.9259  accuracy: 24.59% -> 24.59%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 2.2172 -> 2.0389  accuracy: 17.65% -> 29.41%     
client [99] (testset)   loss: 2.1895 -> 2.0514  accuracy: 20.51% -> 20.51%     
client [67] (testset)   loss: 2.1610 -> 2.0899  accuracy: 19.30% -> 19.30%     
client [0]  (testset)   loss: 1.7427 -> 1.7279  accuracy: 36.99% -> 36.99%     
client [76] (testset)   loss: 2.1102 -> 1.8865  accuracy: 27.78% -> 27.78%     
client [41] (testset)   loss: 2.1318 -> 1.9841  accuracy: 26.92% -> 26.92%     
client [62] (testset)   loss: 2.1569 -> 1.8520  accuracy: 41.38% -> 41.38%     
client [2]  (testset)   loss: 2.5793 -> 1.7655  accuracy: 2.41% -> 49.40%      
client [14] (testset)   loss: 2.1082 -> 2.0663  accuracy: 31.88% -> 31.88%     
client [46] (testset)   loss: 1.8751 -> 1.8221  accuracy: 48.94% -> 48.94%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 2.1931 -> 2.2352  accuracy: 20.00% -> 36.00%     
client [68] (testset)   loss: 1.7710 -> 1.7770  accuracy: 37.78% -> 37.78%     
client [57] (testset)   loss: 2.0860 -> 2.0986  accuracy: 34.78% -> 34.78%     
client [17] (testset)   loss: 1.9897 -> 1.9879  accuracy: 32.00% -> 32.00%     
client [54] (testset)   loss: 2.5018 -> 2.4665  accuracy: 18.75% -> 18.75%     
client [23] (testset)   loss: 3.0656 -> 2.2969  accuracy: 5.88% -> 23.53%      
client [35] (testset)   loss: 2.2192 -> 1.9910  accuracy: 33.33% -> 33.33%     
client [59] (testset)   loss: 2.1165 -> 2.1034  accuracy: 24.14% -> 24.14%     
client [31] (testset)   loss: 1.9340 -> 1.8369  accuracy: 44.44% -> 44.44%     
client [9]  (testset)   loss: 2.3090 -> 2.3415  accuracy: 13.33% -> 13.33%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 2.1900 -> 2.1844  accuracy: 20.00% -> 20.00%     
client [33] (testset)   loss: 1.8113 -> 1.8250  accuracy: 22.22% -> 22.22%     
client [16] (testset)   loss: 2.0700 -> 2.0287  accuracy: 26.67% -> 26.67%     
client [44] (testset)   loss: 2.1501 -> 2.1379  accuracy: 14.29% -> 23.21%     
client [8]  (testset)   loss: 1.9648 -> 1.9370  accuracy: 34.17% -> 34.17%     
client [31] (testset)   loss: 1.8537 -> 1.9058  accuracy: 44.44% -> 44.44%     
client [47] (testset)   loss: 1.7482 -> 1.7081  accuracy: 47.22% -> 47.22%     
client [36] (testset)   loss: 2.8164 -> 2.1173  accuracy: 4.08% -> 24.49%      
client [20] (testset)   loss: 2.1896 -> 2.1799  accuracy: 18.03% -> 18.03%     
client [56] (testset)   loss: 2.2818 -> 2.1949  accuracy: 7.27% -> 7.27%       
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 2.0298 -> 2.0315  accuracy: 30.19% -> 30.19%     
client [60] (testset)   loss: 2.3404 -> 2.2491  accuracy: 28.57% -> 28.57%     
client [28] (testset)   loss: 2.1887 -> 2.1941  accuracy: 12.33% -> 12.33%     
client [25] (testset)   loss: 2.3665 -> 2.4423  accuracy: 12.00% -> 12.00%     
client [58] (testset)   loss: 1.6817 -> 1.6872  accuracy: 42.47% -> 42.47%     
client [44] (testset)   loss: 2.1210 -> 2.1548  accuracy: 23.21% -> 23.21%     
client [39] (testset)   loss: 1.3948 -> 1.4089  accuracy: 53.77% -> 53.77%     
client [29] (testset)   loss: 1.7979 -> 1.7797  accuracy: 37.66% -> 37.66%     
client [3]  (testset)   loss: 2.3921 -> 2.4879  accuracy: 9.26% -> 9.26%       
client [84] (testset)   loss: 1.6469 -> 1.6596  accuracy: 38.53% -> 38.53%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 1.9679 -> 1.9636  accuracy: 26.32% -> 26.32%     
client [84] (testset)   loss: 1.6845 -> 1.6648  accuracy: 38.53% -> 38.53%     
client [10] (testset)   loss: 2.0979 -> 2.0756  accuracy: 22.22% -> 38.89%     
client [36] (testset)   loss: 2.0879 -> 2.0708  accuracy: 24.49% -> 24.49%     
client [65] (testset)   loss: 1.9856 -> 2.0413  accuracy: 37.74% -> 37.74%     
client [81] (testset)   loss: 2.0498 -> 1.9930  accuracy: 35.14% -> 35.14%     
client [79] (testset)   loss: 2.2325 -> 2.2622  accuracy: 21.15% -> 21.15%     
client [42] (testset)   loss: 2.2782 -> 2.2468  accuracy: 7.14% -> 7.14%       
client [11] (testset)   loss: 1.9738 -> 1.9560  accuracy: 30.36% -> 21.43%     
client [96] (testset)   loss: 2.0678 -> 2.0765  accuracy: 30.36% -> 30.36%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 1.8914 -> 1.9056  accuracy: 34.17% -> 34.17%     
client [53] (testset)   loss: 2.0589 -> 2.0844  accuracy: 38.71% -> 38.71%     
client [52] (testset)   loss: 1.2890 -> 1.2924  accuracy: 57.14% -> 57.14%     
client [42] (testset)   loss: 2.2580 -> 2.2584  accuracy: 7.14% -> 7.14%       
client [69] (testset)   loss: 2.0341 -> 2.0225  accuracy: 29.41% -> 29.41%     
client [59] (testset)   loss: 2.1061 -> 2.1273  accuracy: 24.14% -> 24.14%     
client [7]  (testset)   loss: 1.9988 -> 1.9303  accuracy: 32.79% -> 32.79%     
client [26] (testset)   loss: 2.1766 -> 2.1755  accuracy: 22.81% -> 22.81%     
client [49] (testset)   loss: 1.9371 -> 1.9168  accuracy: 15.15% -> 24.24%     
client [98] (testset)   loss: 2.0510 -> 2.0524  accuracy: 37.74% -> 37.74%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 2.0528 -> 2.0553  accuracy: 37.74% -> 37.74%     
client [47] (testset)   loss: 1.7577 -> 1.7248  accuracy: 47.22% -> 47.22%     
client [21] (testset)   loss: 1.9841 -> 1.9514  accuracy: 26.32% -> 26.32%     
client [77] (testset)   loss: 1.9821 -> 1.9822  accuracy: 30.00% -> 30.00%     
client [95] (testset)   loss: 1.9937 -> 2.0140  accuracy: 34.25% -> 34.25%     
client [91] (testset)   loss: 1.9953 -> 2.0137  accuracy: 37.93% -> 37.93%     
client [14] (testset)   loss: 2.0486 -> 2.0539  accuracy: 31.88% -> 31.88%     
client [99] (testset)   loss: 2.0728 -> 2.0667  accuracy: 10.26% -> 20.51%     
client [20] (testset)   loss: 2.1921 -> 2.1933  accuracy: 18.03% -> 18.03%     
client [39] (testset)   loss: 1.4157 -> 1.4003  accuracy: 53.77% -> 53.77%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 1.3757 -> 1.3012  accuracy: 57.14% -> 57.14%     
client [62] (testset)   loss: 1.8680 -> 1.8684  accuracy: 41.38% -> 41.38%     
client [71] (testset)   loss: 2.0422 -> 2.0512  accuracy: 23.33% -> 23.33%     
client [97] (testset)   loss: 1.8644 -> 1.8590  accuracy: 25.76% -> 25.76%     
client [30] (testset)   loss: 2.3683 -> 2.3469  accuracy: 15.15% -> 15.15%     
client [88] (testset)   loss: 2.1593 -> 2.1713  accuracy: 22.81% -> 22.81%     
client [60] (testset)   loss: 2.2025 -> 2.1926  accuracy: 28.57% -> 28.57%     
client [82] (testset)   loss: 1.9122 -> 1.9260  accuracy: 40.30% -> 11.94%     
client [91] (testset)   loss: 2.0027 -> 2.0237  accuracy: 13.79% -> 13.79%     
client [57] (testset)   loss: 2.1201 -> 2.1032  accuracy: 34.78% -> 34.78%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 1.8415 -> 1.8748  accuracy: 44.44% -> 44.44%     
client [15] (testset)   loss: 1.5445 -> 1.4766  accuracy: 61.04% -> 61.04%     
client [71] (testset)   loss: 2.0400 -> 2.0357  accuracy: 23.33% -> 23.33%     
client [97] (testset)   loss: 1.8548 -> 1.9254  accuracy: 25.76% -> 25.76%     
client [53] (testset)   loss: 2.1281 -> 2.0884  accuracy: 38.71% -> 38.71%     
client [77] (testset)   loss: 1.9783 -> 1.9817  accuracy: 30.00% -> 30.00%     
client [76] (testset)   loss: 1.9180 -> 1.8935  accuracy: 27.78% -> 27.78%     
client [79] (testset)   loss: 2.2996 -> 2.2917  accuracy: 21.15% -> 21.15%     
client [28] (testset)   loss: 2.2024 -> 2.1890  accuracy: 12.33% -> 12.33%     
client [99] (testset)   loss: 2.0607 -> 2.0693  accuracy: 20.51% -> 10.26%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 1.8519 -> 1.8777  accuracy: 31.82% -> 25.76%     
client [86] (testset)   loss: 1.6909 -> 1.7192  accuracy: 48.44% -> 48.44%     
client [34] (testset)   loss: 1.9126 -> 1.9050  accuracy: 24.59% -> 24.59%     
client [73] (testset)   loss: 2.3347 -> 2.3326  accuracy: 12.28% -> 12.28%     
client [5]  (testset)   loss: 2.1607 -> 2.1780  accuracy: 26.09% -> 26.09%     
client [96] (testset)   loss: 2.0733 -> 2.0890  accuracy: 30.36% -> 30.36%     
client [22] (testset)   loss: 1.9050 -> 1.8543  accuracy: 46.00% -> 46.00%     
client [60] (testset)   loss: 2.1868 -> 2.1759  accuracy: 28.57% -> 28.57%     
client [66] (testset)   loss: 2.1743 -> 2.1770  accuracy: 19.05% -> 19.05%     
client [83] (testset)   loss: 2.1133 -> 2.1362  accuracy: 19.57% -> 19.57%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 1.9053 -> 1.9014  accuracy: 27.78% -> 27.78%     
client [65] (testset)   loss: 2.0010 -> 2.0456  accuracy: 37.74% -> 37.74%     
client [95] (testset)   loss: 1.9913 -> 1.9974  accuracy: 34.25% -> 34.25%     
client [17] (testset)   loss: 1.9791 -> 2.0088  accuracy: 32.00% -> 32.00%     
client [8]  (testset)   loss: 1.8970 -> 1.8865  accuracy: 34.17% -> 34.17%     
client [35] (testset)   loss: 2.0096 -> 1.9818  accuracy: 33.33% -> 33.33%     
client [98] (testset)   loss: 2.0533 -> 2.0521  accuracy: 37.74% -> 37.74%     
client [53] (testset)   loss: 2.0771 -> 2.0942  accuracy: 38.71% -> 38.71%     
client [43] (testset)   loss: 1.4961 -> 1.4955  accuracy: 57.89% -> 57.89%     
client [64] (testset)   loss: 2.2067 -> 2.1907  accuracy: 20.00% -> 20.00%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 1.9831 -> 1.9876  accuracy: 26.32% -> 26.32%     
client [88] (testset)   loss: 2.1979 -> 2.1674  accuracy: 15.79% -> 22.81%     
client [38] (testset)   loss: 2.1942 -> 2.1914  accuracy: 18.92% -> 18.92%     
client [3]  (testset)   loss: 2.4777 -> 2.4817  accuracy: 9.26% -> 9.26%       
client [5]  (testset)   loss: 2.1581 -> 2.1667  accuracy: 26.09% -> 26.09%     
client [41] (testset)   loss: 2.0165 -> 2.0142  accuracy: 26.92% -> 26.92%     
client [7]  (testset)   loss: 1.9344 -> 1.9337  accuracy: 32.79% -> 32.79%     
client [37] (testset)   loss: 1.9410 -> 1.9420  accuracy: 40.48% -> 40.48%     
client [45] (testset)   loss: 2.0376 -> 2.0605  accuracy: 34.78% -> 34.78%     
client [47] (testset)   loss: 1.7744 -> 1.7080  accuracy: 16.67% -> 47.22%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 2.0303 -> 2.0352  accuracy: 26.67% -> 26.67%     
client [11] (testset)   loss: 1.9721 -> 1.9860  accuracy: 30.36% -> 30.36%     
client [37] (testset)   loss: 1.9410 -> 1.9559  accuracy: 40.48% -> 40.48%     
client [41] (testset)   loss: 2.0121 -> 2.0117  accuracy: 26.92% -> 26.92%     
client [95] (testset)   loss: 2.0220 -> 2.0114  accuracy: 34.25% -> 34.25%     
client [53] (testset)   loss: 2.0768 -> 2.0926  accuracy: 38.71% -> 38.71%     
client [22] (testset)   loss: 1.8491 -> 1.8522  accuracy: 46.00% -> 46.00%     
client [25] (testset)   loss: 2.4841 -> 2.4678  accuracy: 12.00% -> 12.00%     
client [69] (testset)   loss: 2.0143 -> 2.0251  accuracy: 29.41% -> 29.41%     
client [46] (testset)   loss: 1.8296 -> 1.8327  accuracy: 48.94% -> 48.94%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 1.7171 -> 1.7304  accuracy: 47.22% -> 47.22%     
client [69] (testset)   loss: 2.0186 -> 2.0203  accuracy: 29.41% -> 29.41%     
client [82] (testset)   loss: 1.9282 -> 1.8926  accuracy: 11.94% -> 40.30%     
client [45] (testset)   loss: 2.0443 -> 2.0598  accuracy: 34.78% -> 34.78%     
client [7]  (testset)   loss: 1.9449 -> 1.9328  accuracy: 32.79% -> 32.79%     
client [50] (testset)   loss: 2.1228 -> 2.0861  accuracy: 29.87% -> 29.87%     
client [35] (testset)   loss: 1.9952 -> 1.9854  accuracy: 33.33% -> 33.33%     
client [24] (testset)   loss: 2.2130 -> 2.2046  accuracy: 36.00% -> 36.00%     
client [15] (testset)   loss: 1.5194 -> 1.5008  accuracy: 61.04% -> 61.04%     
client [58] (testset)   loss: 1.6782 -> 1.6759  accuracy: 42.47% -> 42.47%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 2.2858 -> 2.2847  accuracy: 17.39% -> 17.39%     
client [76] (testset)   loss: 1.9095 -> 1.8987  accuracy: 27.78% -> 27.78%     
client [67] (testset)   loss: 2.0943 -> 2.0734  accuracy: 17.54% -> 17.54%     
client [37] (testset)   loss: 1.9381 -> 1.9377  accuracy: 40.48% -> 40.48%     
client [58] (testset)   loss: 1.6768 -> 1.6774  accuracy: 42.47% -> 42.47%     
client [64] (testset)   loss: 2.1896 -> 2.1844  accuracy: 20.00% -> 20.00%     
client [77] (testset)   loss: 1.9847 -> 1.9797  accuracy: 30.00% -> 30.00%     
client [55] (testset)   loss: 1.8985 -> 1.8940  accuracy: 42.62% -> 42.62%     
client [12] (testset)   loss: 1.8931 -> 1.8886  accuracy: 22.03% -> 23.73%     
client [89] (testset)   loss: 1.8881 -> 1.8532  accuracy: 46.88% -> 46.88%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 1.6391 -> 1.6353  accuracy: 38.53% -> 38.53%     
client [51] (testset)   loss: 1.7942 -> 1.7965  accuracy: 47.42% -> 47.42%     
client [8]  (testset)   loss: 1.9002 -> 1.8746  accuracy: 34.17% -> 34.17%     
client [18] (testset)   loss: 2.3024 -> 2.3391  accuracy: 6.98% -> 20.93%      
client [94] (testset)   loss: 1.8028 -> 1.7792  accuracy: 31.71% -> 31.71%     
client [81] (testset)   loss: 2.0012 -> 2.0068  accuracy: 35.14% -> 35.14%     
client [3]  (testset)   loss: 2.4457 -> 2.3865  accuracy: 9.26% -> 9.26%       
client [11] (testset)   loss: 1.9892 -> 1.9671  accuracy: 30.36% -> 30.36%     
client [95] (testset)   loss: 2.0169 -> 2.0143  accuracy: 34.25% -> 34.25%     
client [67] (testset)   loss: 2.0772 -> 2.0756  accuracy: 17.54% -> 19.30%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 1.9549 -> 1.9585  accuracy: 26.32% -> 26.32%     
client [79] (testset)   loss: 2.2724 -> 2.2891  accuracy: 21.15% -> 21.15%     
client [58] (testset)   loss: 1.6783 -> 1.6775  accuracy: 42.47% -> 42.47%     
client [88] (testset)   loss: 2.1709 -> 2.1849  accuracy: 22.81% -> 22.81%     
client [46] (testset)   loss: 1.8302 -> 1.8322  accuracy: 48.94% -> 48.94%     
client [11] (testset)   loss: 1.9694 -> 1.9730  accuracy: 30.36% -> 30.36%     
client [55] (testset)   loss: 1.8996 -> 1.9021  accuracy: 42.62% -> 42.62%     
client [13] (testset)   loss: 2.4816 -> 2.4894  accuracy: 22.22% -> 22.22%     
client [31] (testset)   loss: 1.8609 -> 1.8653  accuracy: 44.44% -> 44.44%     
client [75] (testset)   loss: 2.1837 -> 2.1623  accuracy: 24.07% -> 22.22%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 2.1551 -> 2.1709  accuracy: 23.21% -> 23.21%     
client [7]  (testset)   loss: 1.9352 -> 1.9317  accuracy: 32.79% -> 32.79%     
client [57] (testset)   loss: 2.0901 -> 2.1008  accuracy: 34.78% -> 34.78%     
client [13] (testset)   loss: 2.5165 -> 2.4609  accuracy: 22.22% -> 22.22%     
client [43] (testset)   loss: 1.4934 -> 1.4931  accuracy: 57.89% -> 57.89%     
client [91] (testset)   loss: 2.0077 -> 2.0332  accuracy: 13.79% -> 13.79%     
client [10] (testset)   loss: 2.0924 -> 2.0994  accuracy: 38.89% -> 38.89%     
client [64] (testset)   loss: 2.1969 -> 2.1905  accuracy: 20.00% -> 20.00%     
client [82] (testset)   loss: 1.8938 -> 1.9019  accuracy: 40.30% -> 40.30%     
client [22] (testset)   loss: 1.8657 -> 1.8569  accuracy: 46.00% -> 46.00%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 2.1768 -> 2.1868  accuracy: 18.03% -> 18.03%     
client [23] (testset)   loss: 2.1432 -> 2.1455  accuracy: 20.59% -> 20.59%     
client [88] (testset)   loss: 2.1971 -> 2.1589  accuracy: 22.81% -> 22.81%     
client [98] (testset)   loss: 2.0530 -> 2.0539  accuracy: 37.74% -> 37.74%     
client [79] (testset)   loss: 2.2802 -> 2.2837  accuracy: 21.15% -> 21.15%     
client [21] (testset)   loss: 1.9678 -> 1.9539  accuracy: 26.32% -> 26.32%     
client [92] (testset)   loss: 2.1087 -> 2.1051  accuracy: 26.47% -> 26.47%     
client [56] (testset)   loss: 2.1021 -> 2.1543  accuracy: 7.27% -> 7.27%       
client [5]  (testset)   loss: 2.1650 -> 2.2223  accuracy: 26.09% -> 26.09%     
client [52] (testset)   loss: 1.2904 -> 1.2734  accuracy: 57.14% -> 57.14%     
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 2.0646 -> 2.0733  accuracy: 19.30% -> 19.30%     
client [54] (testset)   loss: 2.4926 -> 2.6896  accuracy: 18.75% -> 18.75%     
client [14] (testset)   loss: 2.0427 -> 2.0544  accuracy: 31.88% -> 31.88%     
client [99] (testset)   loss: 2.0818 -> 2.0711  accuracy: 10.26% -> 10.26%     
client [36] (testset)   loss: 2.0458 -> 2.0512  accuracy: 24.49% -> 24.49%     
client [30] (testset)   loss: 2.3848 -> 2.3591  accuracy: 15.15% -> 15.15%     
client [38] (testset)   loss: 2.1826 -> 2.1905  accuracy: 18.92% -> 18.92%     
client [15] (testset)   loss: 1.5185 -> 1.5105  accuracy: 61.04% -> 61.04%     
client [6]  (testset)   loss: 2.0237 -> 2.0384  accuracy: 21.54% -> 21.54%     
client [53] (testset)   loss: 2.0617 -> 2.0844  accuracy: 38.71% -> 38.71%     
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [99] (testset)   loss: 2.0690 -> 2.0745  accuracy: 20.51% -> 10.26%     
client [6]  (testset)   loss: 2.0312 -> 2.0263  accuracy: 21.54% -> 21.54%     
client [83] (testset)   loss: 2.1212 -> 2.1301  accuracy: 19.57% -> 19.57%     
client [42] (testset)   loss: 2.2697 -> 2.2924  accuracy: 7.14% -> 7.14%       
client [34] (testset)   loss: 1.9088 -> 1.9061  accuracy: 24.59% -> 24.59%     
client [15] (testset)   loss: 1.5168 -> 1.5066  accuracy: 61.04% -> 61.04%     
client [47] (testset)   loss: 1.7181 -> 1.7134  accuracy: 47.22% -> 47.22%     
client [55] (testset)   loss: 1.8985 -> 1.8983  accuracy: 42.62% -> 42.62%     
client [51] (testset)   loss: 1.7946 -> 1.7967  accuracy: 47.42% -> 47.42%     
client [95] (testset)   loss: 1.9841 -> 1.9996  accuracy: 34.25% -> 34.25%     
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 2.0272 -> 2.0191  accuracy: 23.33% -> 23.33%     
client [15] (testset)   loss: 1.5191 -> 1.4864  accuracy: 61.04% -> 61.04%     
client [33] (testset)   loss: 1.7521 -> 1.8078  accuracy: 44.44% -> 22.22%     
client [99] (testset)   loss: 2.0725 -> 2.0765  accuracy: 10.26% -> 10.26%     
client [90] (testset)   loss: 1.9786 -> 1.9753  accuracy: 25.00% -> 25.00%     
client [57] (testset)   loss: 2.0952 -> 2.0824  accuracy: 34.78% -> 34.78%     
client [27] (testset)   loss: 1.9753 -> 1.9855  accuracy: 38.75% -> 38.75%     
client [78] (testset)   loss: 1.9081 -> 1.9176  accuracy: 22.73% -> 22.73%     
client [36] (testset)   loss: 2.0573 -> 2.0519  accuracy: 24.49% -> 24.49%     
client [88] (testset)   loss: 2.1594 -> 2.1887  accuracy: 22.81% -> 22.81%     
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 2.2578 -> 2.2106  accuracy: 25.00% -> 25.00%     
client [35] (testset)   loss: 2.0182 -> 2.0010  accuracy: 33.33% -> 33.33%     
client [16] (testset)   loss: 2.0310 -> 2.0270  accuracy: 26.67% -> 26.67%     
client [80] (testset)   loss: 2.1650 -> 2.1801  accuracy: 38.18% -> 38.18%     
client [38] (testset)   loss: 2.1805 -> 2.1906  accuracy: 18.92% -> 18.92%     
client [78] (testset)   loss: 1.9076 -> 1.9170  accuracy: 22.73% -> 22.73%     
client [68] (testset)   loss: 1.7448 -> 1.7522  accuracy: 37.78% -> 37.78%     
client [11] (testset)   loss: 1.9839 -> 1.9824  accuracy: 30.36% -> 30.36%     
client [64] (testset)   loss: 2.2025 -> 2.1908  accuracy: 20.00% -> 20.00%     
client [82] (testset)   loss: 1.9098 -> 1.8946  accuracy: 40.30% -> 40.30%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 2.3745 -> 2.3469  accuracy: 15.15% -> 15.15%     
client [27] (testset)   loss: 1.9734 -> 1.9817  accuracy: 38.75% -> 38.75%     
client [74] (testset)   loss: 2.0041 -> 2.0070  accuracy: 19.30% -> 19.30%     
client [45] (testset)   loss: 2.0449 -> 2.0474  accuracy: 34.78% -> 34.78%     
client [6]  (testset)   loss: 2.0487 -> 2.0486  accuracy: 21.54% -> 21.54%     
client [36] (testset)   loss: 2.0767 -> 2.0525  accuracy: 24.49% -> 24.49%     
client [63] (testset)   loss: 1.9765 -> 1.9845  accuracy: 31.67% -> 31.67%     
client [76] (testset)   loss: 1.9011 -> 1.8836  accuracy: 27.78% -> 27.78%     
client [83] (testset)   loss: 2.1602 -> 2.1316  accuracy: 19.57% -> 19.57%     
client [86] (testset)   loss: 1.6997 -> 1.6938  accuracy: 48.44% -> 48.44%     
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 2.1306 -> 2.1298  accuracy: 19.57% -> 19.57%     
client [99] (testset)   loss: 2.0723 -> 2.0716  accuracy: 20.51% -> 20.51%     
client [74] (testset)   loss: 2.0002 -> 1.9989  accuracy: 28.07% -> 19.30%     
client [73] (testset)   loss: 2.3425 -> 2.3342  accuracy: 21.05% -> 21.05%     
client [29] (testset)   loss: 1.7967 -> 1.7648  accuracy: 37.66% -> 37.66%     
client [92] (testset)   loss: 2.1054 -> 2.1089  accuracy: 26.47% -> 26.47%     
client [6]  (testset)   loss: 2.0165 -> 2.0200  accuracy: 21.54% -> 21.54%     
client [61] (testset)   loss: 2.1848 -> 2.2428  accuracy: 26.67% -> 26.67%     
client [21] (testset)   loss: 1.9522 -> 1.9572  accuracy: 26.32% -> 26.32%     
client [67] (testset)   loss: 2.0870 -> 2.0817  accuracy: 19.30% -> 19.30%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 2.1259 -> 2.1239  accuracy: 19.57% -> 19.57%     
client [32] (testset)   loss: 1.9758 -> 1.9856  accuracy: 30.43% -> 30.43%     
client [95] (testset)   loss: 2.0280 -> 2.0062  accuracy: 34.25% -> 34.25%     
client [61] (testset)   loss: 2.2377 -> 2.2202  accuracy: 26.67% -> 26.67%     
client [27] (testset)   loss: 1.9776 -> 1.9995  accuracy: 38.75% -> 38.75%     
client [25] (testset)   loss: 2.4767 -> 2.4571  accuracy: 12.00% -> 12.00%     
client [68] (testset)   loss: 1.7522 -> 1.7523  accuracy: 37.78% -> 37.78%     
client [34] (testset)   loss: 1.9105 -> 1.9087  accuracy: 24.59% -> 24.59%     
client [71] (testset)   loss: 2.0276 -> 2.0243  accuracy: 23.33% -> 23.33%     
client [89] (testset)   loss: 1.8599 -> 1.9127  accuracy: 46.88% -> 46.88%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 1.9175 -> 1.9159  accuracy: 22.73% -> 22.73%     
client [81] (testset)   loss: 2.0085 -> 2.0068  accuracy: 35.14% -> 35.14%     
client [51] (testset)   loss: 1.7797 -> 1.7877  accuracy: 47.42% -> 47.42%     
client [54] (testset)   loss: 2.4072 -> 2.3576  accuracy: 18.75% -> 18.75%     
client [65] (testset)   loss: 2.0088 -> 1.9990  accuracy: 37.74% -> 37.74%     
client [41] (testset)   loss: 2.0182 -> 2.0146  accuracy: 26.92% -> 26.92%     
client [11] (testset)   loss: 1.9780 -> 1.9813  accuracy: 30.36% -> 30.36%     
client [85] (testset)   loss: 2.0548 -> 2.0436  accuracy: 29.33% -> 29.33%     
client [12] (testset)   loss: 1.8913 -> 1.8956  accuracy: 23.73% -> 23.73%     
client [23] (testset)   loss: 2.1687 -> 2.1735  accuracy: 20.59% -> 20.59%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 2.0297 -> 2.0318  accuracy: 26.67% -> 26.67%     
client [65] (testset)   loss: 2.0077 -> 1.9994  accuracy: 37.74% -> 37.74%     
client [53] (testset)   loss: 2.0647 -> 2.0906  accuracy: 38.71% -> 38.71%     
client [58] (testset)   loss: 1.6797 -> 1.6804  accuracy: 42.47% -> 42.47%     
client [72] (testset)   loss: 1.7779 -> 1.7773  accuracy: 53.70% -> 53.70%     
client [7]  (testset)   loss: 1.9330 -> 1.9330  accuracy: 32.79% -> 32.79%     
client [71] (testset)   loss: 2.0170 -> 2.0229  accuracy: 23.33% -> 23.33%     
client [59] (testset)   loss: 2.0992 -> 2.1066  accuracy: 24.14% -> 24.14%     
client [86] (testset)   loss: 1.6950 -> 1.6920  accuracy: 48.44% -> 48.44%     
client [39] (testset)   loss: 1.4054 -> 1.4065  accuracy: 53.77% -> 53.77%     
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 2.0721 -> 2.0733  accuracy: 10.26% -> 10.26%     
client [7]  (testset)   loss: 1.9321 -> 1.9315  accuracy: 32.79% -> 32.79%     
client [17] (testset)   loss: 2.0007 -> 1.9944  accuracy: 32.00% -> 32.00%     
client [64] (testset)   loss: 2.1893 -> 2.1866  accuracy: 20.00% -> 20.00%     
client [37] (testset)   loss: 1.9324 -> 1.9492  accuracy: 40.48% -> 40.48%     
client [29] (testset)   loss: 1.7684 -> 1.7778  accuracy: 37.66% -> 37.66%     
client [93] (testset)   loss: 1.6968 -> 1.6989  accuracy: 45.65% -> 45.65%     
client [73] (testset)   loss: 2.3431 -> 2.3342  accuracy: 21.05% -> 12.28%     
client [40] (testset)   loss: 2.1513 -> 2.1494  accuracy: 21.74% -> 21.74%     
client [76] (testset)   loss: 1.9037 -> 1.8827  accuracy: 27.78% -> 27.78%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 1.8646 -> 1.8662  accuracy: 44.44% -> 44.44%     
client [89] (testset)   loss: 1.8491 -> 1.8428  accuracy: 46.88% -> 46.88%     
client [77] (testset)   loss: 1.9872 -> 1.9789  accuracy: 30.00% -> 30.00%     
client [90] (testset)   loss: 1.9851 -> 1.9774  accuracy: 25.00% -> 25.00%     
client [26] (testset)   loss: 2.1808 -> 2.1817  accuracy: 22.81% -> 22.81%     
client [50] (testset)   loss: 2.0940 -> 2.1012  accuracy: 29.87% -> 29.87%     
client [30] (testset)   loss: 2.3506 -> 2.3529  accuracy: 15.15% -> 15.15%     
client [70] (testset)   loss: 2.2404 -> 2.2166  accuracy: 25.00% -> 25.00%     
client [41] (testset)   loss: 2.0271 -> 2.0139  accuracy: 26.92% -> 26.92%     
client [99] (testset)   loss: 2.0741 -> 2.0663  accuracy: 10.26% -> 20.51%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [68] (testset)   loss: 1.7534 -> 1.7581  accuracy: 37.78% -> 37.78%     
client [70] (testset)   loss: 2.3028 -> 2.2457  accuracy: 25.00% -> 25.00%     
client [52] (testset)   loss: 1.3420 -> 1.3265  accuracy: 57.14% -> 57.14%     
client [1]  (testset)   loss: 2.4111 -> 2.4008  accuracy: 4.17% -> 12.50%      
client [2]  (testset)   loss: 1.7707 -> 1.7755  accuracy: 49.40% -> 49.40%     
client [67] (testset)   loss: 2.0777 -> 2.0835  accuracy: 19.30% -> 19.30%     
client [92] (testset)   loss: 2.1060 -> 2.1072  accuracy: 26.47% -> 26.47%     
client [35] (testset)   loss: 1.9902 -> 1.9969  accuracy: 33.33% -> 33.33%     
client [36] (testset)   loss: 2.0540 -> 2.0556  accuracy: 24.49% -> 24.49%     
client [64] (testset)   loss: 2.1994 -> 2.1862  accuracy: 20.00% -> 20.00%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 2.1344 -> 2.1242  accuracy: 23.21% -> 23.21%     
client [6]  (testset)   loss: 2.0296 -> 2.0052  accuracy: 21.54% -> 21.54%     
client [12] (testset)   loss: 1.9012 -> 1.8821  accuracy: 22.03% -> 23.73%     
client [55] (testset)   loss: 1.9024 -> 1.9011  accuracy: 42.62% -> 42.62%     
client [29] (testset)   loss: 1.7631 -> 1.7906  accuracy: 37.66% -> 37.66%     
client [9]  (testset)   loss: 2.3002 -> 2.3527  accuracy: 13.33% -> 13.33%     
client [43] (testset)   loss: 1.4886 -> 1.4912  accuracy: 57.89% -> 57.89%     
client [77] (testset)   loss: 1.9821 -> 1.9796  accuracy: 30.00% -> 30.00%     
client [98] (testset)   loss: 2.0569 -> 2.0554  accuracy: 37.74% -> 37.74%     
client [78] (testset)   loss: 1.9174 -> 1.9215  accuracy: 22.73% -> 22.73%     
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 2.1114 -> 2.1057  accuracy: 26.47% -> 26.47%     
client [80] (testset)   loss: 2.1592 -> 2.1565  accuracy: 38.18% -> 38.18%     
client [63] (testset)   loss: 1.9918 -> 1.9802  accuracy: 31.67% -> 31.67%     
client [76] (testset)   loss: 1.8948 -> 1.8931  accuracy: 27.78% -> 27.78%     
client [78] (testset)   loss: 1.9167 -> 1.9133  accuracy: 22.73% -> 22.73%     
client [25] (testset)   loss: 2.4148 -> 2.4565  accuracy: 12.00% -> 12.00%     
client [58] (testset)   loss: 1.6750 -> 1.6761  accuracy: 42.47% -> 42.47%     
client [13] (testset)   loss: 2.4842 -> 2.5095  accuracy: 22.22% -> 22.22%     
client [17] (testset)   loss: 2.0078 -> 2.0224  accuracy: 32.00% -> 32.00%     
client [38] (testset)   loss: 2.1996 -> 2.1878  accuracy: 18.92% -> 18.92%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 1.7695 -> 1.7857  accuracy: 53.70% -> 53.70%     
client [82] (testset)   loss: 1.9396 -> 1.9220  accuracy: 11.94% -> 11.94%     
client [86] (testset)   loss: 1.6952 -> 1.6927  accuracy: 48.44% -> 48.44%     
client [51] (testset)   loss: 1.7898 -> 1.7896  accuracy: 47.42% -> 47.42%     
client [96] (testset)   loss: 2.0780 -> 2.0792  accuracy: 30.36% -> 30.36%     
client [42] (testset)   loss: 2.2712 -> 2.2726  accuracy: 7.14% -> 7.14%       
client [55] (testset)   loss: 1.8974 -> 1.8983  accuracy: 42.62% -> 42.62%     
client [13] (testset)   loss: 2.5053 -> 2.4954  accuracy: 22.22% -> 22.22%     
client [1]  (testset)   loss: 2.4036 -> 2.4248  accuracy: 12.50% -> 4.17%      
client [12] (testset)   loss: 1.8916 -> 1.8921  accuracy: 23.73% -> 23.73%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 1.7667 -> 1.7707  accuracy: 37.78% -> 37.78%     
client [23] (testset)   loss: 2.1507 -> 2.1474  accuracy: 20.59% -> 20.59%     
client [46] (testset)   loss: 1.8571 -> 1.8473  accuracy: 48.94% -> 48.94%     
client [41] (testset)   loss: 2.0219 -> 2.0201  accuracy: 26.92% -> 26.92%     
client [25] (testset)   loss: 2.4546 -> 2.4574  accuracy: 12.00% -> 12.00%     
client [58] (testset)   loss: 1.6806 -> 1.6813  accuracy: 42.47% -> 42.47%     
client [14] (testset)   loss: 2.0587 -> 2.0532  accuracy: 31.88% -> 31.88%     
client [33] (testset)   loss: 1.8232 -> 1.7663  accuracy: 22.22% -> 44.44%     
client [85] (testset)   loss: 2.1129 -> 2.0401  accuracy: 29.33% -> 29.33%     
client [62] (testset)   loss: 1.8975 -> 1.8754  accuracy: 41.38% -> 41.38%     
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 2.0551 -> 2.0553  accuracy: 37.74% -> 37.74%     
client [63] (testset)   loss: 1.9739 -> 1.9814  accuracy: 31.67% -> 31.67%     
client [70] (testset)   loss: 2.2385 -> 2.2178  accuracy: 25.00% -> 25.00%     
client [65] (testset)   loss: 1.9892 -> 2.0146  accuracy: 37.74% -> 37.74%     
client [14] (testset)   loss: 2.0654 -> 2.0535  accuracy: 31.88% -> 31.88%     
client [73] (testset)   loss: 2.3343 -> 2.3326  accuracy: 21.05% -> 21.05%     
client [34] (testset)   loss: 1.9099 -> 1.9064  accuracy: 24.59% -> 24.59%     
client [99] (testset)   loss: 2.0702 -> 2.0670  accuracy: 20.51% -> 20.51%     
client [69] (testset)   loss: 2.0195 -> 2.0206  accuracy: 29.41% -> 29.41%     
client [46] (testset)   loss: 1.8454 -> 1.8440  accuracy: 48.94% -> 48.94%     
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [99] (testset)   loss: 2.0741 -> 2.0722  accuracy: 10.26% -> 10.26%     
client [93] (testset)   loss: 1.6991 -> 1.7067  accuracy: 45.65% -> 45.65%     
client [11] (testset)   loss: 1.9832 -> 1.9892  accuracy: 30.36% -> 30.36%     
client [58] (testset)   loss: 1.6842 -> 1.6771  accuracy: 42.47% -> 42.47%     
client [81] (testset)   loss: 2.0104 -> 2.0089  accuracy: 35.14% -> 35.14%     
client [85] (testset)   loss: 2.0513 -> 2.0692  accuracy: 29.33% -> 29.33%     
client [89] (testset)   loss: 1.8646 -> 1.8631  accuracy: 46.88% -> 46.88%     
client [45] (testset)   loss: 2.0289 -> 2.0494  accuracy: 34.78% -> 34.78%     
client [8]  (testset)   loss: 1.8758 -> 1.8803  accuracy: 34.17% -> 34.17%     
client [68] (testset)   loss: 1.7371 -> 1.7423  accuracy: 37.78% -> 37.78%     
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 2.0629 -> 2.0790  accuracy: 19.30% -> 19.30%     
client [72] (testset)   loss: 1.7681 -> 1.7880  accuracy: 53.70% -> 53.70%     
client [1]  (testset)   loss: 2.4047 -> 2.4266  accuracy: 4.17% -> 4.17%       
client [78] (testset)   loss: 1.9171 -> 1.9160  accuracy: 22.73% -> 22.73%     
client [83] (testset)   loss: 2.1441 -> 2.1270  accuracy: 19.57% -> 19.57%     
client [21] (testset)   loss: 1.9610 -> 1.9584  accuracy: 26.32% -> 26.32%     
client [56] (testset)   loss: 2.1383 -> 2.1019  accuracy: 7.27% -> 7.27%       
client [44] (testset)   loss: 2.1199 -> 2.1362  accuracy: 23.21% -> 23.21%     
client [92] (testset)   loss: 2.1082 -> 2.1013  accuracy: 26.47% -> 26.47%     
client [27] (testset)   loss: 1.9931 -> 1.9952  accuracy: 38.75% -> 38.75%     
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 2.0978 -> 2.0975  accuracy: 38.89% -> 38.89%     
client [39] (testset)   loss: 1.4135 -> 1.4237  accuracy: 53.77% -> 53.77%     
client [65] (testset)   loss: 2.0071 -> 2.0201  accuracy: 37.74% -> 37.74%     
client [26] (testset)   loss: 2.1764 -> 2.1743  accuracy: 19.30% -> 22.81%     
client [19] (testset)   loss: 2.1656 -> 2.1949  accuracy: 23.21% -> 23.21%     
client [68] (testset)   loss: 1.7502 -> 1.7766  accuracy: 37.78% -> 37.78%     
client [41] (testset)   loss: 2.0216 -> 2.0201  accuracy: 26.92% -> 26.92%     
client [50] (testset)   loss: 2.1233 -> 2.1031  accuracy: 29.87% -> 29.87%     
client [75] (testset)   loss: 2.1410 -> 2.1348  accuracy: 24.07% -> 22.22%     
client [81] (testset)   loss: 2.0165 -> 2.0019  accuracy: 35.14% -> 35.14%     
Training... ---------------------------------------- 100% 0:07:15
FedRoD's average time taken by each global epoch: 0 min 1.08 sec.              
FedRoD's total running time: 0 h 7 m 15 s.                                     
==================== FedRoD Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9840 -> 0.0000",                                    
                "accuracy": "30.70% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9946 -> 0.0000",                                    
                "accuracy": "30.97% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9838 -> 0.0000",                                    
                "accuracy": "31.46% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9810 -> 0.0000",                                    
                "accuracy": "31.07% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedRoD Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 31.46% at epoch 300                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
[0m