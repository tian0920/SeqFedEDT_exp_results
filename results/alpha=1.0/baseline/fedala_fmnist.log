==================== FedALA ====================                               
Experiment Arguments:                                                          
{
│   'method': 'fedala',
│   'dataset': {
│   │   'name': 'fmnist',
│   │   'client_num': 100,
│   │   'test_ratio': 0.25,
│   │   'val_ratio': 0.0,
│   │   'seed': 42,
│   │   'split': 'sample',
│   │   'IID_ratio': 0.0,
│   │   'monitor_window_name_suffix': 'fmnist-100clients-0%IID-Dir(1.0)-seed42',
│   │   'alpha': 1.0,
│   │   'min_samples_per_client': 10
│   },
│   'model': {
│   │   'name': 'avgcnn',
│   │   'use_torchvision_pretrained_weights': True,
│   │   'external_model_weights_path': None
│   },
│   'optimizer': {
│   │   'lr': 0.01,
│   │   'dampening': 0,
│   │   'weight_decay': 0,
│   │   'momentum': 0,
│   │   'nesterov': False,
│   │   'name': 'sgd'
│   },
│   'mode': 'serial',
│   'parallel': {
│   │   'ray_cluster_addr': None,
│   │   'num_cpus': None,
│   │   'num_gpus': None,
│   │   'num_workers': 2
│   },
│   'common': {
│   │   'seed': 42,
│   │   'join_ratio': 0.1,
│   │   'global_epoch': 400,
│   │   'local_epoch': 5,
│   │   'batch_size': 32,
│   │   'reset_optimizer_on_global_epoch': True,
│   │   'straggler_ratio': 0,
│   │   'straggler_min_local_epoch': 0,
│   │   'buffers': 'global',
│   │   'client_side_evaluation': True,
│   │   'test': {
│   │   │   'client': {
│   │   │   │   'interval': 100,
│   │   │   │   'finetune_epoch': 0,
│   │   │   │   'train': False,
│   │   │   │   'val': False,
│   │   │   │   'test': True
│   │   │   },
│   │   │   'server': {
│   │   │   │   'interval': -1,
│   │   │   │   'train': False,
│   │   │   │   'val': False,
│   │   │   │   'test': False,
│   │   │   │   'model_in_train_mode': False
│   │   │   }
│   │   },
│   │   'verbose_gap': 10,
│   │   'monitor': None,
│   │   'use_cuda': True,
│   │   'save_log': True,
│   │   'save_model': False,
│   │   'save_learning_curve_plot': False,
│   │   'save_metrics': True,
│   │   'delete_useless_run': True
│   },
│   'fedala': {
│   │   'layer_idx': 2,
│   │   'num_pre_loss': 10,
│   │   'eta': 1.0,
│   │   'threshold': 0.1,
│   │   'rand_percent': 0.8
│   }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 0.7148 -> 0.7240  accuracy: 72.50% -> 74.17%     
client [81] (testset)   loss: 0.6650 -> 0.5545  accuracy: 73.57% -> 77.53%     
client [21] (testset)   loss: 0.6364 -> 0.5008  accuracy: 78.53% -> 85.89%     
client [68] (testset)   loss: 0.7233 -> 0.6356  accuracy: 73.61% -> 75.00%     
client [93] (testset)   loss: 0.8198 -> 0.8781  accuracy: 64.84% -> 72.66%     
client [31] (testset)   loss: 0.7022 -> 0.5317  accuracy: 65.83% -> 80.22%     
client [20] (testset)   loss: 0.6352 -> 0.6152  accuracy: 79.29% -> 77.86%     
client [59] (testset)   loss: 0.3593 -> 0.2913  accuracy: 88.48% -> 89.01%     
client [48] (testset)   loss: 0.4983 -> 0.3837  accuracy: 86.14% -> 84.65%     
client [34] (testset)   loss: 0.5635 -> 0.4697  accuracy: 76.44% -> 81.68%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 0.5016 -> 0.3637  accuracy: 84.25% -> 82.88%     
client [99] (testset)   loss: 0.4645 -> 0.3089  accuracy: 85.28% -> 90.18%     
client [67] (testset)   loss: 0.4232 -> 0.3660  accuracy: 85.63% -> 87.93%     
client [0]  (testset)   loss: 0.4599 -> 0.4406  accuracy: 84.68% -> 85.96%     
client [76] (testset)   loss: 0.3708 -> 0.3362  accuracy: 86.59% -> 88.83%     
client [41] (testset)   loss: 0.6227 -> 0.5982  accuracy: 79.07% -> 76.74%     
client [62] (testset)   loss: 0.5227 -> 0.6589  accuracy: 82.14% -> 79.29%     
client [2]  (testset)   loss: 0.5268 -> 0.4700  accuracy: 80.53% -> 79.65%     
client [14] (testset)   loss: 0.4238 -> 0.8691  accuracy: 83.57% -> 77.46%     
client [46] (testset)   loss: 0.4575 -> 0.3683  accuracy: 84.33% -> 83.58%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 0.2956 -> 0.2847  accuracy: 89.38% -> 88.05%     
client [68] (testset)   loss: 0.4856 -> 0.5097  accuracy: 80.56% -> 80.56%     
client [57] (testset)   loss: 0.2893 -> 0.2759  accuracy: 91.13% -> 87.90%     
client [17] (testset)   loss: 0.3562 -> 0.1784  accuracy: 89.29% -> 93.88%     
client [54] (testset)   loss: 0.2271 -> 0.2048  accuracy: 93.10% -> 93.68%     
client [23] (testset)   loss: 0.7930 -> 0.3469  accuracy: 69.16% -> 86.69%     
client [35] (testset)   loss: 0.3164 -> 0.2192  accuracy: 87.09% -> 93.05%     
client [59] (testset)   loss: 0.3415 -> 0.1891  accuracy: 91.10% -> 93.72%     
client [31] (testset)   loss: 0.5108 -> 0.4239  accuracy: 78.42% -> 85.25%     
client [9]  (testset)   loss: 0.4488 -> 0.4513  accuracy: 84.62% -> 82.25%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 0.4283 -> 0.4324  accuracy: 85.03% -> 84.13%     
client [33] (testset)   loss: 0.3223 -> 0.3473  accuracy: 87.88% -> 86.36%     
client [16] (testset)   loss: 0.2407 -> 0.1043  accuracy: 89.42% -> 96.83%     
client [44] (testset)   loss: 0.2922 -> 0.2441  accuracy: 88.65% -> 90.81%     
client [8]  (testset)   loss: 0.4605 -> 0.4022  accuracy: 82.73% -> 84.89%     
client [31] (testset)   loss: 0.4147 -> 0.4721  accuracy: 84.17% -> 80.58%     
client [47] (testset)   loss: 0.2514 -> 0.2067  accuracy: 92.00% -> 93.60%     
client [36] (testset)   loss: 0.4215 -> 0.8088  accuracy: 82.98% -> 73.76%     
client [20] (testset)   loss: 0.4845 -> 0.4467  accuracy: 82.14% -> 82.86%     
client [56] (testset)   loss: 0.3639 -> 0.4172  accuracy: 86.82% -> 84.50%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 0.5884 -> 0.6693  accuracy: 81.07% -> 75.74%     
client [60] (testset)   loss: 0.3425 -> 0.2148  accuracy: 88.21% -> 93.01%     
client [28] (testset)   loss: 0.3718 -> 0.3736  accuracy: 86.14% -> 88.12%     
client [25] (testset)   loss: 0.3145 -> 0.2050  accuracy: 90.32% -> 91.40%     
client [58] (testset)   loss: 0.5022 -> 0.6683  accuracy: 80.49% -> 74.39%     
client [44] (testset)   loss: 0.2684 -> 0.2489  accuracy: 89.19% -> 89.73%     
client [39] (testset)   loss: 0.5147 -> 0.3138  accuracy: 78.87% -> 88.73%     
client [29] (testset)   loss: 0.3975 -> 0.3938  accuracy: 85.03% -> 84.35%     
client [3]  (testset)   loss: 0.4080 -> 0.3752  accuracy: 86.85% -> 87.25%     
client [84] (testset)   loss: 0.4848 -> 0.3571  accuracy: 82.24% -> 89.47%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 0.4061 -> 0.3425  accuracy: 85.89% -> 87.73%     
client [84] (testset)   loss: 0.4778 -> 0.4500  accuracy: 83.55% -> 86.84%     
client [10] (testset)   loss: 0.3380 -> 0.1996  accuracy: 87.24% -> 91.84%     
client [36] (testset)   loss: 0.3734 -> 0.3612  accuracy: 85.11% -> 86.52%     
client [65] (testset)   loss: 0.3197 -> 0.3193  accuracy: 90.10% -> 90.62%     
client [81] (testset)   loss: 0.4378 -> 0.3373  accuracy: 84.14% -> 85.02%     
client [79] (testset)   loss: 0.4490 -> 0.3016  accuracy: 80.54% -> 88.24%     
client [42] (testset)   loss: 0.4133 -> 0.3013  accuracy: 80.00% -> 93.33%     
client [11] (testset)   loss: 0.2929 -> 0.2812  accuracy: 86.89% -> 90.16%     
client [96] (testset)   loss: 0.3241 -> 0.2900  accuracy: 88.07% -> 90.34%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 0.3316 -> 0.3328  accuracy: 87.77% -> 89.93%     
client [53] (testset)   loss: 0.2839 -> 0.2488  accuracy: 89.05% -> 91.17%     
client [52] (testset)   loss: 0.3518 -> 0.2582  accuracy: 88.14% -> 90.40%     
client [42] (testset)   loss: 0.4250 -> 0.2757  accuracy: 81.11% -> 93.33%     
client [69] (testset)   loss: 0.3130 -> 0.2464  accuracy: 89.73% -> 90.41%     
client [59] (testset)   loss: 0.2525 -> 0.1715  accuracy: 90.58% -> 93.72%     
client [7]  (testset)   loss: 0.3837 -> 0.3554  accuracy: 85.81% -> 84.52%     
client [26] (testset)   loss: 0.1418 -> 0.1529  accuracy: 93.81% -> 96.46%     
client [49] (testset)   loss: 0.3517 -> 0.3623  accuracy: 88.95% -> 86.05%     
client [98] (testset)   loss: 0.4985 -> 0.7578  accuracy: 83.52% -> 74.18%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 0.5421 -> 1.2766  accuracy: 82.42% -> 69.23%     
client [47] (testset)   loss: 0.3003 -> 0.1868  accuracy: 88.80% -> 92.80%     
client [21] (testset)   loss: 0.3721 -> 0.2765  accuracy: 87.73% -> 90.80%     
client [77] (testset)   loss: 0.4305 -> 0.3520  accuracy: 81.67% -> 86.67%     
client [95] (testset)   loss: 0.2891 -> 0.2249  accuracy: 93.17% -> 93.17%     
client [91] (testset)   loss: 0.5118 -> 0.4059  accuracy: 79.50% -> 84.47%     
client [14] (testset)   loss: 0.1803 -> 0.1390  accuracy: 92.02% -> 95.77%     
client [99] (testset)   loss: 0.3084 -> 0.2582  accuracy: 87.73% -> 92.02%     
client [20] (testset)   loss: 0.3780 -> 0.3916  accuracy: 86.43% -> 83.57%     
client [39] (testset)   loss: 0.6680 -> 0.2877  accuracy: 76.06% -> 89.20%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 0.3506 -> 0.2424  accuracy: 88.14% -> 92.66%     
client [62] (testset)   loss: 0.3419 -> 0.3373  accuracy: 88.57% -> 89.29%     
client [71] (testset)   loss: 0.2013 -> 0.2337  accuracy: 93.04% -> 93.04%     
client [97] (testset)   loss: 0.3866 -> 0.3977  accuracy: 84.55% -> 86.18%     
client [30] (testset)   loss: 0.3096 -> 0.2074  accuracy: 84.75% -> 94.07%     
client [88] (testset)   loss: 0.5062 -> 0.8817  accuracy: 83.33% -> 69.27%     
client [60] (testset)   loss: 0.2855 -> 0.1630  accuracy: 90.83% -> 93.45%     
client [82] (testset)   loss: 0.3415 -> 0.2238  accuracy: 86.90% -> 90.48%     
client [91] (testset)   loss: 0.4459 -> 0.4722  accuracy: 80.75% -> 85.71%     
client [57] (testset)   loss: 0.2161 -> 0.2479  accuracy: 94.35% -> 92.74%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 0.4746 -> 0.5652  accuracy: 78.42% -> 79.50%     
client [15] (testset)   loss: 0.1975 -> 0.1809  accuracy: 93.29% -> 93.29%     
client [71] (testset)   loss: 0.2077 -> 0.2066  accuracy: 93.67% -> 94.30%     
client [97] (testset)   loss: 0.4052 -> 0.3950  accuracy: 84.55% -> 86.18%     
client [53] (testset)   loss: 0.3126 -> 0.2347  accuracy: 87.99% -> 92.58%     
client [77] (testset)   loss: 0.3917 -> 0.3425  accuracy: 82.50% -> 86.67%     
client [76] (testset)   loss: 0.1696 -> 0.2043  accuracy: 93.30% -> 91.62%     
client [79] (testset)   loss: 0.4098 -> 0.2820  accuracy: 83.71% -> 88.24%     
client [28] (testset)   loss: 0.2838 -> 0.3135  accuracy: 92.08% -> 89.11%     
client [99] (testset)   loss: 0.3204 -> 0.2549  accuracy: 85.28% -> 92.64%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 0.3621 -> 0.4190  accuracy: 87.80% -> 86.18%     
client [86] (testset)   loss: 0.1611 -> 0.1671  accuracy: 92.63% -> 94.74%     
client [34] (testset)   loss: 0.1952 -> 0.1452  accuracy: 91.10% -> 93.72%     
client [73] (testset)   loss: 0.3741 -> 0.7899  accuracy: 88.59% -> 77.85%     
client [5]  (testset)   loss: 0.3353 -> 0.2748  accuracy: 85.00% -> 89.17%     
client [96] (testset)   loss: 0.2780 -> 0.2209  accuracy: 89.77% -> 93.18%     
client [22] (testset)   loss: 0.4793 -> 0.4506  accuracy: 88.41% -> 86.23%     
client [60] (testset)   loss: 0.3124 -> 0.1800  accuracy: 89.96% -> 93.89%     
client [66] (testset)   loss: 0.2543 -> 0.2649  accuracy: 87.93% -> 88.79%     
client [83] (testset)   loss: 0.4793 -> 0.3668  accuracy: 84.64% -> 88.39%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 0.1673 -> 0.1701  accuracy: 93.30% -> 93.30%     
client [65] (testset)   loss: 0.2797 -> 0.2961  accuracy: 91.67% -> 89.58%     
client [95] (testset)   loss: 0.3065 -> 0.2141  accuracy: 91.93% -> 93.79%     
client [17] (testset)   loss: 0.2015 -> 0.1275  accuracy: 92.86% -> 95.41%     
client [8]  (testset)   loss: 0.2600 -> 0.2891  accuracy: 90.65% -> 89.93%     
client [35] (testset)   loss: 0.1760 -> 0.2479  accuracy: 93.71% -> 89.40%     
client [98] (testset)   loss: 0.4151 -> 0.3885  accuracy: 85.71% -> 90.66%     
client [53] (testset)   loss: 0.2677 -> 0.2482  accuracy: 91.17% -> 91.87%     
client [43] (testset)   loss: 0.0972 -> 0.0703  accuracy: 96.20% -> 97.47%     
client [64] (testset)   loss: 0.2810 -> 0.7308  accuracy: 91.02% -> 74.25%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 0.3363 -> 0.2908  accuracy: 88.96% -> 92.02%     
client [88] (testset)   loss: 0.5265 -> 0.4268  accuracy: 83.33% -> 82.81%     
client [38] (testset)   loss: 0.4287 -> 0.3941  accuracy: 88.49% -> 89.21%     
client [3]  (testset)   loss: 0.3227 -> 0.2754  accuracy: 88.45% -> 92.43%     
client [5]  (testset)   loss: 0.2822 -> 0.2384  accuracy: 88.33% -> 91.67%     
client [41] (testset)   loss: 0.3095 -> 0.3491  accuracy: 89.15% -> 85.27%     
client [7]  (testset)   loss: 0.3243 -> 0.2943  accuracy: 91.61% -> 89.68%     
client [37] (testset)   loss: 0.2264 -> 0.2360  accuracy: 91.61% -> 92.90%     
client [45] (testset)   loss: 0.4524 -> 0.4047  accuracy: 81.65% -> 85.32%     
client [47] (testset)   loss: 0.2246 -> 0.1577  accuracy: 91.20% -> 94.40%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 0.1548 -> 0.0636  accuracy: 94.71% -> 97.88%     
client [11] (testset)   loss: 0.2538 -> 0.2464  accuracy: 87.70% -> 90.98%     
client [37] (testset)   loss: 0.2479 -> 0.2253  accuracy: 89.68% -> 94.19%     
client [41] (testset)   loss: 0.3518 -> 0.8237  accuracy: 88.37% -> 69.77%     
client [95] (testset)   loss: 0.3513 -> 0.1887  accuracy: 90.06% -> 95.03%     
client [53] (testset)   loss: 0.2259 -> 0.2415  accuracy: 91.52% -> 91.87%     
client [22] (testset)   loss: 0.4580 -> 0.4280  accuracy: 89.13% -> 89.13%     
client [25] (testset)   loss: 0.3038 -> 0.1966  accuracy: 90.32% -> 91.04%     
client [69] (testset)   loss: 0.2221 -> 0.1896  accuracy: 93.15% -> 92.47%     
client [46] (testset)   loss: 0.3396 -> 0.2535  accuracy: 88.06% -> 94.03%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 0.1841 -> 0.1614  accuracy: 92.80% -> 95.20%     
client [69] (testset)   loss: 0.2445 -> 0.2001  accuracy: 90.41% -> 91.10%     
client [82] (testset)   loss: 0.2931 -> 0.1465  accuracy: 88.10% -> 94.05%     
client [45] (testset)   loss: 0.4417 -> 0.3024  accuracy: 83.94% -> 88.07%     
client [7]  (testset)   loss: 0.3089 -> 0.2727  accuracy: 89.03% -> 89.68%     
client [50] (testset)   loss: 0.2825 -> 0.2822  accuracy: 88.70% -> 88.28%     
client [35] (testset)   loss: 0.1892 -> 0.1662  accuracy: 92.72% -> 93.38%     
client [24] (testset)   loss: 0.2560 -> 0.2130  accuracy: 91.59% -> 92.48%     
client [15] (testset)   loss: 0.1642 -> 0.1578  accuracy: 94.51% -> 94.51%     
client [58] (testset)   loss: 0.4204 -> 0.4469  accuracy: 84.96% -> 83.33%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 0.3956 -> 0.1960  accuracy: 87.62% -> 93.56%     
client [76] (testset)   loss: 0.1377 -> 0.1662  accuracy: 94.97% -> 92.74%     
client [67] (testset)   loss: 0.1366 -> 0.1438  accuracy: 97.13% -> 95.98%     
client [37] (testset)   loss: 0.2260 -> 0.2341  accuracy: 93.55% -> 92.26%     
client [58] (testset)   loss: 0.4196 -> 0.3942  accuracy: 85.77% -> 86.59%     
client [64] (testset)   loss: 0.2907 -> 0.3055  accuracy: 91.62% -> 89.82%     
client [77] (testset)   loss: 0.3414 -> 0.4312  accuracy: 85.00% -> 82.50%     
client [55] (testset)   loss: 0.4060 -> 0.3398  accuracy: 86.69% -> 89.92%     
client [12] (testset)   loss: 0.5100 -> 0.6079  accuracy: 85.00% -> 79.00%     
client [89] (testset)   loss: 0.3112 -> 0.2610  accuracy: 89.78% -> 92.70%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 0.4414 -> 0.3650  accuracy: 84.21% -> 88.82%     
client [51] (testset)   loss: 0.2200 -> 0.2666  accuracy: 90.71% -> 89.29%     
client [8]  (testset)   loss: 0.2567 -> 0.4013  accuracy: 90.65% -> 90.65%     
client [18] (testset)   loss: 0.2518 -> 0.2173  accuracy: 91.79% -> 91.79%     
client [94] (testset)   loss: 0.3264 -> 0.3139  accuracy: 89.64% -> 86.98%     
client [81] (testset)   loss: 0.2760 -> 0.2496  accuracy: 92.95% -> 93.83%     
client [3]  (testset)   loss: 0.3290 -> 0.2602  accuracy: 88.84% -> 92.43%     
client [11] (testset)   loss: 0.2187 -> 0.2144  accuracy: 92.62% -> 91.80%     
client [95] (testset)   loss: 0.2733 -> 0.1897  accuracy: 91.93% -> 93.79%     
client [67] (testset)   loss: 0.1726 -> 0.2104  accuracy: 94.25% -> 93.10%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 0.3431 -> 0.2310  accuracy: 88.96% -> 92.64%     
client [79] (testset)   loss: 0.3311 -> 0.2965  accuracy: 87.78% -> 90.05%     
client [58] (testset)   loss: 0.5013 -> 0.4535  accuracy: 84.55% -> 86.59%     
client [88] (testset)   loss: 0.4705 -> 0.5254  accuracy: 84.90% -> 83.33%     
client [46] (testset)   loss: 0.2773 -> 0.2851  accuracy: 91.79% -> 91.79%     
client [11] (testset)   loss: 0.2785 -> 0.2355  accuracy: 89.34% -> 90.98%     
client [55] (testset)   loss: 0.4820 -> 0.3887  accuracy: 85.89% -> 88.31%     
client [13] (testset)   loss: 0.2829 -> 0.2407  accuracy: 89.47% -> 91.05%     
client [31] (testset)   loss: 0.3365 -> 1.4189  accuracy: 86.69% -> 71.22%     
client [75] (testset)   loss: 0.2675 -> 0.1976  accuracy: 88.46% -> 91.03%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 0.1654 -> 0.1125  accuracy: 93.08% -> 95.38%     
client [7]  (testset)   loss: 0.2900 -> 0.2936  accuracy: 87.10% -> 89.68%     
client [57] (testset)   loss: 0.1317 -> 0.1388  accuracy: 95.97% -> 95.97%     
client [13] (testset)   loss: 0.2714 -> 0.2013  accuracy: 91.58% -> 93.16%     
client [43] (testset)   loss: 0.1231 -> 0.0495  accuracy: 94.94% -> 97.47%     
client [91] (testset)   loss: 0.3965 -> 0.3383  accuracy: 86.96% -> 86.96%     
client [10] (testset)   loss: 0.2104 -> 0.1378  accuracy: 93.88% -> 95.92%     
client [64] (testset)   loss: 0.3067 -> 0.2835  accuracy: 90.42% -> 91.62%     
client [82] (testset)   loss: 0.2382 -> 0.1179  accuracy: 93.45% -> 95.83%     
client [22] (testset)   loss: 0.5505 -> 0.4602  accuracy: 87.68% -> 88.41%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 0.3337 -> 0.5159  accuracy: 87.14% -> 80.00%     
client [23] (testset)   loss: 0.4295 -> 0.2743  accuracy: 87.99% -> 91.56%     
client [88] (testset)   loss: 0.4742 -> 0.3757  accuracy: 87.50% -> 83.85%     
client [98] (testset)   loss: 0.4296 -> 0.3989  accuracy: 87.36% -> 87.91%     
client [79] (testset)   loss: 0.3687 -> 0.2936  accuracy: 87.78% -> 90.95%     
client [21] (testset)   loss: 0.3210 -> 0.2401  accuracy: 88.96% -> 91.41%     
client [92] (testset)   loss: 0.3614 -> 0.2834  accuracy: 88.74% -> 90.54%     
client [56] (testset)   loss: 0.2852 -> 0.3536  accuracy: 91.47% -> 87.60%     
client [5]  (testset)   loss: 0.2634 -> 0.2322  accuracy: 90.00% -> 90.00%     
client [52] (testset)   loss: 0.3323 -> 0.2494  accuracy: 87.01% -> 90.96%     
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 0.1112 -> 0.1634  accuracy: 97.70% -> 94.25%     
client [54] (testset)   loss: 0.1138 -> 0.1018  accuracy: 94.25% -> 96.55%     
client [14] (testset)   loss: 0.1186 -> 0.0896  accuracy: 95.77% -> 97.18%     
client [99] (testset)   loss: 0.2607 -> 0.2441  accuracy: 87.12% -> 93.87%     
client [36] (testset)   loss: 0.3006 -> 0.2916  accuracy: 89.36% -> 87.23%     
client [30] (testset)   loss: 0.2784 -> 0.1534  accuracy: 89.83% -> 94.07%     
client [38] (testset)   loss: 0.4825 -> 0.3769  accuracy: 87.77% -> 89.21%     
client [15] (testset)   loss: 0.1787 -> 0.1572  accuracy: 94.51% -> 95.12%     
client [6]  (testset)   loss: 0.2784 -> 0.3051  accuracy: 88.64% -> 91.48%     
client [53] (testset)   loss: 0.2655 -> 0.2872  accuracy: 91.87% -> 92.58%     
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [99] (testset)   loss: 0.3504 -> 0.2519  accuracy: 85.89% -> 93.25%     
client [6]  (testset)   loss: 0.3037 -> 0.2833  accuracy: 88.07% -> 90.34%     
client [83] (testset)   loss: 0.3937 -> 0.3210  accuracy: 88.39% -> 89.51%     
client [42] (testset)   loss: 0.4284 -> 0.1921  accuracy: 82.22% -> 93.33%     
client [34] (testset)   loss: 0.2808 -> 0.1549  accuracy: 88.48% -> 92.67%     
client [15] (testset)   loss: 0.2130 -> 0.1586  accuracy: 93.90% -> 95.73%     
client [47] (testset)   loss: 0.2547 -> 0.1461  accuracy: 92.00% -> 96.00%     
client [55] (testset)   loss: 0.3008 -> 0.3812  accuracy: 88.31% -> 87.90%     
client [51] (testset)   loss: 0.2941 -> 0.4502  accuracy: 87.86% -> 89.29%     
client [95] (testset)   loss: 0.3261 -> 0.1801  accuracy: 91.93% -> 95.03%     
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 0.1999 -> 0.2198  accuracy: 94.30% -> 92.41%     
client [15] (testset)   loss: 0.1695 -> 0.1657  accuracy: 94.51% -> 96.34%     
client [33] (testset)   loss: 0.1857 -> 0.1483  accuracy: 92.42% -> 93.94%     
client [99] (testset)   loss: 0.2632 -> 0.2600  accuracy: 88.34% -> 93.25%     
client [90] (testset)   loss: 0.3360 -> 0.1595  accuracy: 89.62% -> 93.99%     
client [57] (testset)   loss: 0.1415 -> 0.1411  accuracy: 96.77% -> 96.77%     
client [27] (testset)   loss: 0.2928 -> 0.3517  accuracy: 92.59% -> 88.27%     
client [78] (testset)   loss: 0.5282 -> 0.4225  accuracy: 85.78% -> 86.21%     
client [36] (testset)   loss: 0.2977 -> 0.3314  accuracy: 87.94% -> 89.36%     
client [88] (testset)   loss: 0.4269 -> 0.4654  accuracy: 89.06% -> 81.25%     
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 0.2314 -> 0.1894  accuracy: 92.16% -> 93.73%     
client [35] (testset)   loss: 0.1907 -> 0.1673  accuracy: 92.72% -> 92.72%     
client [16] (testset)   loss: 0.1017 -> 0.0585  accuracy: 97.88% -> 97.35%     
client [80] (testset)   loss: 0.5679 -> 0.5181  accuracy: 86.43% -> 84.42%     
client [38] (testset)   loss: 0.4709 -> 0.5162  accuracy: 89.21% -> 87.77%     
client [78] (testset)   loss: 0.5372 -> 0.4442  accuracy: 85.34% -> 85.78%     
client [68] (testset)   loss: 0.4810 -> 0.4381  accuracy: 83.33% -> 84.72%     
client [11] (testset)   loss: 0.1798 -> 0.1811  accuracy: 90.16% -> 92.62%     
client [64] (testset)   loss: 0.2730 -> 0.3064  accuracy: 92.81% -> 92.22%     
client [82] (testset)   loss: 0.1934 -> 0.1075  accuracy: 94.64% -> 96.43%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 0.2259 -> 0.1759  accuracy: 91.53% -> 93.22%     
client [27] (testset)   loss: 0.2773 -> 0.2504  accuracy: 91.36% -> 93.83%     
client [74] (testset)   loss: 0.3700 -> 0.3607  accuracy: 87.43% -> 87.43%     
client [45] (testset)   loss: 0.2760 -> 0.2632  accuracy: 90.37% -> 92.20%     
client [6]  (testset)   loss: 0.3127 -> 0.2992  accuracy: 90.34% -> 90.91%     
client [36] (testset)   loss: 0.2967 -> 0.2691  accuracy: 90.07% -> 87.94%     
client [63] (testset)   loss: 0.1886 -> 0.2142  accuracy: 90.83% -> 92.50%     
client [76] (testset)   loss: 0.1625 -> 0.1729  accuracy: 93.30% -> 93.85%     
client [83] (testset)   loss: 0.4359 -> 0.3353  accuracy: 87.64% -> 89.14%     
client [86] (testset)   loss: 0.1889 -> 0.1892  accuracy: 93.16% -> 95.26%     
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 0.4716 -> 0.3686  accuracy: 86.14% -> 89.51%     
client [99] (testset)   loss: 0.2757 -> 0.2397  accuracy: 88.34% -> 93.25%     
client [74] (testset)   loss: 0.3825 -> 0.3771  accuracy: 89.82% -> 88.02%     
client [73] (testset)   loss: 0.3714 -> 0.3513  accuracy: 89.26% -> 91.28%     
client [29] (testset)   loss: 0.3730 -> 0.4152  accuracy: 87.07% -> 86.39%     
client [92] (testset)   loss: 0.2882 -> 0.2765  accuracy: 90.09% -> 90.09%     
client [6]  (testset)   loss: 0.2680 -> 0.3116  accuracy: 92.05% -> 92.05%     
client [61] (testset)   loss: 0.1810 -> 0.1801  accuracy: 91.74% -> 92.66%     
client [21] (testset)   loss: 0.2869 -> 0.2459  accuracy: 88.34% -> 91.41%     
client [67] (testset)   loss: 0.1488 -> 0.1391  accuracy: 95.40% -> 95.98%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 0.4549 -> 0.3464  accuracy: 86.14% -> 90.26%     
client [32] (testset)   loss: 0.3679 -> 0.2392  accuracy: 88.14% -> 91.53%     
client [95] (testset)   loss: 0.2762 -> 0.1586  accuracy: 91.93% -> 96.27%     
client [61] (testset)   loss: 0.2100 -> 0.2142  accuracy: 88.07% -> 91.74%     
client [27] (testset)   loss: 0.2368 -> 0.2532  accuracy: 91.36% -> 94.44%     
client [25] (testset)   loss: 0.2927 -> 0.1662  accuracy: 89.25% -> 94.62%     
client [68] (testset)   loss: 0.4731 -> 0.4707  accuracy: 86.11% -> 81.94%     
client [34] (testset)   loss: 0.2068 -> 0.1700  accuracy: 91.62% -> 93.19%     
client [71] (testset)   loss: 0.1821 -> 0.2055  accuracy: 93.04% -> 93.04%     
client [89] (testset)   loss: 0.3486 -> 0.2092  accuracy: 90.51% -> 92.70%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 0.5507 -> 0.4484  accuracy: 86.21% -> 86.21%     
client [81] (testset)   loss: 0.3244 -> 0.2445  accuracy: 90.31% -> 92.51%     
client [51] (testset)   loss: 0.2846 -> 0.2989  accuracy: 89.29% -> 90.00%     
client [54] (testset)   loss: 0.1189 -> 0.1135  accuracy: 93.68% -> 95.98%     
client [65] (testset)   loss: 0.2745 -> 0.2995  accuracy: 92.71% -> 92.19%     
client [41] (testset)   loss: 0.3153 -> 0.4219  accuracy: 86.82% -> 86.05%     
client [11] (testset)   loss: 0.1820 -> 0.1965  accuracy: 93.44% -> 91.80%     
client [85] (testset)   loss: 0.3445 -> 0.5004  accuracy: 90.98% -> 86.47%     
client [12] (testset)   loss: 0.5207 -> 0.6495  accuracy: 82.00% -> 79.00%     
client [23] (testset)   loss: 0.3892 -> 0.2629  accuracy: 90.58% -> 92.53%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 0.1003 -> 0.0710  accuracy: 96.83% -> 97.88%     
client [65] (testset)   loss: 0.2673 -> 0.2938  accuracy: 93.23% -> 93.23%     
client [53] (testset)   loss: 0.2885 -> 0.2700  accuracy: 91.87% -> 92.58%     
client [58] (testset)   loss: 0.3761 -> 0.4168  accuracy: 86.99% -> 87.40%     
client [72] (testset)   loss: 0.3746 -> 0.3657  accuracy: 90.68% -> 90.68%     
client [7]  (testset)   loss: 0.3123 -> 0.3173  accuracy: 88.39% -> 90.32%     
client [71] (testset)   loss: 0.1900 -> 0.2269  accuracy: 93.67% -> 93.04%     
client [59] (testset)   loss: 0.1594 -> 0.1280  accuracy: 92.67% -> 97.38%     
client [86] (testset)   loss: 0.2122 -> 0.1803  accuracy: 93.16% -> 94.74%     
client [39] (testset)   loss: 0.5031 -> 0.2761  accuracy: 86.38% -> 92.49%     
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 0.3314 -> 0.2377  accuracy: 85.28% -> 93.87%     
client [7]  (testset)   loss: 0.2824 -> 0.3462  accuracy: 89.03% -> 88.39%     
client [17] (testset)   loss: 0.1726 -> 0.0828  accuracy: 94.39% -> 96.43%     
client [64] (testset)   loss: 0.3390 -> 0.2807  accuracy: 90.42% -> 92.81%     
client [37] (testset)   loss: 0.2019 -> 0.2224  accuracy: 92.26% -> 92.26%     
client [29] (testset)   loss: 0.4286 -> 0.3669  accuracy: 85.71% -> 89.80%     
client [93] (testset)   loss: 0.3894 -> 0.2958  accuracy: 90.62% -> 89.84%     
client [73] (testset)   loss: 0.4507 -> 0.3771  accuracy: 87.92% -> 91.95%     
client [40] (testset)   loss: 0.2830 -> 0.1571  accuracy: 88.64% -> 93.94%     
client [76] (testset)   loss: 0.1491 -> 0.1526  accuracy: 94.97% -> 94.41%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 0.2817 -> 0.3801  accuracy: 89.93% -> 88.85%     
client [89] (testset)   loss: 0.3500 -> 0.2026  accuracy: 90.51% -> 93.43%     
client [77] (testset)   loss: 0.3355 -> 0.3798  accuracy: 90.00% -> 86.67%     
client [90] (testset)   loss: 0.3980 -> 0.1626  accuracy: 88.52% -> 92.35%     
client [26] (testset)   loss: 0.1346 -> 0.0955  accuracy: 96.46% -> 97.35%     
client [50] (testset)   loss: 0.3509 -> 0.3105  accuracy: 88.70% -> 89.96%     
client [30] (testset)   loss: 0.3230 -> 0.1687  accuracy: 91.53% -> 94.07%     
client [70] (testset)   loss: 0.2434 -> 0.1901  accuracy: 92.55% -> 93.33%     
client [41] (testset)   loss: 0.3472 -> 0.3753  accuracy: 87.60% -> 88.37%     
client [99] (testset)   loss: 0.2498 -> 0.2235  accuracy: 88.34% -> 93.87%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [68] (testset)   loss: 0.4275 -> 0.4346  accuracy: 88.89% -> 84.72%     
client [70] (testset)   loss: 0.2685 -> 0.1971  accuracy: 91.37% -> 94.12%     
client [52] (testset)   loss: 0.2695 -> 0.2959  accuracy: 89.27% -> 90.96%     
client [1]  (testset)   loss: 0.1493 -> 0.2724  accuracy: 92.59% -> 91.36%     
client [2]  (testset)   loss: 0.3725 -> 0.4119  accuracy: 89.38% -> 90.27%     
client [67] (testset)   loss: 0.1529 -> 0.1364  accuracy: 94.83% -> 95.98%     
client [92] (testset)   loss: 0.2947 -> 0.2624  accuracy: 89.19% -> 90.99%     
client [35] (testset)   loss: 0.1779 -> 0.1678  accuracy: 94.04% -> 93.71%     
client [36] (testset)   loss: 0.2889 -> 0.3324  accuracy: 91.49% -> 87.23%     
client [64] (testset)   loss: 0.3413 -> 0.4740  accuracy: 91.02% -> 89.22%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 0.2861 -> 0.3348  accuracy: 92.43% -> 91.35%     
client [6]  (testset)   loss: 0.2901 -> 0.3113  accuracy: 90.34% -> 90.91%     
client [12] (testset)   loss: 0.5260 -> 0.6467  accuracy: 83.00% -> 82.00%     
client [55] (testset)   loss: 0.4454 -> 0.3385  accuracy: 84.68% -> 91.53%     
client [29] (testset)   loss: 0.4626 -> 0.3970  accuracy: 86.39% -> 89.80%     
client [9]  (testset)   loss: 0.3344 -> 0.3750  accuracy: 89.35% -> 91.12%     
client [43] (testset)   loss: 0.1022 -> 0.0603  accuracy: 94.94% -> 97.47%     
client [77] (testset)   loss: 0.3464 -> 0.4186  accuracy: 89.17% -> 86.67%     
client [98] (testset)   loss: 0.4217 -> 0.3751  accuracy: 87.91% -> 90.66%     
client [78] (testset)   loss: 0.5720 -> 0.4705  accuracy: 86.21% -> 85.78%     
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 0.2960 -> 0.2535  accuracy: 89.19% -> 91.44%     
client [80] (testset)   loss: 0.5886 -> 0.5813  accuracy: 87.94% -> 86.43%     
client [63] (testset)   loss: 0.2509 -> 0.1490  accuracy: 90.00% -> 94.17%     
client [76] (testset)   loss: 0.1701 -> 0.1490  accuracy: 94.97% -> 94.41%     
client [78] (testset)   loss: 0.5572 -> 0.4445  accuracy: 84.91% -> 85.34%     
client [25] (testset)   loss: 0.2806 -> 0.1660  accuracy: 91.40% -> 93.19%     
client [58] (testset)   loss: 0.4220 -> 0.4798  accuracy: 87.80% -> 85.77%     
client [13] (testset)   loss: 0.3069 -> 0.2520  accuracy: 91.05% -> 92.63%     
client [17] (testset)   loss: 0.1320 -> 0.0753  accuracy: 95.41% -> 95.92%     
client [38] (testset)   loss: 0.5567 -> 0.4045  accuracy: 87.05% -> 90.65%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 0.4133 -> 0.3439  accuracy: 89.44% -> 91.30%     
client [82] (testset)   loss: 0.1207 -> 0.0938  accuracy: 95.83% -> 96.43%     
client [86] (testset)   loss: 0.2172 -> 0.1757  accuracy: 93.68% -> 95.26%     
client [51] (testset)   loss: 0.3257 -> 0.3006  accuracy: 87.14% -> 88.57%     
client [96] (testset)   loss: 0.2663 -> 0.2741  accuracy: 90.91% -> 90.91%     
client [42] (testset)   loss: 0.3708 -> 0.1870  accuracy: 84.44% -> 94.44%     
client [55] (testset)   loss: 0.3284 -> 0.3566  accuracy: 89.11% -> 90.73%     
client [13] (testset)   loss: 0.3696 -> 0.2575  accuracy: 88.95% -> 92.63%     
client [1]  (testset)   loss: 0.1570 -> 0.2217  accuracy: 95.06% -> 91.36%     
client [12] (testset)   loss: 0.4971 -> 0.6247  accuracy: 86.00% -> 82.00%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 0.4569 -> 0.3989  accuracy: 83.33% -> 86.11%     
client [23] (testset)   loss: 0.3396 -> 0.2698  accuracy: 91.56% -> 92.53%     
client [46] (testset)   loss: 0.3024 -> 0.3109  accuracy: 92.54% -> 92.54%     
client [41] (testset)   loss: 0.3430 -> 0.8607  accuracy: 86.05% -> 75.97%     
client [25] (testset)   loss: 0.2821 -> 0.1603  accuracy: 92.11% -> 93.19%     
client [58] (testset)   loss: 0.4136 -> 0.4437  accuracy: 87.80% -> 88.21%     
client [14] (testset)   loss: 0.1534 -> 0.0828  accuracy: 94.84% -> 97.65%     
client [33] (testset)   loss: 0.2295 -> 0.1648  accuracy: 92.93% -> 94.95%     
client [85] (testset)   loss: 0.3601 -> 0.2925  accuracy: 89.47% -> 91.73%     
client [62] (testset)   loss: 0.3645 -> 0.3702  accuracy: 89.29% -> 90.00%     
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 0.4331 -> 0.3827  accuracy: 87.91% -> 91.21%     
client [63] (testset)   loss: 0.1901 -> 0.1525  accuracy: 91.67% -> 95.00%     
client [70] (testset)   loss: 0.2509 -> 0.2141  accuracy: 93.33% -> 94.51%     
client [65] (testset)   loss: 0.2779 -> 0.2984  accuracy: 92.71% -> 94.27%     
client [14] (testset)   loss: 0.1180 -> 0.0812  accuracy: 95.77% -> 97.18%     
client [73] (testset)   loss: 0.3965 -> 0.4036  accuracy: 89.93% -> 92.62%     
client [34] (testset)   loss: 0.1557 -> 0.1256  accuracy: 94.76% -> 93.72%     
client [99] (testset)   loss: 0.2313 -> 0.2382  accuracy: 90.18% -> 95.09%     
client [69] (testset)   loss: 0.1756 -> 0.1803  accuracy: 94.52% -> 92.47%     
client [46] (testset)   loss: 0.2794 -> 0.2916  accuracy: 93.28% -> 94.03%     
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [99] (testset)   loss: 0.2628 -> 0.2442  accuracy: 90.18% -> 93.87%     
client [93] (testset)   loss: 0.4905 -> 0.3205  accuracy: 88.28% -> 89.84%     
client [11] (testset)   loss: 0.1516 -> 0.1538  accuracy: 94.26% -> 93.44%     
client [58] (testset)   loss: 0.3974 -> 0.4475  accuracy: 87.40% -> 86.59%     
client [81] (testset)   loss: 0.3247 -> 0.2155  accuracy: 91.19% -> 92.07%     
client [85] (testset)   loss: 0.3874 -> 0.3107  accuracy: 88.72% -> 90.98%     
client [89] (testset)   loss: 0.3205 -> 0.2193  accuracy: 91.97% -> 94.16%     
client [45] (testset)   loss: 0.3800 -> 0.2547  accuracy: 88.53% -> 90.83%     
client [8]  (testset)   loss: 0.2594 -> 0.2775  accuracy: 92.81% -> 92.09%     
client [68] (testset)   loss: 0.3987 -> 0.4408  accuracy: 84.72% -> 84.72%     
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 0.1228 -> 0.6237  accuracy: 97.70% -> 84.48%     
client [72] (testset)   loss: 0.3478 -> 0.3342  accuracy: 91.30% -> 90.06%     
client [1]  (testset)   loss: 0.1865 -> 0.2571  accuracy: 92.59% -> 91.36%     
client [78] (testset)   loss: 0.5392 -> 0.4425  accuracy: 88.79% -> 87.07%     
client [83] (testset)   loss: 0.4403 -> 0.3609  accuracy: 89.14% -> 90.64%     
client [21] (testset)   loss: 0.2816 -> 0.2295  accuracy: 90.18% -> 92.64%     
client [56] (testset)   loss: 0.3248 -> 0.3316  accuracy: 90.70% -> 91.47%     
client [44] (testset)   loss: 0.2924 -> 0.3305  accuracy: 91.89% -> 92.43%     
client [92] (testset)   loss: 0.3172 -> 0.2726  accuracy: 89.19% -> 92.34%     
client [27] (testset)   loss: 0.2545 -> 0.2707  accuracy: 92.59% -> 93.21%     
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 0.1805 -> 0.1140  accuracy: 94.90% -> 96.43%     
client [39] (testset)   loss: 0.4940 -> 0.2808  accuracy: 88.26% -> 92.96%     
client [65] (testset)   loss: 0.2891 -> 0.2919  accuracy: 92.71% -> 94.27%     
client [26] (testset)   loss: 0.0993 -> 0.0760  accuracy: 95.58% -> 98.23%     
client [19] (testset)   loss: 0.1557 -> 0.2418  accuracy: 93.85% -> 95.38%     
client [68] (testset)   loss: 0.4261 -> 0.3977  accuracy: 83.33% -> 83.33%     
client [41] (testset)   loss: 0.3684 -> 0.3836  accuracy: 86.82% -> 86.82%     
client [50] (testset)   loss: 0.3053 -> 0.2995  accuracy: 90.38% -> 91.63%     
client [75] (testset)   loss: 0.1851 -> 0.1471  accuracy: 93.59% -> 94.87%     
client [81] (testset)   loss: 0.3169 -> 0.2246  accuracy: 90.75% -> 93.39%     
Training... ---------------------------------------- 100% 0:16:45
FedALA's average time taken by each global epoch: 0 min 2.47 sec.              
FedALA's total running time: 0 h 16 m 45 s.                                    
==================== FedALA Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.3386 -> 0.0000",                                    
                "accuracy": "87.95% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.3102 -> 0.0000",                                    
                "accuracy": "89.52% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.3031 -> 0.0000",                                    
                "accuracy": "90.60% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.3144 -> 0.0000",                                    
                "accuracy": "91.15% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedALA Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 91.15% at epoch 400                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
[0m