==================== FedAvg ====================                               
Experiment Arguments:                                                          
{
â”‚   'method': 'fedavg',
â”‚   'dataset': {
â”‚   â”‚   'name': 'medmnistA',
â”‚   â”‚   'client_num': 100,
â”‚   â”‚   'test_ratio': 0.25,
â”‚   â”‚   'val_ratio': 0.0,
â”‚   â”‚   'seed': 42,
â”‚   â”‚   'split': 'sample',
â”‚   â”‚   'IID_ratio': 0.0,
â”‚   â”‚   'monitor_window_name_suffix': 'medmnistA-100clients-0%IID-Dir(1.0)-seed42',
â”‚   â”‚   'alpha': 1.0,
â”‚   â”‚   'min_samples_per_client': 10
â”‚   },
â”‚   'model': {
â”‚   â”‚   'name': 'lenet5',
â”‚   â”‚   'use_torchvision_pretrained_weights': True,
â”‚   â”‚   'external_model_weights_path': None
â”‚   },
â”‚   'optimizer': {
â”‚   â”‚   'lr': 0.01,
â”‚   â”‚   'dampening': 0,
â”‚   â”‚   'weight_decay': 0,
â”‚   â”‚   'momentum': 0,
â”‚   â”‚   'nesterov': False,
â”‚   â”‚   'name': 'sgd'
â”‚   },
â”‚   'mode': 'serial',
â”‚   'parallel': {
â”‚   â”‚   'ray_cluster_addr': None,
â”‚   â”‚   'num_cpus': None,
â”‚   â”‚   'num_gpus': None,
â”‚   â”‚   'num_workers': 2
â”‚   },
â”‚   'common': {
â”‚   â”‚   'seed': 42,
â”‚   â”‚   'join_ratio': 0.1,
â”‚   â”‚   'global_epoch': 400,
â”‚   â”‚   'local_epoch': 5,
â”‚   â”‚   'batch_size': 32,
â”‚   â”‚   'reset_optimizer_on_global_epoch': True,
â”‚   â”‚   'straggler_ratio': 0,
â”‚   â”‚   'straggler_min_local_epoch': 0,
â”‚   â”‚   'buffers': 'global',
â”‚   â”‚   'client_side_evaluation': True,
â”‚   â”‚   'test': {
â”‚   â”‚   â”‚   'client': {
â”‚   â”‚   â”‚   â”‚   'interval': 100,
â”‚   â”‚   â”‚   â”‚   'finetune_epoch': 0,
â”‚   â”‚   â”‚   â”‚   'train': False,
â”‚   â”‚   â”‚   â”‚   'val': False,
â”‚   â”‚   â”‚   â”‚   'test': True
â”‚   â”‚   â”‚   },
â”‚   â”‚   â”‚   'server': {
â”‚   â”‚   â”‚   â”‚   'interval': -1,
â”‚   â”‚   â”‚   â”‚   'train': False,
â”‚   â”‚   â”‚   â”‚   'val': False,
â”‚   â”‚   â”‚   â”‚   'test': False,
â”‚   â”‚   â”‚   â”‚   'model_in_train_mode': False
â”‚   â”‚   â”‚   }
â”‚   â”‚   },
â”‚   â”‚   'verbose_gap': 10,
â”‚   â”‚   'monitor': None,
â”‚   â”‚   'use_cuda': True,
â”‚   â”‚   'save_log': True,
â”‚   â”‚   'save_model': False,
â”‚   â”‚   'save_learning_curve_plot': False,
â”‚   â”‚   'save_metrics': True,
â”‚   â”‚   'delete_useless_run': True
â”‚   }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 2.3666 -> 2.0610  accuracy: 2.61% -> 24.84%      
client [81] (testset)   loss: 2.7058 -> 2.2074  accuracy: 4.17% -> 25.00%      
client [21] (testset)   loss: 2.3420 -> 2.0173  accuracy: 27.10% -> 27.10%     
client [68] (testset)   loss: 2.4162 -> 2.1035  accuracy: 16.80% -> 16.80%     
client [93] (testset)   loss: 1.8392 -> 1.1884  accuracy: 69.57% -> 69.57%     
client [31] (testset)   loss: 2.6186 -> 2.2183  accuracy: 4.12% -> 18.56%      
client [20] (testset)   loss: 2.1853 -> 1.9905  accuracy: 8.68% -> 32.42%      
client [59] (testset)   loss: 2.5310 -> 2.0610  accuracy: 7.48% -> 21.77%      
client [48] (testset)   loss: 2.2485 -> 2.1624  accuracy: 19.40% -> 21.98%     
client [34] (testset)   loss: 2.1140 -> 2.0250  accuracy: 32.74% -> 32.74%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 2.4876 -> 1.9112  accuracy: 0.64% -> 25.64%      
client [99] (testset)   loss: 2.2649 -> 1.9820  accuracy: 12.30% -> 32.79%     
client [67] (testset)   loss: 2.4219 -> 2.1243  accuracy: 7.34% -> 19.27%      
client [0]  (testset)   loss: 2.3316 -> 2.1029  accuracy: 12.04% -> 17.28%     
client [76] (testset)   loss: 2.3561 -> 2.1633  accuracy: 10.53% -> 20.39%     
client [41] (testset)   loss: 3.0330 -> 1.9017  accuracy: 4.42% -> 44.25%      
client [62] (testset)   loss: 2.3546 -> 2.0495  accuracy: 7.06% -> 33.83%      
client [2]  (testset)   loss: 2.4264 -> 2.1066  accuracy: 11.98% -> 11.98%     
client [14] (testset)   loss: 2.1091 -> 1.9589  accuracy: 35.56% -> 35.56%     
client [46] (testset)   loss: 2.1653 -> 1.9799  accuracy: 30.39% -> 30.39%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 2.0753 -> 1.7523  accuracy: 19.63% -> 39.88%     
client [68] (testset)   loss: 2.3345 -> 2.0778  accuracy: 16.80% -> 23.20%     
client [57] (testset)   loss: 2.4768 -> 2.2272  accuracy: 11.11% -> 19.75%     
client [17] (testset)   loss: 2.5039 -> 2.2227  accuracy: 9.23% -> 20.00%      
client [54] (testset)   loss: 2.3815 -> 2.0482  accuracy: 10.43% -> 20.00%     
client [23] (testset)   loss: 2.3003 -> 2.0621  accuracy: 24.23% -> 24.23%     
client [35] (testset)   loss: 2.3285 -> 2.0404  accuracy: 17.78% -> 23.33%     
client [59] (testset)   loss: 2.5574 -> 2.0623  accuracy: 7.48% -> 24.49%      
client [31] (testset)   loss: 2.3330 -> 2.1791  accuracy: 4.12% -> 15.46%      
client [9]  (testset)   loss: 2.4807 -> 2.0941  accuracy: 4.44% -> 31.11%      
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 2.1329 -> 2.1398  accuracy: 22.22% -> 15.87%     
client [33] (testset)   loss: 2.2405 -> 2.1248  accuracy: 7.65% -> 28.82%      
client [16] (testset)   loss: 2.1325 -> 1.4008  accuracy: 8.66% -> 59.84%      
client [44] (testset)   loss: 2.3222 -> 2.0825  accuracy: 10.14% -> 28.38%     
client [8]  (testset)   loss: 2.4225 -> 1.8849  accuracy: 2.13% -> 46.10%      
client [31] (testset)   loss: 2.4135 -> 2.1946  accuracy: 18.56% -> 18.56%     
client [47] (testset)   loss: 2.2805 -> 1.7863  accuracy: 15.38% -> 27.97%     
client [36] (testset)   loss: 2.2724 -> 1.8285  accuracy: 3.85% -> 36.54%      
client [20] (testset)   loss: 2.2339 -> 2.0163  accuracy: 9.59% -> 19.18%      
client [56] (testset)   loss: 2.1877 -> 1.9365  accuracy: 11.80% -> 32.58%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 2.2047 -> 1.9616  accuracy: 14.91% -> 32.92%     
client [60] (testset)   loss: 2.1164 -> 1.9260  accuracy: 28.35% -> 28.35%     
client [28] (testset)   loss: 2.6536 -> 2.1774  accuracy: 2.65% -> 18.58%      
client [25] (testset)   loss: 2.0642 -> 1.8288  accuracy: 40.30% -> 40.30%     
client [58] (testset)   loss: 2.2583 -> 1.7217  accuracy: 1.11% -> 32.22%      
client [44] (testset)   loss: 2.2498 -> 2.0677  accuracy: 28.38% -> 28.38%     
client [39] (testset)   loss: 2.3332 -> 1.9879  accuracy: 10.65% -> 20.12%     
client [29] (testset)   loss: 2.6509 -> 2.2845  accuracy: 9.62% -> 24.04%      
client [3]  (testset)   loss: 2.2460 -> 1.4230  accuracy: 7.59% -> 62.66%      
client [84] (testset)   loss: 2.3334 -> 2.2111  accuracy: 13.16% -> 21.93%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 2.3629 -> 2.0302  accuracy: 4.52% -> 27.10%      
client [84] (testset)   loss: 2.3045 -> 2.1983  accuracy: 2.63% -> 21.93%      
client [10] (testset)   loss: 2.3330 -> 1.8557  accuracy: 5.41% -> 36.94%      
client [36] (testset)   loss: 2.4685 -> 1.8532  accuracy: 4.49% -> 36.54%      
client [65] (testset)   loss: 2.3328 -> 1.9926  accuracy: 28.26% -> 28.26%     
client [81] (testset)   loss: 2.5175 -> 2.2829  accuracy: 5.21% -> 20.83%      
client [79] (testset)   loss: 2.3980 -> 2.0284  accuracy: 1.98% -> 21.78%      
client [42] (testset)   loss: 2.3833 -> 2.0780  accuracy: 0.00% -> 21.62%      
client [11] (testset)   loss: 2.6896 -> 2.0173  accuracy: 2.65% -> 36.28%      
client [96] (testset)   loss: 2.3708 -> 2.0234  accuracy: 7.76% -> 22.41%      
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 2.3250 -> 1.8961  accuracy: 0.71% -> 46.10%      
client [53] (testset)   loss: 2.2191 -> 1.8516  accuracy: 6.48% -> 32.41%      
client [52] (testset)   loss: 2.3051 -> 1.8967  accuracy: 1.31% -> 28.38%      
client [42] (testset)   loss: 2.3308 -> 2.0690  accuracy: 20.95% -> 20.95%     
client [69] (testset)   loss: 2.2640 -> 1.9184  accuracy: 30.13% -> 25.64%     
client [59] (testset)   loss: 2.5078 -> 2.0587  accuracy: 7.48% -> 24.49%      
client [7]  (testset)   loss: 2.1703 -> 1.8430  accuracy: 41.94% -> 41.94%     
client [26] (testset)   loss: 2.1348 -> 1.4733  accuracy: 54.98% -> 54.98%     
client [49] (testset)   loss: 2.1790 -> 1.7172  accuracy: 48.28% -> 48.28%     
client [98] (testset)   loss: 2.4000 -> 2.1720  accuracy: 3.45% -> 28.74%      
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 2.5847 -> 2.2030  accuracy: 3.45% -> 18.39%      
client [47] (testset)   loss: 2.5597 -> 1.7604  accuracy: 0.70% -> 27.97%      
client [21] (testset)   loss: 2.4103 -> 1.9980  accuracy: 27.10% -> 27.10%     
client [77] (testset)   loss: 2.5363 -> 2.0802  accuracy: 2.61% -> 19.61%      
client [95] (testset)   loss: 2.5910 -> 2.1821  accuracy: 1.83% -> 20.18%      
client [91] (testset)   loss: 2.6524 -> 2.2658  accuracy: 8.33% -> 13.10%      
client [14] (testset)   loss: 2.1909 -> 1.9834  accuracy: 9.63% -> 35.56%      
client [99] (testset)   loss: 2.1246 -> 1.9939  accuracy: 32.79% -> 32.79%     
client [20] (testset)   loss: 2.3045 -> 2.0174  accuracy: 8.68% -> 10.96%      
client [39] (testset)   loss: 2.5485 -> 2.0028  accuracy: 10.65% -> 19.53%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 2.2934 -> 1.9117  accuracy: 1.31% -> 28.38%      
client [62] (testset)   loss: 2.1534 -> 2.0857  accuracy: 33.83% -> 33.83%     
client [71] (testset)   loss: 2.6613 -> 1.7687  accuracy: 0.00% -> 40.35%      
client [97] (testset)   loss: 2.3952 -> 1.9872  accuracy: 3.86% -> 21.26%      
client [30] (testset)   loss: 2.3664 -> 1.8038  accuracy: 7.14% -> 32.47%      
client [88] (testset)   loss: 2.3764 -> 1.8976  accuracy: 6.51% -> 41.42%      
client [60] (testset)   loss: 2.2404 -> 1.9558  accuracy: 28.35% -> 25.77%     
client [82] (testset)   loss: 2.2458 -> 1.8511  accuracy: 1.74% -> 38.26%      
client [91] (testset)   loss: 2.4827 -> 2.2786  accuracy: 8.33% -> 10.71%      
client [57] (testset)   loss: 2.4126 -> 2.2245  accuracy: 11.11% -> 19.75%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 2.4769 -> 2.2039  accuracy: 4.12% -> 12.37%      
client [15] (testset)   loss: 2.2629 -> 1.9553  accuracy: 35.54% -> 35.54%     
client [71] (testset)   loss: 2.4950 -> 1.7581  accuracy: 0.00% -> 40.35%      
client [97] (testset)   loss: 2.2895 -> 1.9364  accuracy: 3.86% -> 21.26%      
client [53] (testset)   loss: 2.3095 -> 1.9784  accuracy: 6.48% -> 32.41%      
client [77] (testset)   loss: 2.4372 -> 2.0835  accuracy: 2.61% -> 24.84%      
client [76] (testset)   loss: 2.3186 -> 2.1347  accuracy: 20.39% -> 20.39%     
client [79] (testset)   loss: 2.3183 -> 2.0386  accuracy: 14.85% -> 21.78%     
client [28] (testset)   loss: 2.6739 -> 2.1216  accuracy: 2.65% -> 23.01%      
client [99] (testset)   loss: 2.1423 -> 1.9938  accuracy: 32.79% -> 32.79%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 2.3040 -> 1.9320  accuracy: 2.90% -> 23.19%      
client [86] (testset)   loss: 2.3449 -> 2.0168  accuracy: 3.57% -> 22.62%      
client [34] (testset)   loss: 2.2549 -> 1.9968  accuracy: 0.36% -> 32.74%      
client [73] (testset)   loss: 2.2426 -> 1.8575  accuracy: 2.91% -> 27.18%      
client [5]  (testset)   loss: 2.1978 -> 1.7910  accuracy: 17.41% -> 51.79%     
client [96] (testset)   loss: 2.3383 -> 2.0220  accuracy: 13.79% -> 22.41%     
client [22] (testset)   loss: 2.3747 -> 2.1039  accuracy: 3.70% -> 30.86%      
client [60] (testset)   loss: 2.2672 -> 1.9596  accuracy: 4.12% -> 25.77%      
client [66] (testset)   loss: 2.3065 -> 2.0449  accuracy: 20.16% -> 30.23%     
client [83] (testset)   loss: 2.4157 -> 1.7749  accuracy: 23.27% -> 30.82%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 2.3879 -> 2.1336  accuracy: 20.39% -> 20.39%     
client [65] (testset)   loss: 2.6594 -> 1.9962  accuracy: 1.45% -> 28.26%      
client [95] (testset)   loss: 2.5527 -> 2.1874  accuracy: 1.83% -> 12.84%      
client [17] (testset)   loss: 2.5872 -> 2.1224  accuracy: 9.23% -> 20.00%      
client [8]  (testset)   loss: 2.6591 -> 1.8944  accuracy: 0.71% -> 46.10%      
client [35] (testset)   loss: 2.3760 -> 2.0640  accuracy: 17.78% -> 23.33%     
client [98] (testset)   loss: 2.7465 -> 2.2258  accuracy: 3.45% -> 28.74%      
client [53] (testset)   loss: 2.2670 -> 1.9526  accuracy: 6.48% -> 32.41%      
client [43] (testset)   loss: 2.5037 -> 2.1464  accuracy: 8.33% -> 24.17%      
client [64] (testset)   loss: 2.2279 -> 2.1283  accuracy: 11.11% -> 15.87%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 2.7390 -> 2.0269  accuracy: 3.87% -> 27.10%      
client [88] (testset)   loss: 2.0928 -> 1.9007  accuracy: 15.38% -> 41.42%     
client [38] (testset)   loss: 2.7769 -> 1.9979  accuracy: 0.58% -> 39.31%      
client [3]  (testset)   loss: 2.0610 -> 1.4346  accuracy: 2.53% -> 62.66%      
client [5]  (testset)   loss: 2.4229 -> 1.6475  accuracy: 8.93% -> 51.79%      
client [41] (testset)   loss: 3.0513 -> 1.8842  accuracy: 4.42% -> 44.25%      
client [7]  (testset)   loss: 2.4667 -> 1.8567  accuracy: 7.53% -> 41.94%      
client [37] (testset)   loss: 2.6507 -> 2.2691  accuracy: 5.69% -> 13.01%      
client [45] (testset)   loss: 2.3724 -> 1.9213  accuracy: 9.09% -> 33.57%      
client [47] (testset)   loss: 2.0840 -> 1.7642  accuracy: 27.97% -> 27.97%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 1.8309 -> 1.3952  accuracy: 59.84% -> 59.84%     
client [11] (testset)   loss: 2.5794 -> 2.0148  accuracy: 7.96% -> 36.28%      
client [37] (testset)   loss: 2.4502 -> 2.2706  accuracy: 19.51% -> 13.01%     
client [41] (testset)   loss: 3.2070 -> 1.8855  accuracy: 0.00% -> 44.25%      
client [95] (testset)   loss: 2.4947 -> 2.1887  accuracy: 1.83% -> 20.18%      
client [53] (testset)   loss: 2.2023 -> 1.9321  accuracy: 6.48% -> 32.41%      
client [22] (testset)   loss: 2.5608 -> 2.0761  accuracy: 4.94% -> 30.86%      
client [25] (testset)   loss: 1.9960 -> 1.8287  accuracy: 40.30% -> 40.30%     
client [69] (testset)   loss: 2.1451 -> 1.9317  accuracy: 30.13% -> 25.64%     
client [46] (testset)   loss: 2.3331 -> 1.9618  accuracy: 6.86% -> 30.39%      
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 2.0573 -> 1.7751  accuracy: 27.97% -> 27.97%     
client [69] (testset)   loss: 2.3599 -> 1.9178  accuracy: 14.10% -> 25.64%     
client [82] (testset)   loss: 2.2796 -> 1.8252  accuracy: 23.48% -> 38.26%     
client [45] (testset)   loss: 2.1768 -> 1.8921  accuracy: 9.09% -> 19.58%      
client [7]  (testset)   loss: 2.3035 -> 1.8785  accuracy: 7.53% -> 41.94%      
client [50] (testset)   loss: 2.5270 -> 2.1248  accuracy: 12.82% -> 23.08%     
client [35] (testset)   loss: 2.2795 -> 2.0377  accuracy: 16.67% -> 23.33%     
client [24] (testset)   loss: 2.4460 -> 1.7635  accuracy: 7.98% -> 39.88%      
client [15] (testset)   loss: 2.3039 -> 1.9570  accuracy: 19.88% -> 35.54%     
client [58] (testset)   loss: 2.5057 -> 1.7632  accuracy: 4.44% -> 31.11%      
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 2.3442 -> 2.1609  accuracy: 19.40% -> 21.98%     
client [76] (testset)   loss: 2.2237 -> 2.1217  accuracy: 20.39% -> 20.39%     
client [67] (testset)   loss: 2.2158 -> 2.4527  accuracy: 20.18% -> 14.68%     
client [37] (testset)   loss: 2.4567 -> 2.2922  accuracy: 19.51% -> 13.01%     
client [58] (testset)   loss: 2.6900 -> 1.7478  accuracy: 1.11% -> 32.22%      
client [64] (testset)   loss: 2.3609 -> 2.1373  accuracy: 11.11% -> 15.87%     
client [77] (testset)   loss: 2.3723 -> 2.0903  accuracy: 2.61% -> 24.84%      
client [55] (testset)   loss: 2.4122 -> 2.1604  accuracy: 13.92% -> 13.92%     
client [12] (testset)   loss: 2.3117 -> 2.2228  accuracy: 12.73% -> 27.27%     
client [89] (testset)   loss: 2.4290 -> 2.0530  accuracy: 21.60% -> 21.60%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 2.4240 -> 2.1805  accuracy: 5.26% -> 21.93%      
client [51] (testset)   loss: 2.4300 -> 2.0394  accuracy: 7.62% -> 36.19%      
client [8]  (testset)   loss: 2.5631 -> 1.8587  accuracy: 9.22% -> 46.10%      
client [18] (testset)   loss: 1.9112 -> 1.6315  accuracy: 32.46% -> 32.46%     
client [94] (testset)   loss: 2.1621 -> 1.8946  accuracy: 38.84% -> 38.84%     
client [81] (testset)   loss: 2.7446 -> 2.2071  accuracy: 3.12% -> 25.00%      
client [3]  (testset)   loss: 2.3611 -> 1.4224  accuracy: 2.53% -> 62.66%      
client [11] (testset)   loss: 2.7240 -> 2.0245  accuracy: 6.19% -> 36.28%      
client [95] (testset)   loss: 2.4721 -> 2.1932  accuracy: 12.84% -> 20.18%     
client [67] (testset)   loss: 2.3728 -> 2.1597  accuracy: 17.43% -> 19.27%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 2.5190 -> 1.9955  accuracy: 13.55% -> 27.10%     
client [79] (testset)   loss: 2.3802 -> 2.0389  accuracy: 0.00% -> 21.78%      
client [58] (testset)   loss: 2.1213 -> 1.7601  accuracy: 32.22% -> 31.11%     
client [88] (testset)   loss: 2.2551 -> 1.8831  accuracy: 5.92% -> 41.42%      
client [46] (testset)   loss: 2.2808 -> 1.9443  accuracy: 4.90% -> 25.49%      
client [11] (testset)   loss: 2.4444 -> 2.0476  accuracy: 2.65% -> 36.28%      
client [55] (testset)   loss: 2.7907 -> 2.1611  accuracy: 1.27% -> 17.72%      
client [13] (testset)   loss: 2.5158 -> 2.1338  accuracy: 14.62% -> 19.88%     
client [31] (testset)   loss: 2.4440 -> 2.1924  accuracy: 7.22% -> 18.56%      
client [75] (testset)   loss: 2.3990 -> 1.7616  accuracy: 4.76% -> 39.29%      
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 2.5963 -> 2.1602  accuracy: 11.80% -> 34.16%     
client [7]  (testset)   loss: 2.1620 -> 1.8547  accuracy: 41.94% -> 41.94%     
client [57] (testset)   loss: 2.4367 -> 2.2477  accuracy: 11.11% -> 19.75%     
client [13] (testset)   loss: 2.5950 -> 2.1475  accuracy: 18.71% -> 19.30%     
client [43] (testset)   loss: 2.3803 -> 2.1539  accuracy: 8.33% -> 24.17%      
client [91] (testset)   loss: 2.6066 -> 2.2765  accuracy: 8.33% -> 10.71%      
client [10] (testset)   loss: 2.3568 -> 1.8250  accuracy: 2.70% -> 36.94%      
client [64] (testset)   loss: 2.1884 -> 2.1331  accuracy: 11.11% -> 15.87%     
client [82] (testset)   loss: 2.1963 -> 1.8473  accuracy: 1.74% -> 38.26%      
client [22] (testset)   loss: 2.5455 -> 2.0762  accuracy: 4.94% -> 30.86%      
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 2.4230 -> 1.9974  accuracy: 8.68% -> 32.42%      
client [23] (testset)   loss: 2.2348 -> 2.0335  accuracy: 24.23% -> 24.23%     
client [88] (testset)   loss: 2.2919 -> 1.8963  accuracy: 6.51% -> 41.42%      
client [98] (testset)   loss: 2.4070 -> 2.1687  accuracy: 3.45% -> 28.74%      
client [79] (testset)   loss: 2.2388 -> 2.0568  accuracy: 14.85% -> 21.78%     
client [21] (testset)   loss: 2.4183 -> 2.0038  accuracy: 27.10% -> 27.10%     
client [92] (testset)   loss: 2.5775 -> 2.1977  accuracy: 2.48% -> 21.49%      
client [56] (testset)   loss: 2.1696 -> 1.9320  accuracy: 21.35% -> 32.58%     
client [5]  (testset)   loss: 2.0838 -> 1.8126  accuracy: 51.79% -> 51.79%     
client [52] (testset)   loss: 2.2605 -> 1.9044  accuracy: 1.31% -> 19.21%      
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 2.3877 -> 2.0132  accuracy: 7.34% -> 19.27%      
client [54] (testset)   loss: 2.5509 -> 2.0294  accuracy: 6.96% -> 20.00%      
client [14] (testset)   loss: 2.1796 -> 1.9595  accuracy: 35.56% -> 35.56%     
client [99] (testset)   loss: 2.2038 -> 2.0227  accuracy: 12.30% -> 32.79%     
client [36] (testset)   loss: 2.4270 -> 1.8141  accuracy: 4.49% -> 36.54%      
client [30] (testset)   loss: 2.3372 -> 1.7973  accuracy: 32.47% -> 32.47%     
client [38] (testset)   loss: 2.5700 -> 1.9415  accuracy: 4.05% -> 39.31%      
client [15] (testset)   loss: 2.3132 -> 1.9509  accuracy: 6.02% -> 35.54%      
client [6]  (testset)   loss: 2.1629 -> 2.0866  accuracy: 16.29% -> 24.72%     
client [53] (testset)   loss: 2.4890 -> 1.9868  accuracy: 2.78% -> 9.26%       
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [99] (testset)   loss: 2.2358 -> 1.9829  accuracy: 32.79% -> 32.79%     
client [6]  (testset)   loss: 2.3664 -> 2.0789  accuracy: 24.72% -> 24.72%     
client [83] (testset)   loss: 2.1736 -> 1.7797  accuracy: 2.52% -> 30.82%      
client [42] (testset)   loss: 2.2676 -> 2.0726  accuracy: 20.95% -> 20.95%     
client [34] (testset)   loss: 2.3812 -> 1.9873  accuracy: 32.74% -> 32.74%     
client [15] (testset)   loss: 2.2077 -> 1.9514  accuracy: 35.54% -> 35.54%     
client [47] (testset)   loss: 2.4950 -> 1.7538  accuracy: 0.70% -> 27.97%      
client [55] (testset)   loss: 2.7571 -> 2.1126  accuracy: 13.92% -> 17.72%     
client [51] (testset)   loss: 2.7024 -> 2.0227  accuracy: 8.57% -> 36.19%      
client [95] (testset)   loss: 2.4766 -> 2.2123  accuracy: 1.83% -> 12.84%      
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 2.6754 -> 1.8415  accuracy: 0.00% -> 40.35%      
client [15] (testset)   loss: 2.1486 -> 1.9546  accuracy: 35.54% -> 35.54%     
client [33] (testset)   loss: 2.3321 -> 2.1282  accuracy: 5.29% -> 28.82%      
client [99] (testset)   loss: 2.2644 -> 1.9750  accuracy: 32.79% -> 32.79%     
client [90] (testset)   loss: 2.6613 -> 1.8132  accuracy: 0.00% -> 16.85%      
client [57] (testset)   loss: 2.4741 -> 2.2303  accuracy: 11.11% -> 19.75%     
client [27] (testset)   loss: 2.5157 -> 1.9661  accuracy: 12.78% -> 30.83%     
client [78] (testset)   loss: 2.3720 -> 2.0863  accuracy: 8.20% -> 26.23%      
client [36] (testset)   loss: 2.4021 -> 1.8474  accuracy: 3.21% -> 36.54%      
client [88] (testset)   loss: 2.3258 -> 1.8603  accuracy: 6.51% -> 41.42%      
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 2.4756 -> 1.7880  accuracy: 0.86% -> 30.17%      
client [35] (testset)   loss: 2.4787 -> 2.0481  accuracy: 1.67% -> 23.33%      
client [16] (testset)   loss: 2.2562 -> 1.4084  accuracy: 16.54% -> 59.84%     
client [80] (testset)   loss: 2.2986 -> 2.0182  accuracy: 35.71% -> 35.71%     
client [38] (testset)   loss: 2.5222 -> 1.9184  accuracy: 9.83% -> 39.31%      
client [78] (testset)   loss: 2.3369 -> 2.0605  accuracy: 17.21% -> 26.23%     
client [68] (testset)   loss: 2.2888 -> 2.0934  accuracy: 20.00% -> 16.80%     
client [11] (testset)   loss: 2.3434 -> 2.0103  accuracy: 36.28% -> 36.28%     
client [64] (testset)   loss: 2.2829 -> 2.1250  accuracy: 12.70% -> 15.87%     
client [82] (testset)   loss: 2.3427 -> 1.8464  accuracy: 16.52% -> 38.26%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 2.5144 -> 1.9589  accuracy: 5.19% -> 30.52%      
client [27] (testset)   loss: 2.4941 -> 1.9594  accuracy: 9.02% -> 30.83%      
client [74] (testset)   loss: 2.4572 -> 2.1629  accuracy: 10.53% -> 27.37%     
client [45] (testset)   loss: 2.2608 -> 1.8964  accuracy: 1.40% -> 19.58%      
client [6]  (testset)   loss: 2.2887 -> 2.0687  accuracy: 6.18% -> 24.72%      
client [36] (testset)   loss: 2.2060 -> 1.8464  accuracy: 2.56% -> 36.54%      
client [63] (testset)   loss: 2.2585 -> 2.1010  accuracy: 12.50% -> 14.84%     
client [76] (testset)   loss: 2.3903 -> 2.1504  accuracy: 1.32% -> 20.39%      
client [83] (testset)   loss: 2.3570 -> 1.7787  accuracy: 3.14% -> 30.82%      
client [86] (testset)   loss: 2.3624 -> 1.9985  accuracy: 8.33% -> 22.62%      
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 2.2596 -> 1.7803  accuracy: 22.01% -> 30.82%     
client [99] (testset)   loss: 2.3137 -> 1.9970  accuracy: 1.64% -> 32.79%      
client [74] (testset)   loss: 2.4671 -> 2.1346  accuracy: 7.37% -> 27.37%      
client [73] (testset)   loss: 2.2583 -> 1.8661  accuracy: 1.94% -> 27.18%      
client [29] (testset)   loss: 2.5316 -> 2.2894  accuracy: 24.04% -> 24.04%     
client [92] (testset)   loss: 2.6356 -> 2.1338  accuracy: 6.61% -> 17.36%      
client [6]  (testset)   loss: 2.2575 -> 2.0758  accuracy: 7.30% -> 24.72%      
client [61] (testset)   loss: 2.2935 -> 2.0237  accuracy: 15.08% -> 15.08%     
client [21] (testset)   loss: 2.6221 -> 2.0309  accuracy: 3.87% -> 27.10%      
client [67] (testset)   loss: 2.4487 -> 2.0436  accuracy: 17.43% -> 19.27%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 2.2377 -> 1.7841  accuracy: 2.52% -> 30.82%      
client [32] (testset)   loss: 2.1077 -> 1.9771  accuracy: 26.51% -> 26.51%     
client [95] (testset)   loss: 2.4505 -> 2.2148  accuracy: 1.83% -> 12.84%      
client [61] (testset)   loss: 2.2099 -> 1.9742  accuracy: 18.25% -> 31.75%     
client [27] (testset)   loss: 2.6738 -> 1.9783  accuracy: 12.78% -> 30.83%     
client [25] (testset)   loss: 2.0791 -> 1.8691  accuracy: 40.30% -> 40.30%     
client [68] (testset)   loss: 2.2005 -> 2.0772  accuracy: 16.80% -> 23.20%     
client [34] (testset)   loss: 2.3196 -> 2.0535  accuracy: 32.74% -> 32.74%     
client [71] (testset)   loss: 2.7992 -> 1.7503  accuracy: 0.00% -> 40.35%      
client [89] (testset)   loss: 2.3053 -> 2.0887  accuracy: 21.60% -> 23.46%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 2.3364 -> 2.0857  accuracy: 8.20% -> 26.23%      
client [81] (testset)   loss: 2.5773 -> 2.3524  accuracy: 4.17% -> 5.21%       
client [51] (testset)   loss: 2.3982 -> 2.0277  accuracy: 8.57% -> 36.19%      
client [54] (testset)   loss: 2.3801 -> 2.0261  accuracy: 10.43% -> 20.00%     
client [65] (testset)   loss: 2.6640 -> 1.9761  accuracy: 1.45% -> 28.26%      
client [41] (testset)   loss: 3.0414 -> 1.9102  accuracy: 0.00% -> 44.25%      
client [11] (testset)   loss: 2.4610 -> 2.0175  accuracy: 7.96% -> 36.28%      
client [85] (testset)   loss: 2.4060 -> 2.1174  accuracy: 27.76% -> 27.76%     
client [12] (testset)   loss: 2.2352 -> 2.2388  accuracy: 12.73% -> 27.27%     
client [23] (testset)   loss: 2.1876 -> 2.0674  accuracy: 24.23% -> 16.54%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 1.9083 -> 1.3972  accuracy: 16.54% -> 59.84%     
client [65] (testset)   loss: 2.4157 -> 1.9785  accuracy: 6.52% -> 28.26%      
client [53] (testset)   loss: 2.2671 -> 1.8729  accuracy: 32.41% -> 32.41%     
client [58] (testset)   loss: 2.1584 -> 1.7279  accuracy: 31.11% -> 31.11%     
client [72] (testset)   loss: 2.4382 -> 2.0987  accuracy: 5.33% -> 26.63%      
client [7]  (testset)   loss: 2.1208 -> 1.8578  accuracy: 12.90% -> 41.94%     
client [71] (testset)   loss: 2.6535 -> 1.7739  accuracy: 0.00% -> 40.35%      
client [59] (testset)   loss: 2.6736 -> 2.0559  accuracy: 0.00% -> 24.49%      
client [86] (testset)   loss: 2.4566 -> 2.0010  accuracy: 3.57% -> 22.62%      
client [39] (testset)   loss: 2.5375 -> 1.9872  accuracy: 1.78% -> 20.12%      
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 2.2942 -> 1.9735  accuracy: 32.79% -> 32.79%     
client [7]  (testset)   loss: 2.1056 -> 1.8398  accuracy: 41.94% -> 41.94%     
client [17] (testset)   loss: 2.4525 -> 2.1095  accuracy: 9.23% -> 23.08%      
client [64] (testset)   loss: 2.3544 -> 2.1076  accuracy: 11.11% -> 15.87%     
client [37] (testset)   loss: 2.5392 -> 2.2696  accuracy: 19.51% -> 13.01%     
client [29] (testset)   loss: 2.5194 -> 2.2806  accuracy: 9.62% -> 24.04%      
client [93] (testset)   loss: 1.8252 -> 1.1965  accuracy: 69.57% -> 69.57%     
client [73] (testset)   loss: 2.3529 -> 1.8460  accuracy: 26.21% -> 27.18%     
client [40] (testset)   loss: 2.3292 -> 1.8590  accuracy: 23.21% -> 31.25%     
client [76] (testset)   loss: 2.2945 -> 2.1531  accuracy: 20.39% -> 20.39%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 2.4063 -> 2.1977  accuracy: 4.12% -> 15.46%      
client [89] (testset)   loss: 2.2543 -> 2.0380  accuracy: 21.60% -> 19.14%     
client [77] (testset)   loss: 2.4948 -> 2.0697  accuracy: 2.61% -> 24.84%      
client [90] (testset)   loss: 2.5714 -> 1.8259  accuracy: 0.00% -> 19.10%      
client [26] (testset)   loss: 2.0357 -> 1.4732  accuracy: 54.98% -> 54.98%     
client [50] (testset)   loss: 2.5429 -> 2.1372  accuracy: 14.53% -> 23.08%     
client [30] (testset)   loss: 2.5571 -> 1.8250  accuracy: 7.14% -> 32.47%      
client [70] (testset)   loss: 2.3501 -> 1.7958  accuracy: 30.17% -> 30.17%     
client [41] (testset)   loss: 2.8367 -> 1.8942  accuracy: 0.00% -> 44.25%      
client [99] (testset)   loss: 2.2143 -> 1.9973  accuracy: 32.79% -> 32.79%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [68] (testset)   loss: 2.3812 -> 2.0741  accuracy: 16.80% -> 20.00%     
client [70] (testset)   loss: 2.2713 -> 1.7809  accuracy: 30.17% -> 30.17%     
client [52] (testset)   loss: 2.3148 -> 1.9099  accuracy: 1.31% -> 28.38%      
client [1]  (testset)   loss: 2.2436 -> 2.0297  accuracy: 23.66% -> 23.66%     
client [2]  (testset)   loss: 2.1843 -> 2.0078  accuracy: 8.33% -> 33.85%      
client [67] (testset)   loss: 2.3979 -> 2.0694  accuracy: 20.18% -> 19.27%     
client [92] (testset)   loss: 2.5382 -> 2.0975  accuracy: 2.48% -> 21.49%      
client [35] (testset)   loss: 2.3853 -> 2.0447  accuracy: 17.78% -> 23.33%     
client [36] (testset)   loss: 2.2093 -> 1.8557  accuracy: 3.21% -> 36.54%      
client [64] (testset)   loss: 2.1694 -> 2.1349  accuracy: 11.11% -> 15.87%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 2.2061 -> 2.0638  accuracy: 21.62% -> 28.38%     
client [6]  (testset)   loss: 2.2698 -> 2.0711  accuracy: 7.30% -> 24.72%      
client [12] (testset)   loss: 2.2128 -> 2.2056  accuracy: 27.27% -> 27.27%     
client [55] (testset)   loss: 2.5960 -> 2.1396  accuracy: 17.72% -> 13.92%     
client [29] (testset)   loss: 2.5049 -> 2.3154  accuracy: 24.04% -> 24.04%     
client [9]  (testset)   loss: 2.3084 -> 2.1155  accuracy: 16.30% -> 31.11%     
client [43] (testset)   loss: 2.3312 -> 2.1493  accuracy: 24.17% -> 24.17%     
client [77] (testset)   loss: 2.5718 -> 2.0593  accuracy: 4.58% -> 24.84%      
client [98] (testset)   loss: 2.5835 -> 2.1864  accuracy: 4.60% -> 28.74%      
client [78] (testset)   loss: 2.3608 -> 2.0683  accuracy: 1.64% -> 26.23%      
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 2.7192 -> 2.1216  accuracy: 2.48% -> 21.49%      
client [80] (testset)   loss: 2.4139 -> 2.0060  accuracy: 7.14% -> 35.71%      
client [63] (testset)   loss: 2.3118 -> 2.0394  accuracy: 16.41% -> 16.41%     
client [76] (testset)   loss: 2.3441 -> 2.1632  accuracy: 20.39% -> 20.39%     
client [78] (testset)   loss: 2.3857 -> 2.0690  accuracy: 8.20% -> 26.23%      
client [25] (testset)   loss: 2.1605 -> 1.8587  accuracy: 40.30% -> 40.30%     
client [58] (testset)   loss: 2.3149 -> 1.7246  accuracy: 1.11% -> 32.22%      
client [13] (testset)   loss: 2.4931 -> 2.1700  accuracy: 18.71% -> 19.30%     
client [17] (testset)   loss: 2.3771 -> 2.1334  accuracy: 9.23% -> 20.00%      
client [38] (testset)   loss: 2.4292 -> 1.9450  accuracy: 11.56% -> 39.31%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 2.3914 -> 2.0943  accuracy: 26.63% -> 26.63%     
client [82] (testset)   loss: 2.4188 -> 1.8328  accuracy: 1.74% -> 38.26%      
client [86] (testset)   loss: 2.3931 -> 2.0192  accuracy: 7.14% -> 16.67%      
client [51] (testset)   loss: 2.4086 -> 2.0582  accuracy: 8.57% -> 36.19%      
client [96] (testset)   loss: 2.3338 -> 2.0204  accuracy: 6.90% -> 22.41%      
client [42] (testset)   loss: 2.2258 -> 2.0647  accuracy: 20.95% -> 20.95%     
client [55] (testset)   loss: 2.5386 -> 2.1118  accuracy: 13.92% -> 13.92%     
client [13] (testset)   loss: 2.5353 -> 2.1375  accuracy: 18.71% -> 19.30%     
client [1]  (testset)   loss: 2.1654 -> 2.0401  accuracy: 23.66% -> 16.13%     
client [12] (testset)   loss: 2.3875 -> 2.2577  accuracy: 12.73% -> 27.27%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 2.3592 -> 2.0686  accuracy: 14.40% -> 23.20%     
client [23] (testset)   loss: 2.1831 -> 2.1021  accuracy: 16.54% -> 16.54%     
client [46] (testset)   loss: 2.2305 -> 1.9601  accuracy: 30.39% -> 30.39%     
client [41] (testset)   loss: 2.8871 -> 1.8877  accuracy: 4.42% -> 44.25%      
client [25] (testset)   loss: 2.0709 -> 1.8636  accuracy: 19.40% -> 40.30%     
client [58] (testset)   loss: 2.3107 -> 1.7585  accuracy: 12.22% -> 31.11%     
client [14] (testset)   loss: 2.1628 -> 1.9326  accuracy: 35.56% -> 35.56%     
client [33] (testset)   loss: 2.3928 -> 2.1205  accuracy: 17.65% -> 28.82%     
client [85] (testset)   loss: 2.3243 -> 2.1105  accuracy: 13.06% -> 27.76%     
client [62] (testset)   loss: 2.2125 -> 2.0492  accuracy: 7.06% -> 33.83%      
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 2.5016 -> 2.1147  accuracy: 3.45% -> 28.74%      
client [63] (testset)   loss: 2.2546 -> 2.0476  accuracy: 16.41% -> 12.50%     
client [70] (testset)   loss: 2.3129 -> 1.7856  accuracy: 30.17% -> 30.17%     
client [65] (testset)   loss: 2.5361 -> 1.9661  accuracy: 1.45% -> 28.26%      
client [14] (testset)   loss: 2.3623 -> 1.9675  accuracy: 9.63% -> 35.56%      
client [73] (testset)   loss: 2.3254 -> 1.8623  accuracy: 26.21% -> 27.18%     
client [34] (testset)   loss: 2.2752 -> 2.0318  accuracy: 32.74% -> 32.74%     
client [99] (testset)   loss: 2.2897 -> 1.9789  accuracy: 32.79% -> 32.79%     
client [69] (testset)   loss: 2.1891 -> 1.9529  accuracy: 30.13% -> 25.64%     
client [46] (testset)   loss: 2.3147 -> 1.9791  accuracy: 6.86% -> 30.39%      
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [99] (testset)   loss: 2.4428 -> 1.9794  accuracy: 4.10% -> 32.79%      
client [93] (testset)   loss: 2.4027 -> 1.2960  accuracy: 5.80% -> 69.57%      
client [11] (testset)   loss: 2.5878 -> 2.0115  accuracy: 7.08% -> 36.28%      
client [58] (testset)   loss: 2.2299 -> 1.7368  accuracy: 6.11% -> 31.11%      
client [81] (testset)   loss: 2.5587 -> 2.2409  accuracy: 25.00% -> 20.83%     
client [85] (testset)   loss: 2.4696 -> 2.0890  accuracy: 14.29% -> 27.76%     
client [89] (testset)   loss: 2.3479 -> 2.0523  accuracy: 0.62% -> 23.46%      
client [45] (testset)   loss: 2.3021 -> 1.8916  accuracy: 2.10% -> 33.57%      
client [8]  (testset)   loss: 2.3794 -> 1.8767  accuracy: 7.09% -> 46.10%      
client [68] (testset)   loss: 2.3613 -> 2.0655  accuracy: 0.80% -> 23.20%      
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 2.3427 -> 2.0773  accuracy: 19.27% -> 19.27%     
client [72] (testset)   loss: 2.3084 -> 2.1055  accuracy: 14.79% -> 26.63%     
client [1]  (testset)   loss: 2.2841 -> 2.0423  accuracy: 6.45% -> 16.13%      
client [78] (testset)   loss: 2.2561 -> 2.0793  accuracy: 17.21% -> 26.23%     
client [83] (testset)   loss: 2.2499 -> 1.7719  accuracy: 30.82% -> 30.82%     
client [21] (testset)   loss: 2.4475 -> 1.9932  accuracy: 3.87% -> 27.10%      
client [56] (testset)   loss: 2.1941 -> 1.9054  accuracy: 11.80% -> 32.58%     
client [44] (testset)   loss: 2.2746 -> 2.0830  accuracy: 10.14% -> 28.38%     
client [92] (testset)   loss: 2.5368 -> 2.1019  accuracy: 14.05% -> 21.49%     
client [27] (testset)   loss: 2.5303 -> 2.0033  accuracy: 4.51% -> 30.83%      
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 2.3559 -> 1.8125  accuracy: 2.70% -> 36.94%      
client [39] (testset)   loss: 2.3853 -> 1.9891  accuracy: 10.65% -> 20.12%     
client [65] (testset)   loss: 2.4191 -> 1.9877  accuracy: 1.45% -> 28.26%      
client [26] (testset)   loss: 2.0306 -> 1.4840  accuracy: 54.98% -> 54.98%     
client [19] (testset)   loss: 2.3618 -> 2.1237  accuracy: 11.80% -> 34.16%     
client [68] (testset)   loss: 2.1918 -> 2.1278  accuracy: 16.80% -> 16.80%     
client [41] (testset)   loss: 2.8890 -> 1.9164  accuracy: 0.00% -> 44.25%      
client [50] (testset)   loss: 2.5312 -> 2.1260  accuracy: 14.53% -> 23.08%     
client [75] (testset)   loss: 2.1459 -> 1.7547  accuracy: 39.29% -> 22.62%     
client [81] (testset)   loss: 2.6806 -> 2.2654  accuracy: 4.17% -> 12.50%      
Training... ---------------------------------------- 100% 0:12:56
FedAvg's average time taken by each global epoch: 0 min 1.93 sec.              
FedAvg's total running time: 0 h 12 m 56 s.                                    
==================== FedAvg Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "2.3534 -> 0.0000",                                    
                "accuracy": "9.86% -> 0.00%"                                   
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "2.3501 -> 0.0000",                                    
                "accuracy": "18.16% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "2.3681 -> 0.0000",                                    
                "accuracy": "18.16% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "2.3295 -> 0.0000",                                    
                "accuracy": "11.60% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedAvg Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 18.16% at epoch 200                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
[0m