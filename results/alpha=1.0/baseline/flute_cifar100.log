==================== FLUTE ====================                                
Experiment Arguments:                                                          
{
│   'method': 'flute',
│   'dataset': {
│   │   'name': 'cifar100',
│   │   'client_num': 100,
│   │   'test_ratio': 0.25,
│   │   'val_ratio': 0.0,
│   │   'seed': 42,
│   │   'split': 'sample',
│   │   'IID_ratio': 0.0,
│   │   'monitor_window_name_suffix': 'cifar100-100clients-0%IID-use20superclasses-Dir(1.0)-seed42',
│   │   'super_class': False,
│   │   'alpha': 1.0,
│   │   'min_samples_per_client': 10
│   },
│   'model': {
│   │   'name': 'avgcnn',
│   │   'use_torchvision_pretrained_weights': True,
│   │   'external_model_weights_path': None
│   },
│   'optimizer': {
│   │   'lr': 0.01,
│   │   'dampening': 0,
│   │   'weight_decay': 0,
│   │   'momentum': 0,
│   │   'nesterov': False,
│   │   'name': 'sgd'
│   },
│   'mode': 'serial',
│   'parallel': {
│   │   'ray_cluster_addr': None,
│   │   'num_cpus': None,
│   │   'num_gpus': None,
│   │   'num_workers': 2
│   },
│   'common': {
│   │   'seed': 42,
│   │   'join_ratio': 0.1,
│   │   'global_epoch': 400,
│   │   'local_epoch': 5,
│   │   'batch_size': 32,
│   │   'reset_optimizer_on_global_epoch': True,
│   │   'straggler_ratio': 0,
│   │   'straggler_min_local_epoch': 0,
│   │   'buffers': 'global',
│   │   'client_side_evaluation': True,
│   │   'test': {
│   │   │   'client': {
│   │   │   │   'interval': 100,
│   │   │   │   'finetune_epoch': 0,
│   │   │   │   'train': False,
│   │   │   │   'val': False,
│   │   │   │   'test': True
│   │   │   },
│   │   │   'server': {
│   │   │   │   'interval': -1,
│   │   │   │   'train': False,
│   │   │   │   'val': False,
│   │   │   │   'test': False,
│   │   │   │   'model_in_train_mode': False
│   │   │   }
│   │   },
│   │   'verbose_gap': 10,
│   │   'monitor': None,
│   │   'use_cuda': True,
│   │   'save_log': True,
│   │   'save_model': False,
│   │   'save_learning_curve_plot': False,
│   │   'save_metrics': True,
│   │   'delete_useless_run': True
│   },
│   'flute': {
│   │   'rep_round': 1,
│   │   'lamda1': 0.25,
│   │   'lamda2': 0.0025,
│   │   'lamda3': 0.0005,
│   │   'gamma1': 1,
│   │   'gamma2': 1,
│   │   'nc2_lr': 0.5
│   }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 4.5052 -> 4.4759  accuracy: 2.50% -> 2.50%       
client [81] (testset)   loss: 4.5230 -> 4.4904  accuracy: 4.83% -> 4.83%       
client [21] (testset)   loss: 4.6088 -> 4.5726  accuracy: 2.05% -> 2.05%       
client [68] (testset)   loss: 4.5500 -> 4.5118  accuracy: 4.22% -> 3.01%       
client [93] (testset)   loss: 4.5522 -> 4.5181  accuracy: 3.60% -> 2.16%       
client [31] (testset)   loss: 4.5815 -> 4.5563  accuracy: 1.54% -> 2.31%       
client [20] (testset)   loss: 4.5265 -> 4.4904  accuracy: 9.23% -> 8.46%       
client [59] (testset)   loss: 4.5881 -> 4.5438  accuracy: 1.45% -> 4.35%       
client [48] (testset)   loss: 4.4773 -> 4.4570  accuracy: 5.65% -> 3.95%       
client [34] (testset)   loss: 4.5436 -> 4.4848  accuracy: 3.80% -> 3.80%       
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 4.4436 -> 4.3889  accuracy: 8.07% -> 6.83%       
client [99] (testset)   loss: 4.5468 -> 4.5071  accuracy: 4.40% -> 6.59%       
client [67] (testset)   loss: 4.5725 -> 4.5420  accuracy: 1.32% -> 0.66%       
client [0]  (testset)   loss: 4.5023 -> 4.4686  accuracy: 2.94% -> 2.94%       
client [76] (testset)   loss: 4.5590 -> 4.5488  accuracy: 2.48% -> 2.48%       
client [41] (testset)   loss: 4.5280 -> 4.4889  accuracy: 5.76% -> 5.76%       
client [62] (testset)   loss: 4.5864 -> 4.5375  accuracy: 2.40% -> 8.80%       
client [2]  (testset)   loss: 4.5995 -> 4.5531  accuracy: 3.07% -> 6.75%       
client [14] (testset)   loss: 4.4910 -> 4.4670  accuracy: 6.20% -> 6.98%       
client [46] (testset)   loss: 4.3639 -> 4.3246  accuracy: 8.70% -> 10.56%      
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 4.5054 -> 4.4823  accuracy: 4.35% -> 4.35%       
client [68] (testset)   loss: 4.4434 -> 4.4298  accuracy: 3.61% -> 3.61%       
client [57] (testset)   loss: 4.4664 -> 4.4217  accuracy: 7.69% -> 7.69%       
client [17] (testset)   loss: 4.5265 -> 4.5062  accuracy: 3.33% -> 3.33%       
client [54] (testset)   loss: 4.4169 -> 4.4068  accuracy: 5.93% -> 5.93%       
client [23] (testset)   loss: 4.5997 -> 4.5070  accuracy: 1.18% -> 6.47%       
client [35] (testset)   loss: 4.4540 -> 4.4360  accuracy: 4.79% -> 4.79%       
client [59] (testset)   loss: 4.4782 -> 4.4550  accuracy: 6.52% -> 6.52%       
client [31] (testset)   loss: 4.5031 -> 4.4967  accuracy: 2.31% -> 2.31%       
client [9]  (testset)   loss: 4.4376 -> 4.4038  accuracy: 6.47% -> 6.47%       
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 4.4818 -> 4.4658  accuracy: 6.85% -> 6.85%       
client [33] (testset)   loss: 4.4353 -> 4.4299  accuracy: 4.49% -> 5.13%       
client [16] (testset)   loss: 4.4880 -> 4.4638  accuracy: 3.12% -> 3.91%       
client [44] (testset)   loss: 4.5503 -> 4.5075  accuracy: 3.57% -> 4.29%       
client [8]  (testset)   loss: 4.4911 -> 4.4851  accuracy: 5.80% -> 5.80%       
client [31] (testset)   loss: 4.4921 -> 4.4882  accuracy: 2.31% -> 2.31%       
client [47] (testset)   loss: 4.3571 -> 4.3163  accuracy: 10.80% -> 10.80%     
client [36] (testset)   loss: 4.5107 -> 4.4604  accuracy: 6.63% -> 7.23%       
client [20] (testset)   loss: 4.4046 -> 4.3931  accuracy: 8.46% -> 8.46%       
client [56] (testset)   loss: 4.4994 -> 4.4620  accuracy: 7.35% -> 7.35%       
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 4.4481 -> 4.4298  accuracy: 6.08% -> 6.08%       
client [60] (testset)   loss: 4.4916 -> 4.4573  accuracy: 5.71% -> 5.71%       
client [28] (testset)   loss: 4.4247 -> 4.4096  accuracy: 3.45% -> 3.45%       
client [25] (testset)   loss: 4.4996 -> 4.4766  accuracy: 3.12% -> 5.47%       
client [58] (testset)   loss: 4.3158 -> 4.2991  accuracy: 12.40% -> 12.40%     
client [44] (testset)   loss: 4.5077 -> 4.4724  accuracy: 4.29% -> 4.29%       
client [39] (testset)   loss: 4.4932 -> 4.4717  accuracy: 4.55% -> 5.84%       
client [29] (testset)   loss: 4.4032 -> 4.3920  accuracy: 4.32% -> 5.41%       
client [3]  (testset)   loss: 4.4176 -> 4.3952  accuracy: 4.95% -> 4.95%       
client [84] (testset)   loss: 4.4130 -> 4.3992  accuracy: 7.04% -> 7.75%       
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 4.5194 -> 4.5004  accuracy: 3.42% -> 2.74%       
client [84] (testset)   loss: 4.3907 -> 4.3816  accuracy: 8.45% -> 9.15%       
client [10] (testset)   loss: 4.4501 -> 4.4356  accuracy: 3.29% -> 3.29%       
client [36] (testset)   loss: 4.3985 -> 4.3782  accuracy: 7.83% -> 7.83%       
client [65] (testset)   loss: 4.4385 -> 4.4294  accuracy: 4.67% -> 4.67%       
client [81] (testset)   loss: 4.4159 -> 4.4044  accuracy: 4.83% -> 4.83%       
client [79] (testset)   loss: 4.4275 -> 4.4144  accuracy: 3.98% -> 3.98%       
client [42] (testset)   loss: 4.3662 -> 4.3499  accuracy: 5.73% -> 5.73%       
client [11] (testset)   loss: 4.5073 -> 4.4970  accuracy: 2.90% -> 2.90%       
client [96] (testset)   loss: 4.4113 -> 4.3898  accuracy: 4.92% -> 4.92%       
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 4.4780 -> 4.4743  accuracy: 5.80% -> 5.80%       
client [53] (testset)   loss: 4.4234 -> 4.4057  accuracy: 5.48% -> 5.48%       
client [52] (testset)   loss: 4.3018 -> 4.2863  accuracy: 4.55% -> 4.55%       
client [42] (testset)   loss: 4.3406 -> 4.3293  accuracy: 5.73% -> 5.73%       
client [69] (testset)   loss: 4.2530 -> 4.2423  accuracy: 9.94% -> 10.56%      
client [59] (testset)   loss: 4.4152 -> 4.4059  accuracy: 5.80% -> 5.80%       
client [7]  (testset)   loss: 4.5093 -> 4.5048  accuracy: 4.29% -> 4.29%       
client [26] (testset)   loss: 4.3701 -> 4.3470  accuracy: 4.94% -> 5.56%       
client [49] (testset)   loss: 4.4472 -> 4.4362  accuracy: 3.29% -> 3.29%       
client [98] (testset)   loss: 4.4878 -> 4.4841  accuracy: 2.67% -> 2.67%       
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 4.4841 -> 4.4785  accuracy: 2.67% -> 2.67%       
client [47] (testset)   loss: 4.2941 -> 4.2745  accuracy: 10.80% -> 10.80%     
client [21] (testset)   loss: 4.4864 -> 4.4745  accuracy: 2.74% -> 2.74%       
client [77] (testset)   loss: 4.4084 -> 4.4036  accuracy: 3.12% -> 3.12%       
client [95] (testset)   loss: 4.3432 -> 4.3329  accuracy: 8.76% -> 8.76%       
client [91] (testset)   loss: 4.3460 -> 4.3388  accuracy: 7.22% -> 7.22%       
client [14] (testset)   loss: 4.4051 -> 4.3987  accuracy: 7.75% -> 7.75%       
client [99] (testset)   loss: 4.4395 -> 4.4327  accuracy: 3.85% -> 3.85%       
client [20] (testset)   loss: 4.3665 -> 4.3630  accuracy: 8.46% -> 8.46%       
client [39] (testset)   loss: 4.4445 -> 4.4355  accuracy: 6.49% -> 5.84%       
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 4.2886 -> 4.2752  accuracy: 4.55% -> 4.55%       
client [62] (testset)   loss: 4.3491 -> 4.3420  accuracy: 6.40% -> 6.40%       
client [71] (testset)   loss: 4.3127 -> 4.3033  accuracy: 9.49% -> 9.49%       
client [97] (testset)   loss: 4.4269 -> 4.4183  accuracy: 2.48% -> 3.73%       
client [30] (testset)   loss: 4.3960 -> 4.3903  accuracy: 5.06% -> 5.06%       
client [88] (testset)   loss: 4.3839 -> 4.3685  accuracy: 4.29% -> 4.29%       
client [60] (testset)   loss: 4.3784 -> 4.3714  accuracy: 6.43% -> 6.43%       
client [82] (testset)   loss: 4.4205 -> 4.4127  accuracy: 2.96% -> 2.96%       
client [91] (testset)   loss: 4.3349 -> 4.3292  accuracy: 7.22% -> 7.22%       
client [57] (testset)   loss: 4.3557 -> 4.3429  accuracy: 7.69% -> 8.33%       
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 4.4592 -> 4.4570  accuracy: 2.31% -> 2.31%       
client [15] (testset)   loss: 4.3794 -> 4.3656  accuracy: 5.00% -> 5.00%       
client [71] (testset)   loss: 4.3056 -> 4.2976  accuracy: 9.49% -> 9.49%       
client [97] (testset)   loss: 4.4080 -> 4.4027  accuracy: 3.73% -> 3.73%       
client [53] (testset)   loss: 4.3785 -> 4.3718  accuracy: 5.48% -> 5.48%       
client [77] (testset)   loss: 4.4045 -> 4.3994  accuracy: 3.12% -> 3.12%       
client [76] (testset)   loss: 4.5247 -> 4.5235  accuracy: 2.48% -> 2.48%       
client [79] (testset)   loss: 4.4009 -> 4.3940  accuracy: 3.98% -> 3.98%       
client [28] (testset)   loss: 4.3624 -> 4.3563  accuracy: 2.76% -> 2.76%       
client [99] (testset)   loss: 4.4298 -> 4.4247  accuracy: 4.40% -> 4.40%       
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 4.3981 -> 4.3938  accuracy: 4.35% -> 3.73%       
client [86] (testset)   loss: 4.4024 -> 4.3961  accuracy: 2.82% -> 2.82%       
client [34] (testset)   loss: 4.2895 -> 4.2824  accuracy: 4.43% -> 4.43%       
client [73] (testset)   loss: 4.3669 -> 4.3597  accuracy: 1.83% -> 3.05%       
client [5]  (testset)   loss: 4.4709 -> 4.4693  accuracy: 5.92% -> 6.58%       
client [96] (testset)   loss: 4.3173 -> 4.3109  accuracy: 5.74% -> 5.74%       
client [22] (testset)   loss: 4.4032 -> 4.3968  accuracy: 6.34% -> 6.34%       
client [60] (testset)   loss: 4.3578 -> 4.3526  accuracy: 5.71% -> 6.43%       
client [66] (testset)   loss: 4.3915 -> 4.3840  accuracy: 4.73% -> 4.73%       
client [83] (testset)   loss: 4.2887 -> 4.2796  accuracy: 2.55% -> 3.18%       
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 4.5195 -> 4.5187  accuracy: 2.48% -> 2.48%       
client [65] (testset)   loss: 4.4202 -> 4.4185  accuracy: 4.67% -> 4.67%       
client [95] (testset)   loss: 4.3145 -> 4.3069  accuracy: 13.87% -> 13.87%     
client [17] (testset)   loss: 4.4702 -> 4.4631  accuracy: 6.00% -> 6.00%       
client [8]  (testset)   loss: 4.4673 -> 4.4647  accuracy: 5.80% -> 5.80%       
client [35] (testset)   loss: 4.3837 -> 4.3804  accuracy: 4.79% -> 4.79%       
client [98] (testset)   loss: 4.4729 -> 4.4705  accuracy: 2.00% -> 2.00%       
client [53] (testset)   loss: 4.3676 -> 4.3624  accuracy: 5.48% -> 5.48%       
client [43] (testset)   loss: 4.3067 -> 4.2990  accuracy: 3.45% -> 3.45%       
client [64] (testset)   loss: 4.4357 -> 4.4325  accuracy: 6.85% -> 6.85%       
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 4.4667 -> 4.4586  accuracy: 2.74% -> 2.74%       
client [88] (testset)   loss: 4.3299 -> 4.3237  accuracy: 5.71% -> 6.43%       
client [38] (testset)   loss: 4.1870 -> 4.1770  accuracy: 12.14% -> 12.14%     
client [3]  (testset)   loss: 4.3251 -> 4.3200  accuracy: 5.94% -> 5.94%       
client [5]  (testset)   loss: 4.4677 -> 4.4664  accuracy: 6.58% -> 6.58%       
client [41] (testset)   loss: 4.3599 -> 4.3492  accuracy: 2.88% -> 2.88%       
client [7]  (testset)   loss: 4.4996 -> 4.4964  accuracy: 4.29% -> 4.29%       
client [37] (testset)   loss: 4.2753 -> 4.2649  accuracy: 4.86% -> 4.86%       
client [45] (testset)   loss: 4.3799 -> 4.3717  accuracy: 6.29% -> 6.29%       
client [47] (testset)   loss: 4.2586 -> 4.2491  accuracy: 10.80% -> 10.80%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 4.3779 -> 4.3729  accuracy: 6.25% -> 5.47%       
client [11] (testset)   loss: 4.4623 -> 4.4588  accuracy: 2.90% -> 3.62%       
client [37] (testset)   loss: 4.2531 -> 4.2457  accuracy: 5.56% -> 5.56%       
client [41] (testset)   loss: 4.3509 -> 4.3465  accuracy: 2.88% -> 3.60%       
client [95] (testset)   loss: 4.2947 -> 4.2887  accuracy: 13.87% -> 14.60%     
client [53] (testset)   loss: 4.3633 -> 4.3586  accuracy: 5.48% -> 5.48%       
client [22] (testset)   loss: 4.3935 -> 4.3885  accuracy: 6.34% -> 6.34%       
client [25] (testset)   loss: 4.4257 -> 4.4211  accuracy: 6.25% -> 6.25%       
client [69] (testset)   loss: 4.2075 -> 4.2021  accuracy: 10.56% -> 10.56%     
client [46] (testset)   loss: 4.2342 -> 4.2267  accuracy: 13.04% -> 11.18%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 4.2349 -> 4.2292  accuracy: 10.80% -> 10.80%     
client [69] (testset)   loss: 4.2018 -> 4.1982  accuracy: 10.56% -> 10.56%     
client [82] (testset)   loss: 4.3956 -> 4.3909  accuracy: 2.96% -> 2.96%       
client [45] (testset)   loss: 4.3642 -> 4.3591  accuracy: 6.29% -> 6.29%       
client [7]  (testset)   loss: 4.4966 -> 4.4946  accuracy: 4.29% -> 4.29%       
client [50] (testset)   loss: 4.2964 -> 4.2835  accuracy: 9.02% -> 9.84%       
client [35] (testset)   loss: 4.3774 -> 4.3743  accuracy: 4.79% -> 4.79%       
client [24] (testset)   loss: 4.3872 -> 4.3834  accuracy: 5.80% -> 5.80%       
client [15] (testset)   loss: 4.3348 -> 4.3279  accuracy: 5.71% -> 5.00%       
client [58] (testset)   loss: 4.2079 -> 4.2025  accuracy: 12.40% -> 11.57%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 4.3810 -> 4.3780  accuracy: 7.34% -> 6.78%       
client [76] (testset)   loss: 4.5154 -> 4.5151  accuracy: 2.48% -> 2.48%       
client [67] (testset)   loss: 4.4509 -> 4.4478  accuracy: 1.32% -> 1.32%       
client [37] (testset)   loss: 4.2430 -> 4.2359  accuracy: 5.56% -> 5.56%       
client [58] (testset)   loss: 4.2007 -> 4.1963  accuracy: 11.57% -> 11.57%     
client [64] (testset)   loss: 4.4272 -> 4.4246  accuracy: 6.85% -> 6.85%       
client [77] (testset)   loss: 4.3833 -> 4.3794  accuracy: 3.12% -> 3.12%       
client [55] (testset)   loss: 4.2259 -> 4.2190  accuracy: 7.75% -> 7.75%       
client [12] (testset)   loss: 4.2912 -> 4.2849  accuracy: 8.05% -> 8.05%       
client [89] (testset)   loss: 4.3283 -> 4.3247  accuracy: 10.96% -> 10.27%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 4.3344 -> 4.3318  accuracy: 9.15% -> 9.15%       
client [51] (testset)   loss: 4.3722 -> 4.3687  accuracy: 2.82% -> 3.52%       
client [8]  (testset)   loss: 4.4552 -> 4.4533  accuracy: 5.80% -> 5.80%       
client [18] (testset)   loss: 4.2228 -> 4.2153  accuracy: 8.50% -> 8.50%       
client [94] (testset)   loss: 4.2930 -> 4.2879  accuracy: 3.57% -> 3.57%       
client [81] (testset)   loss: 4.3495 -> 4.3460  accuracy: 4.83% -> 4.83%       
client [3]  (testset)   loss: 4.3097 -> 4.3053  accuracy: 5.94% -> 5.45%       
client [11] (testset)   loss: 4.4516 -> 4.4487  accuracy: 3.62% -> 3.62%       
client [95] (testset)   loss: 4.2695 -> 4.2646  accuracy: 17.52% -> 17.52%     
client [67] (testset)   loss: 4.4482 -> 4.4451  accuracy: 1.32% -> 1.32%       
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 4.4489 -> 4.4437  accuracy: 3.42% -> 3.42%       
client [79] (testset)   loss: 4.3679 -> 4.3648  accuracy: 3.98% -> 3.98%       
client [58] (testset)   loss: 4.1885 -> 4.1844  accuracy: 12.40% -> 11.57%     
client [88] (testset)   loss: 4.3149 -> 4.3100  accuracy: 5.71% -> 6.43%       
client [46] (testset)   loss: 4.2127 -> 4.2033  accuracy: 9.94% -> 11.18%      
client [11] (testset)   loss: 4.4493 -> 4.4465  accuracy: 3.62% -> 3.62%       
client [55] (testset)   loss: 4.2020 -> 4.1970  accuracy: 7.75% -> 7.75%       
client [13] (testset)   loss: 4.3556 -> 4.3520  accuracy: 8.16% -> 8.16%       
client [31] (testset)   loss: 4.4515 -> 4.4506  accuracy: 3.08% -> 3.08%       
client [75] (testset)   loss: 4.4065 -> 4.4040  accuracy: 6.10% -> 6.10%       
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 4.2344 -> 4.2312  accuracy: 8.72% -> 8.72%       
client [7]  (testset)   loss: 4.4814 -> 4.4805  accuracy: 4.29% -> 4.29%       
client [57] (testset)   loss: 4.3019 -> 4.2969  accuracy: 8.97% -> 8.97%       
client [13] (testset)   loss: 4.3505 -> 4.3473  accuracy: 8.16% -> 8.16%       
client [43] (testset)   loss: 4.2797 -> 4.2749  accuracy: 6.90% -> 6.90%       
client [91] (testset)   loss: 4.3166 -> 4.3124  accuracy: 7.22% -> 7.22%       
client [10] (testset)   loss: 4.3700 -> 4.3665  accuracy: 5.26% -> 5.26%       
client [64] (testset)   loss: 4.4187 -> 4.4167  accuracy: 6.85% -> 6.85%       
client [82] (testset)   loss: 4.3770 -> 4.3735  accuracy: 4.14% -> 4.14%       
client [22] (testset)   loss: 4.3763 -> 4.3736  accuracy: 6.34% -> 6.34%       
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 4.3408 -> 4.3371  accuracy: 8.46% -> 8.46%       
client [23] (testset)   loss: 4.2404 -> 4.2316  accuracy: 8.24% -> 8.24%       
client [88] (testset)   loss: 4.3116 -> 4.3060  accuracy: 6.43% -> 5.71%       
client [98] (testset)   loss: 4.4562 -> 4.4559  accuracy: 2.67% -> 2.00%       
client [79] (testset)   loss: 4.3625 -> 4.3597  accuracy: 3.98% -> 3.98%       
client [21] (testset)   loss: 4.4407 -> 4.4362  accuracy: 3.42% -> 3.42%       
client [92] (testset)   loss: 4.4198 -> 4.4168  accuracy: 4.23% -> 4.23%       
client [56] (testset)   loss: 4.3222 -> 4.3189  accuracy: 7.35% -> 7.35%       
client [5]  (testset)   loss: 4.4568 -> 4.4564  accuracy: 6.58% -> 6.58%       
client [52] (testset)   loss: 4.2195 -> 4.2142  accuracy: 7.79% -> 7.79%       
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 4.4306 -> 4.4288  accuracy: 1.32% -> 1.32%       
client [54] (testset)   loss: 4.3714 -> 4.3732  accuracy: 6.78% -> 7.63%       
client [14] (testset)   loss: 4.3624 -> 4.3592  accuracy: 6.98% -> 10.08%      
client [99] (testset)   loss: 4.4034 -> 4.4006  accuracy: 5.49% -> 5.49%       
client [36] (testset)   loss: 4.3061 -> 4.3023  accuracy: 7.83% -> 8.43%       
client [30] (testset)   loss: 4.3647 -> 4.3613  accuracy: 5.62% -> 5.62%       
client [38] (testset)   loss: 4.1485 -> 4.1451  accuracy: 15.00% -> 15.00%     
client [15] (testset)   loss: 4.3127 -> 4.3069  accuracy: 5.71% -> 5.00%       
client [6]  (testset)   loss: 4.3298 -> 4.3264  accuracy: 3.27% -> 3.27%       
client [53] (testset)   loss: 4.3362 -> 4.3337  accuracy: 6.85% -> 6.85%       
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [99] (testset)   loss: 4.3956 -> 4.3923  accuracy: 4.95% -> 6.04%       
client [6]  (testset)   loss: 4.3271 -> 4.3228  accuracy: 3.27% -> 3.27%       
client [83] (testset)   loss: 4.2365 -> 4.2311  accuracy: 6.37% -> 6.37%       
client [42] (testset)   loss: 4.2782 -> 4.2735  accuracy: 6.37% -> 6.37%       
client [34] (testset)   loss: 4.2610 -> 4.2560  accuracy: 5.06% -> 5.06%       
client [15] (testset)   loss: 4.3087 -> 4.3035  accuracy: 5.00% -> 5.00%       
client [47] (testset)   loss: 4.2060 -> 4.2014  accuracy: 10.80% -> 10.80%     
client [55] (testset)   loss: 4.1961 -> 4.1905  accuracy: 7.75% -> 7.75%       
client [51] (testset)   loss: 4.3649 -> 4.3613  accuracy: 4.23% -> 4.23%       
client [95] (testset)   loss: 4.2553 -> 4.2509  accuracy: 17.52% -> 18.25%     
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 4.2728 -> 4.2682  accuracy: 12.66% -> 12.66%     
client [15] (testset)   loss: 4.3053 -> 4.3000  accuracy: 5.00% -> 5.00%       
client [33] (testset)   loss: 4.4035 -> 4.4015  accuracy: 5.13% -> 5.13%       
client [99] (testset)   loss: 4.3939 -> 4.3902  accuracy: 5.49% -> 6.59%       
client [90] (testset)   loss: 4.3666 -> 4.3646  accuracy: 7.09% -> 7.09%       
client [57] (testset)   loss: 4.2812 -> 4.2769  accuracy: 9.62% -> 9.62%       
client [27] (testset)   loss: 4.3088 -> 4.3050  accuracy: 2.76% -> 2.76%       
client [78] (testset)   loss: 4.3427 -> 4.3394  accuracy: 6.21% -> 6.21%       
client [36] (testset)   loss: 4.3033 -> 4.3000  accuracy: 9.04% -> 8.43%       
client [88] (testset)   loss: 4.3008 -> 4.2960  accuracy: 5.71% -> 6.43%       
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 4.2575 -> 4.2531  accuracy: 4.11% -> 4.11%       
client [35] (testset)   loss: 4.3663 -> 4.3638  accuracy: 4.79% -> 4.79%       
client [16] (testset)   loss: 4.3411 -> 4.3378  accuracy: 6.25% -> 6.25%       
client [80] (testset)   loss: 4.2548 -> 4.2511  accuracy: 10.13% -> 10.13%     
client [38] (testset)   loss: 4.1446 -> 4.1403  accuracy: 15.71% -> 15.71%     
client [78] (testset)   loss: 4.3391 -> 4.3358  accuracy: 6.21% -> 6.21%       
client [68] (testset)   loss: 4.3682 -> 4.3656  accuracy: 6.02% -> 6.02%       
client [11] (testset)   loss: 4.4376 -> 4.4354  accuracy: 3.62% -> 3.62%       
client [64] (testset)   loss: 4.4115 -> 4.4097  accuracy: 7.53% -> 7.53%       
client [82] (testset)   loss: 4.3627 -> 4.3595  accuracy: 4.73% -> 4.73%       
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 4.3544 -> 4.3515  accuracy: 5.62% -> 5.62%       
client [27] (testset)   loss: 4.3066 -> 4.3028  accuracy: 2.76% -> 2.76%       
client [74] (testset)   loss: 4.4207 -> 4.4192  accuracy: 6.43% -> 6.43%       
client [45] (testset)   loss: 4.3400 -> 4.3371  accuracy: 6.29% -> 6.29%       
client [6]  (testset)   loss: 4.3218 -> 4.3192  accuracy: 3.27% -> 3.27%       
client [36] (testset)   loss: 4.3002 -> 4.2966  accuracy: 9.04% -> 9.04%       
client [63] (testset)   loss: 4.4106 -> 4.4084  accuracy: 5.79% -> 5.79%       
client [76] (testset)   loss: 4.5057 -> 4.5056  accuracy: 2.48% -> 2.48%       
client [83] (testset)   loss: 4.2267 -> 4.2218  accuracy: 6.37% -> 6.37%       
client [86] (testset)   loss: 4.3495 -> 4.3455  accuracy: 2.82% -> 2.82%       
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 4.2238 -> 4.2187  accuracy: 6.37% -> 6.37%       
client [99] (testset)   loss: 4.3909 -> 4.3875  accuracy: 5.49% -> 6.59%       
client [74] (testset)   loss: 4.4186 -> 4.4163  accuracy: 6.43% -> 7.14%       
client [73] (testset)   loss: 4.3221 -> 4.3194  accuracy: 4.88% -> 4.88%       
client [29] (testset)   loss: 4.3335 -> 4.3297  accuracy: 7.03% -> 7.03%       
client [92] (testset)   loss: 4.4117 -> 4.4096  accuracy: 4.93% -> 4.93%       
client [6]  (testset)   loss: 4.3182 -> 4.3159  accuracy: 3.27% -> 3.27%       
client [61] (testset)   loss: 4.3451 -> 4.3410  accuracy: 5.38% -> 5.38%       
client [21] (testset)   loss: 4.4284 -> 4.4251  accuracy: 3.42% -> 3.42%       
client [67] (testset)   loss: 4.4262 -> 4.4254  accuracy: 1.32% -> 1.32%       
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 4.2207 -> 4.2158  accuracy: 6.37% -> 6.37%       
client [32] (testset)   loss: 4.3163 -> 4.3130  accuracy: 5.49% -> 5.49%       
client [95] (testset)   loss: 4.2504 -> 4.2463  accuracy: 17.52% -> 17.52%     
client [61] (testset)   loss: 4.3367 -> 4.3330  accuracy: 5.38% -> 5.38%       
client [27] (testset)   loss: 4.3045 -> 4.3007  accuracy: 2.76% -> 2.76%       
client [25] (testset)   loss: 4.3961 -> 4.3945  accuracy: 6.25% -> 6.25%       
client [68] (testset)   loss: 4.3620 -> 4.3593  accuracy: 6.02% -> 6.02%       
client [34] (testset)   loss: 4.2545 -> 4.2498  accuracy: 4.43% -> 4.43%       
client [71] (testset)   loss: 4.2597 -> 4.2555  accuracy: 12.03% -> 11.39%     
client [89] (testset)   loss: 4.3145 -> 4.3113  accuracy: 10.27% -> 10.27%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 4.3263 -> 4.3230  accuracy: 6.21% -> 6.21%       
client [81] (testset)   loss: 4.3229 -> 4.3199  accuracy: 4.83% -> 4.83%       
client [51] (testset)   loss: 4.3507 -> 4.3481  accuracy: 5.63% -> 6.34%       
client [54] (testset)   loss: 4.3748 -> 4.3747  accuracy: 6.78% -> 6.78%       
client [65] (testset)   loss: 4.3927 -> 4.3923  accuracy: 4.67% -> 4.67%       
client [41] (testset)   loss: 4.3034 -> 4.3009  accuracy: 5.76% -> 4.32%       
client [11] (testset)   loss: 4.4330 -> 4.4310  accuracy: 3.62% -> 3.62%       
client [85] (testset)   loss: 4.3349 -> 4.3314  accuracy: 2.98% -> 3.57%       
client [12] (testset)   loss: 4.2592 -> 4.2547  accuracy: 10.07% -> 10.07%     
client [23] (testset)   loss: 4.2040 -> 4.1981  accuracy: 7.65% -> 7.65%       
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 4.3342 -> 4.3333  accuracy: 7.03% -> 7.03%       
client [65] (testset)   loss: 4.3924 -> 4.3925  accuracy: 4.67% -> 4.67%       
client [53] (testset)   loss: 4.3215 -> 4.3195  accuracy: 6.85% -> 6.85%       
client [58] (testset)   loss: 4.1617 -> 4.1580  accuracy: 13.22% -> 12.40%     
client [72] (testset)   loss: 4.4337 -> 4.4323  accuracy: 7.02% -> 7.02%       
client [7]  (testset)   loss: 4.4707 -> 4.4690  accuracy: 5.00% -> 5.00%       
client [71] (testset)   loss: 4.2579 -> 4.2539  accuracy: 11.39% -> 11.39%     
client [59] (testset)   loss: 4.3502 -> 4.3476  accuracy: 5.07% -> 5.07%       
client [86] (testset)   loss: 4.3381 -> 4.3350  accuracy: 2.82% -> 2.82%       
client [39] (testset)   loss: 4.3662 -> 4.3640  accuracy: 5.19% -> 5.19%       
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 4.3877 -> 4.3839  accuracy: 6.59% -> 5.49%       
client [7]  (testset)   loss: 4.4684 -> 4.4673  accuracy: 5.00% -> 5.00%       
client [17] (testset)   loss: 4.4052 -> 4.4058  accuracy: 6.00% -> 6.00%       
client [64] (testset)   loss: 4.4032 -> 4.4016  accuracy: 7.53% -> 7.53%       
client [37] (testset)   loss: 4.1934 -> 4.1892  accuracy: 7.64% -> 7.64%       
client [29] (testset)   loss: 4.3233 -> 4.3201  accuracy: 7.03% -> 7.03%       
client [93] (testset)   loss: 4.3818 -> 4.3787  accuracy: 2.16% -> 2.88%       
client [73] (testset)   loss: 4.3132 -> 4.3097  accuracy: 5.49% -> 5.49%       
client [40] (testset)   loss: 4.2219 -> 4.2181  accuracy: 8.98% -> 8.98%       
client [76] (testset)   loss: 4.5032 -> 4.5031  accuracy: 2.48% -> 2.48%       
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 4.4326 -> 4.4321  accuracy: 2.31% -> 2.31%       
client [89] (testset)   loss: 4.3087 -> 4.3056  accuracy: 10.27% -> 10.27%     
client [77] (testset)   loss: 4.3439 -> 4.3422  accuracy: 3.12% -> 3.12%       
client [90] (testset)   loss: 4.3515 -> 4.3498  accuracy: 7.80% -> 7.09%       
client [26] (testset)   loss: 4.2572 -> 4.2522  accuracy: 5.56% -> 5.56%       
client [50] (testset)   loss: 4.2210 -> 4.2165  accuracy: 9.84% -> 9.84%       
client [30] (testset)   loss: 4.3449 -> 4.3420  accuracy: 5.62% -> 5.62%       
client [70] (testset)   loss: 4.2458 -> 4.2418  accuracy: 4.11% -> 4.11%       
client [41] (testset)   loss: 4.2878 -> 4.2896  accuracy: 7.19% -> 5.04%       
client [99] (testset)   loss: 4.3854 -> 4.3815  accuracy: 5.49% -> 6.59%       
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [68] (testset)   loss: 4.3502 -> 4.3481  accuracy: 6.02% -> 6.02%       
client [70] (testset)   loss: 4.2404 -> 4.2366  accuracy: 4.11% -> 4.11%       
client [52] (testset)   loss: 4.1949 -> 4.1900  accuracy: 9.09% -> 9.09%       
client [1]  (testset)   loss: 4.4075 -> 4.4038  accuracy: 3.55% -> 3.55%       
client [2]  (testset)   loss: 4.3445 -> 4.3413  accuracy: 9.20% -> 9.20%       
client [67] (testset)   loss: 4.4171 -> 4.4162  accuracy: 1.97% -> 1.97%       
client [92] (testset)   loss: 4.3983 -> 4.3969  accuracy: 4.93% -> 5.63%       
client [35] (testset)   loss: 4.3590 -> 4.3565  accuracy: 5.39% -> 4.79%       
client [36] (testset)   loss: 4.2879 -> 4.2852  accuracy: 9.04% -> 9.04%       
client [64] (testset)   loss: 4.4015 -> 4.4000  accuracy: 6.85% -> 7.53%       
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 4.3137 -> 4.3110  accuracy: 5.00% -> 5.00%       
client [6]  (testset)   loss: 4.3060 -> 4.3028  accuracy: 3.27% -> 3.92%       
client [12] (testset)   loss: 4.2483 -> 4.2443  accuracy: 10.07% -> 10.07%     
client [55] (testset)   loss: 4.1818 -> 4.1770  accuracy: 11.27% -> 11.97%     
client [29] (testset)   loss: 4.3162 -> 4.3137  accuracy: 7.03% -> 7.03%       
client [9]  (testset)   loss: 4.2390 -> 4.2352  accuracy: 6.47% -> 6.47%       
client [43] (testset)   loss: 4.2553 -> 4.2515  accuracy: 8.28% -> 8.28%       
client [77] (testset)   loss: 4.3430 -> 4.3396  accuracy: 3.12% -> 3.12%       
client [98] (testset)   loss: 4.4441 -> 4.4430  accuracy: 3.33% -> 3.33%       
client [78] (testset)   loss: 4.3207 -> 4.3180  accuracy: 6.21% -> 6.90%       
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 4.3960 -> 4.3953  accuracy: 5.63% -> 6.34%       
client [80] (testset)   loss: 4.2440 -> 4.2406  accuracy: 9.49% -> 9.49%       
client [63] (testset)   loss: 4.3963 -> 4.3942  accuracy: 5.79% -> 5.79%       
client [76] (testset)   loss: 4.5008 -> 4.5011  accuracy: 2.48% -> 2.48%       
client [78] (testset)   loss: 4.3194 -> 4.3167  accuracy: 6.21% -> 6.90%       
client [25] (testset)   loss: 4.3896 -> 4.3876  accuracy: 6.25% -> 7.03%       
client [58] (testset)   loss: 4.1525 -> 4.1500  accuracy: 12.40% -> 12.40%     
client [13] (testset)   loss: 4.3273 -> 4.3250  accuracy: 10.20% -> 10.20%     
client [17] (testset)   loss: 4.3970 -> 4.3970  accuracy: 6.00% -> 6.00%       
client [38] (testset)   loss: 4.1181 -> 4.1157  accuracy: 18.57% -> 17.86%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 4.4261 -> 4.4247  accuracy: 6.14% -> 7.02%       
client [82] (testset)   loss: 4.3428 -> 4.3403  accuracy: 4.73% -> 4.73%       
client [86] (testset)   loss: 4.3240 -> 4.3213  accuracy: 2.82% -> 2.82%       
client [51] (testset)   loss: 4.3424 -> 4.3402  accuracy: 6.34% -> 6.34%       
client [96] (testset)   loss: 4.2631 -> 4.2603  accuracy: 7.38% -> 7.38%       
client [42] (testset)   loss: 4.2535 -> 4.2497  accuracy: 6.37% -> 6.37%       
client [55] (testset)   loss: 4.1703 -> 4.1670  accuracy: 11.27% -> 11.27%     
client [13] (testset)   loss: 4.3244 -> 4.3219  accuracy: 10.20% -> 10.20%     
client [1]  (testset)   loss: 4.4006 -> 4.3976  accuracy: 3.55% -> 3.55%       
client [12] (testset)   loss: 4.2463 -> 4.2424  accuracy: 10.07% -> 10.07%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 4.3473 -> 4.3451  accuracy: 6.02% -> 6.02%       
client [23] (testset)   loss: 4.1836 -> 4.1786  accuracy: 8.24% -> 8.24%       
client [46] (testset)   loss: 4.1514 -> 4.1450  accuracy: 14.91% -> 14.29%     
client [41] (testset)   loss: 4.2855 -> 4.2835  accuracy: 6.47% -> 7.91%       
client [25] (testset)   loss: 4.3775 -> 4.3715  accuracy: 6.25% -> 6.25%       
client [58] (testset)   loss: 4.1489 -> 4.1454  accuracy: 12.40% -> 13.22%     
client [14] (testset)   loss: 4.3452 -> 4.3428  accuracy: 8.53% -> 7.75%       
client [33] (testset)   loss: 4.3930 -> 4.3916  accuracy: 5.13% -> 5.13%       
client [85] (testset)   loss: 4.3217 -> 4.3190  accuracy: 4.17% -> 4.17%       
client [62] (testset)   loss: 4.2865 -> 4.2830  accuracy: 9.60% -> 9.60%       
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 4.4435 -> 4.4421  accuracy: 3.33% -> 3.33%       
client [63] (testset)   loss: 4.3921 -> 4.3899  accuracy: 5.79% -> 5.79%       
client [70] (testset)   loss: 4.2298 -> 4.2264  accuracy: 3.42% -> 3.42%       
client [65] (testset)   loss: 4.3869 -> 4.3860  accuracy: 4.67% -> 4.67%       
client [14] (testset)   loss: 4.3420 -> 4.3397  accuracy: 6.20% -> 6.20%       
client [73] (testset)   loss: 4.3054 -> 4.3030  accuracy: 5.49% -> 5.49%       
client [34] (testset)   loss: 4.2341 -> 4.2301  accuracy: 3.16% -> 3.16%       
client [99] (testset)   loss: 4.3814 -> 4.3773  accuracy: 5.49% -> 5.49%       
client [69] (testset)   loss: 4.1491 -> 4.1446  accuracy: 10.56% -> 10.56%     
client [46] (testset)   loss: 4.1469 -> 4.1413  accuracy: 14.91% -> 14.91%     
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [99] (testset)   loss: 4.3783 -> 4.3767  accuracy: 6.04% -> 5.49%       
client [93] (testset)   loss: 4.3740 -> 4.3722  accuracy: 4.32% -> 4.32%       
client [11] (testset)   loss: 4.4217 -> 4.4200  accuracy: 3.62% -> 3.62%       
client [58] (testset)   loss: 4.1414 -> 4.1388  accuracy: 13.22% -> 13.22%     
client [81] (testset)   loss: 4.3027 -> 4.3003  accuracy: 4.83% -> 4.83%       
client [85] (testset)   loss: 4.3205 -> 4.3174  accuracy: 4.17% -> 4.17%       
client [89] (testset)   loss: 4.2996 -> 4.2970  accuracy: 10.27% -> 10.27%     
client [45] (testset)   loss: 4.3265 -> 4.3235  accuracy: 6.29% -> 6.29%       
client [8]  (testset)   loss: 4.4379 -> 4.4367  accuracy: 6.52% -> 6.52%       
client [68] (testset)   loss: 4.3428 -> 4.3411  accuracy: 6.02% -> 6.02%       
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 4.4134 -> 4.4124  accuracy: 1.97% -> 1.97%       
client [72] (testset)   loss: 4.4230 -> 4.4216  accuracy: 7.02% -> 6.14%       
client [1]  (testset)   loss: 4.3946 -> 4.3942  accuracy: 3.55% -> 3.55%       
client [78] (testset)   loss: 4.3107 -> 4.3085  accuracy: 6.90% -> 6.90%       
client [83] (testset)   loss: 4.1798 -> 4.1763  accuracy: 7.64% -> 7.01%       
client [21] (testset)   loss: 4.4025 -> 4.4002  accuracy: 5.48% -> 5.48%       
client [56] (testset)   loss: 4.2880 -> 4.2860  accuracy: 7.35% -> 7.35%       
client [44] (testset)   loss: 4.3030 -> 4.3015  accuracy: 5.71% -> 5.71%       
client [92] (testset)   loss: 4.3935 -> 4.3918  accuracy: 6.34% -> 6.34%       
client [27] (testset)   loss: 4.2826 -> 4.2794  accuracy: 4.14% -> 3.45%       
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 4.3329 -> 4.3314  accuracy: 5.26% -> 5.26%       
client [39] (testset)   loss: 4.3568 -> 4.3553  accuracy: 5.19% -> 5.19%       
client [65] (testset)   loss: 4.3865 -> 4.3847  accuracy: 4.67% -> 4.67%       
client [26] (testset)   loss: 4.2319 -> 4.2294  accuracy: 6.79% -> 6.79%       
client [19] (testset)   loss: 4.1917 -> 4.1897  accuracy: 8.72% -> 8.72%       
client [68] (testset)   loss: 4.3412 -> 4.3396  accuracy: 6.02% -> 6.02%       
client [41] (testset)   loss: 4.2832 -> 4.2776  accuracy: 5.76% -> 6.47%       
client [50] (testset)   loss: 4.1899 -> 4.1863  accuracy: 10.66% -> 10.66%     
client [75] (testset)   loss: 4.3817 -> 4.3796  accuracy: 6.10% -> 6.10%       
client [81] (testset)   loss: 4.2988 -> 4.2968  accuracy: 4.83% -> 4.83%       
Training... ---------------------------------------- 100% 0:19:04
FLUTE's average time taken by each global epoch: 0 min 2.85 sec.               
FLUTE's total running time: 0 h 19 m 4 s.                                      
==================== FLUTE Experiment Results: ====================            
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "4.3747 -> 0.0000",                                    
                "accuracy": "5.53% -> 0.00%"                                   
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "4.3381 -> 0.0000",                                    
                "accuracy": "6.16% -> 0.00%"                                   
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "4.3186 -> 0.0000",                                    
                "accuracy": "6.69% -> 0.00%"                                   
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "4.3043 -> 0.0000",                                    
                "accuracy": "6.99% -> 0.00%"                                   
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FLUTE Max Accuracy ====================                   
all_clients:                                                                   
(test) before fine-tuning: 6.99% at epoch 400                                  
(test) after fine-tuning: 0.00% at epoch 100                                   
[0m