==================== LG-FedAvg ====================                            
Experiment Arguments:                                                          
{
â”‚   'method': 'lgfedavg',
â”‚   'dataset': {
â”‚   â”‚   'name': 'medmnistC',
â”‚   â”‚   'client_num': 100,
â”‚   â”‚   'test_ratio': 0.25,
â”‚   â”‚   'val_ratio': 0.0,
â”‚   â”‚   'seed': 42,
â”‚   â”‚   'split': 'sample',
â”‚   â”‚   'IID_ratio': 0.0,
â”‚   â”‚   'monitor_window_name_suffix': 'medmnistC-100clients-0%IID-Dir(1.0)-seed42',
â”‚   â”‚   'alpha': 1.0,
â”‚   â”‚   'min_samples_per_client': 10
â”‚   },
â”‚   'model': {
â”‚   â”‚   'name': 'lenet5',
â”‚   â”‚   'use_torchvision_pretrained_weights': True,
â”‚   â”‚   'external_model_weights_path': None
â”‚   },
â”‚   'optimizer': {
â”‚   â”‚   'lr': 0.01,
â”‚   â”‚   'dampening': 0,
â”‚   â”‚   'weight_decay': 0,
â”‚   â”‚   'momentum': 0,
â”‚   â”‚   'nesterov': False,
â”‚   â”‚   'name': 'sgd'
â”‚   },
â”‚   'mode': 'serial',
â”‚   'parallel': {
â”‚   â”‚   'ray_cluster_addr': None,
â”‚   â”‚   'num_cpus': None,
â”‚   â”‚   'num_gpus': None,
â”‚   â”‚   'num_workers': 2
â”‚   },
â”‚   'common': {
â”‚   â”‚   'seed': 42,
â”‚   â”‚   'join_ratio': 0.1,
â”‚   â”‚   'global_epoch': 400,
â”‚   â”‚   'local_epoch': 5,
â”‚   â”‚   'batch_size': 32,
â”‚   â”‚   'reset_optimizer_on_global_epoch': True,
â”‚   â”‚   'straggler_ratio': 0,
â”‚   â”‚   'straggler_min_local_epoch': 0,
â”‚   â”‚   'buffers': 'global',
â”‚   â”‚   'client_side_evaluation': True,
â”‚   â”‚   'test': {
â”‚   â”‚   â”‚   'client': {
â”‚   â”‚   â”‚   â”‚   'interval': 100,
â”‚   â”‚   â”‚   â”‚   'finetune_epoch': 0,
â”‚   â”‚   â”‚   â”‚   'train': False,
â”‚   â”‚   â”‚   â”‚   'val': False,
â”‚   â”‚   â”‚   â”‚   'test': True
â”‚   â”‚   â”‚   },
â”‚   â”‚   â”‚   'server': {
â”‚   â”‚   â”‚   â”‚   'interval': -1,
â”‚   â”‚   â”‚   â”‚   'train': False,
â”‚   â”‚   â”‚   â”‚   'val': False,
â”‚   â”‚   â”‚   â”‚   'test': False,
â”‚   â”‚   â”‚   â”‚   'model_in_train_mode': False
â”‚   â”‚   â”‚   }
â”‚   â”‚   },
â”‚   â”‚   'verbose_gap': 10,
â”‚   â”‚   'monitor': None,
â”‚   â”‚   'use_cuda': True,
â”‚   â”‚   'save_log': True,
â”‚   â”‚   'save_model': False,
â”‚   â”‚   'save_learning_curve_plot': False,
â”‚   â”‚   'save_metrics': True,
â”‚   â”‚   'delete_useless_run': True
â”‚   },
â”‚   'lgfedavg': {
â”‚   â”‚   'num_global_layers': 1
â”‚   }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 1.9867 -> 2.0044  accuracy: 30.00% -> 16.67%     
client [81] (testset)   loss: 1.9995 -> 1.9950  accuracy: 35.14% -> 35.14%     
client [21] (testset)   loss: 2.3538 -> 1.9534  accuracy: 24.56% -> 26.32%     
client [68] (testset)   loss: 1.8075 -> 1.7651  accuracy: 37.78% -> 37.78%     
client [93] (testset)   loss: 1.7527 -> 1.6979  accuracy: 45.65% -> 45.65%     
client [31] (testset)   loss: 2.2320 -> 1.8553  accuracy: 44.44% -> 44.44%     
client [20] (testset)   loss: 2.1882 -> 2.1727  accuracy: 18.03% -> 18.03%     
client [59] (testset)   loss: 2.4613 -> 2.1249  accuracy: 24.14% -> 24.14%     
client [48] (testset)   loss: 2.3146 -> 2.3234  accuracy: 17.39% -> 17.39%     
client [34] (testset)   loss: 1.9163 -> 1.9334  accuracy: 24.59% -> 24.59%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 2.0313 -> 2.0209  accuracy: 29.41% -> 29.41%     
client [99] (testset)   loss: 2.0703 -> 2.0630  accuracy: 10.26% -> 20.51%     
client [67] (testset)   loss: 2.0891 -> 2.1034  accuracy: 19.30% -> 22.81%     
client [0]  (testset)   loss: 1.7126 -> 1.7121  accuracy: 36.99% -> 36.99%     
client [76] (testset)   loss: 1.8879 -> 1.8640  accuracy: 27.78% -> 27.78%     
client [41] (testset)   loss: 2.0152 -> 2.0189  accuracy: 26.92% -> 26.92%     
client [62] (testset)   loss: 2.4547 -> 1.8518  accuracy: 3.45% -> 41.38%      
client [2]  (testset)   loss: 2.1840 -> 1.7770  accuracy: 49.40% -> 49.40%     
client [14] (testset)   loss: 2.0675 -> 2.0639  accuracy: 31.88% -> 31.88%     
client [46] (testset)   loss: 1.8389 -> 1.8462  accuracy: 48.94% -> 48.94%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 2.2039 -> 2.2919  accuracy: 20.00% -> 20.00%     
client [68] (testset)   loss: 1.7531 -> 1.7765  accuracy: 37.78% -> 37.78%     
client [57] (testset)   loss: 2.0839 -> 2.1047  accuracy: 34.78% -> 34.78%     
client [17] (testset)   loss: 1.9952 -> 1.9951  accuracy: 32.00% -> 32.00%     
client [54] (testset)   loss: 2.3671 -> 2.4663  accuracy: 18.75% -> 18.75%     
client [23] (testset)   loss: 2.3411 -> 2.0861  accuracy: 20.59% -> 20.59%     
client [35] (testset)   loss: 1.9667 -> 1.9651  accuracy: 33.33% -> 33.33%     
client [59] (testset)   loss: 2.0978 -> 2.0987  accuracy: 24.14% -> 24.14%     
client [31] (testset)   loss: 1.8888 -> 1.8366  accuracy: 44.44% -> 44.44%     
client [9]  (testset)   loss: 2.3651 -> 2.3633  accuracy: 13.33% -> 13.33%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 2.1774 -> 2.1830  accuracy: 20.00% -> 20.00%     
client [33] (testset)   loss: 1.8164 -> 1.8533  accuracy: 22.22% -> 22.22%     
client [16] (testset)   loss: 2.0340 -> 2.0252  accuracy: 26.67% -> 26.67%     
client [44] (testset)   loss: 2.1648 -> 2.1517  accuracy: 19.64% -> 23.21%     
client [8]  (testset)   loss: 1.9316 -> 1.9506  accuracy: 34.17% -> 34.17%     
client [31] (testset)   loss: 1.8591 -> 1.9139  accuracy: 44.44% -> 44.44%     
client [47] (testset)   loss: 1.7406 -> 1.7039  accuracy: 16.67% -> 47.22%     
client [36] (testset)   loss: 2.0657 -> 2.0608  accuracy: 24.49% -> 24.49%     
client [20] (testset)   loss: 2.2100 -> 2.1800  accuracy: 18.03% -> 18.03%     
client [56] (testset)   loss: 2.3335 -> 2.1729  accuracy: 7.27% -> 7.27%       
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 2.0214 -> 2.0272  accuracy: 30.19% -> 30.19%     
client [60] (testset)   loss: 2.2143 -> 2.2136  accuracy: 28.57% -> 28.57%     
client [28] (testset)   loss: 2.1888 -> 2.1894  accuracy: 12.33% -> 12.33%     
client [25] (testset)   loss: 2.4279 -> 2.4535  accuracy: 12.00% -> 12.00%     
client [58] (testset)   loss: 1.6854 -> 1.6883  accuracy: 42.47% -> 42.47%     
client [44] (testset)   loss: 2.1445 -> 2.1627  accuracy: 23.21% -> 23.21%     
client [39] (testset)   loss: 1.4089 -> 1.4084  accuracy: 53.77% -> 53.77%     
client [29] (testset)   loss: 1.7785 -> 1.7779  accuracy: 37.66% -> 37.66%     
client [3]  (testset)   loss: 2.3889 -> 2.4965  accuracy: 9.26% -> 9.26%       
client [84] (testset)   loss: 1.6418 -> 1.6670  accuracy: 38.53% -> 38.53%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 1.9692 -> 1.9692  accuracy: 26.32% -> 26.32%     
client [84] (testset)   loss: 1.7090 -> 1.6741  accuracy: 38.53% -> 38.53%     
client [10] (testset)   loss: 2.1287 -> 2.0886  accuracy: 38.89% -> 38.89%     
client [36] (testset)   loss: 2.0551 -> 2.0699  accuracy: 24.49% -> 24.49%     
client [65] (testset)   loss: 2.0147 -> 2.0518  accuracy: 37.74% -> 37.74%     
client [81] (testset)   loss: 2.0030 -> 2.0003  accuracy: 35.14% -> 35.14%     
client [79] (testset)   loss: 2.2552 -> 2.2567  accuracy: 21.15% -> 21.15%     
client [42] (testset)   loss: 2.3169 -> 2.2558  accuracy: 7.14% -> 7.14%       
client [11] (testset)   loss: 1.9707 -> 1.9712  accuracy: 30.36% -> 21.43%     
client [96] (testset)   loss: 2.0930 -> 2.0936  accuracy: 30.36% -> 30.36%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 1.8911 -> 1.9104  accuracy: 34.17% -> 34.17%     
client [53] (testset)   loss: 2.1179 -> 2.0869  accuracy: 38.71% -> 38.71%     
client [52] (testset)   loss: 1.2892 -> 1.3012  accuracy: 57.14% -> 57.14%     
client [42] (testset)   loss: 2.2339 -> 2.2682  accuracy: 17.86% -> 7.14%      
client [69] (testset)   loss: 2.0272 -> 2.0176  accuracy: 29.41% -> 29.41%     
client [59] (testset)   loss: 2.1054 -> 2.1215  accuracy: 24.14% -> 24.14%     
client [7]  (testset)   loss: 1.9443 -> 1.9253  accuracy: 32.79% -> 32.79%     
client [26] (testset)   loss: 2.1807 -> 2.1744  accuracy: 22.81% -> 22.81%     
client [49] (testset)   loss: 2.0002 -> 1.8997  accuracy: 15.15% -> 24.24%     
client [98] (testset)   loss: 2.0573 -> 2.0566  accuracy: 37.74% -> 37.74%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 2.0548 -> 2.0612  accuracy: 37.74% -> 37.74%     
client [47] (testset)   loss: 1.7302 -> 1.7121  accuracy: 47.22% -> 47.22%     
client [21] (testset)   loss: 1.9838 -> 1.9519  accuracy: 26.32% -> 26.32%     
client [77] (testset)   loss: 1.9833 -> 1.9779  accuracy: 30.00% -> 30.00%     
client [95] (testset)   loss: 1.9943 -> 2.0141  accuracy: 34.25% -> 34.25%     
client [91] (testset)   loss: 1.9755 -> 1.9978  accuracy: 37.93% -> 37.93%     
client [14] (testset)   loss: 2.0490 -> 2.0510  accuracy: 31.88% -> 31.88%     
client [99] (testset)   loss: 2.0669 -> 2.0746  accuracy: 10.26% -> 12.82%     
client [20] (testset)   loss: 2.1908 -> 2.1968  accuracy: 18.03% -> 18.03%     
client [39] (testset)   loss: 1.4170 -> 1.4040  accuracy: 53.77% -> 53.77%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 1.3143 -> 1.2981  accuracy: 57.14% -> 57.14%     
client [62] (testset)   loss: 1.8832 -> 1.8763  accuracy: 41.38% -> 41.38%     
client [71] (testset)   loss: 2.0261 -> 2.0838  accuracy: 23.33% -> 23.33%     
client [97] (testset)   loss: 1.8674 -> 1.8638  accuracy: 25.76% -> 31.82%     
client [30] (testset)   loss: 2.3508 -> 2.3503  accuracy: 15.15% -> 15.15%     
client [88] (testset)   loss: 2.2066 -> 2.1705  accuracy: 22.81% -> 22.81%     
client [60] (testset)   loss: 2.2033 -> 2.1934  accuracy: 28.57% -> 28.57%     
client [82] (testset)   loss: 1.9476 -> 1.9333  accuracy: 11.94% -> 11.94%     
client [91] (testset)   loss: 2.0208 -> 2.0403  accuracy: 13.79% -> 13.79%     
client [57] (testset)   loss: 2.0902 -> 2.1042  accuracy: 34.78% -> 34.78%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 1.8412 -> 1.8737  accuracy: 44.44% -> 44.44%     
client [15] (testset)   loss: 1.4981 -> 1.4710  accuracy: 61.04% -> 61.04%     
client [71] (testset)   loss: 2.0752 -> 2.0437  accuracy: 23.33% -> 23.33%     
client [97] (testset)   loss: 1.8614 -> 1.9634  accuracy: 25.76% -> 25.76%     
client [53] (testset)   loss: 2.0810 -> 2.0959  accuracy: 38.71% -> 38.71%     
client [77] (testset)   loss: 1.9813 -> 1.9786  accuracy: 30.00% -> 30.00%     
client [76] (testset)   loss: 1.9116 -> 1.8895  accuracy: 27.78% -> 27.78%     
client [79] (testset)   loss: 2.2952 -> 2.2930  accuracy: 21.15% -> 21.15%     
client [28] (testset)   loss: 2.1921 -> 2.1896  accuracy: 12.33% -> 12.33%     
client [99] (testset)   loss: 2.0669 -> 2.0812  accuracy: 12.82% -> 10.26%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 1.8563 -> 1.8958  accuracy: 31.82% -> 25.76%     
client [86] (testset)   loss: 1.6980 -> 1.7396  accuracy: 48.44% -> 48.44%     
client [34] (testset)   loss: 1.9169 -> 1.9004  accuracy: 24.59% -> 31.15%     
client [73] (testset)   loss: 2.3358 -> 2.3335  accuracy: 12.28% -> 12.28%     
client [5]  (testset)   loss: 2.2924 -> 2.2010  accuracy: 26.09% -> 26.09%     
client [96] (testset)   loss: 2.0797 -> 2.0978  accuracy: 30.36% -> 30.36%     
client [22] (testset)   loss: 1.8620 -> 1.8484  accuracy: 46.00% -> 46.00%     
client [60] (testset)   loss: 2.1834 -> 2.1721  accuracy: 28.57% -> 28.57%     
client [66] (testset)   loss: 2.1775 -> 2.1775  accuracy: 19.05% -> 19.05%     
client [83] (testset)   loss: 2.1153 -> 2.1356  accuracy: 19.57% -> 19.57%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 1.9123 -> 1.9028  accuracy: 27.78% -> 27.78%     
client [65] (testset)   loss: 1.9933 -> 2.0413  accuracy: 37.74% -> 37.74%     
client [95] (testset)   loss: 1.9998 -> 2.0035  accuracy: 34.25% -> 34.25%     
client [17] (testset)   loss: 1.9904 -> 2.0150  accuracy: 32.00% -> 32.00%     
client [8]  (testset)   loss: 1.8768 -> 1.8901  accuracy: 34.17% -> 34.17%     
client [35] (testset)   loss: 2.0027 -> 1.9878  accuracy: 33.33% -> 33.33%     
client [98] (testset)   loss: 2.0525 -> 2.0540  accuracy: 37.74% -> 37.74%     
client [53] (testset)   loss: 2.0844 -> 2.1021  accuracy: 38.71% -> 38.71%     
client [43] (testset)   loss: 1.5190 -> 1.4953  accuracy: 57.89% -> 57.89%     
client [64] (testset)   loss: 2.1846 -> 2.1889  accuracy: 20.00% -> 20.00%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 1.9783 -> 2.0150  accuracy: 26.32% -> 26.32%     
client [88] (testset)   loss: 2.1910 -> 2.1651  accuracy: 15.79% -> 22.81%     
client [38] (testset)   loss: 2.1887 -> 2.1944  accuracy: 18.92% -> 18.92%     
client [3]  (testset)   loss: 2.4744 -> 2.4914  accuracy: 9.26% -> 9.26%       
client [5]  (testset)   loss: 2.1915 -> 2.1801  accuracy: 26.09% -> 26.09%     
client [41] (testset)   loss: 2.0142 -> 2.0169  accuracy: 26.92% -> 26.92%     
client [7]  (testset)   loss: 1.9329 -> 1.9348  accuracy: 32.79% -> 32.79%     
client [37] (testset)   loss: 1.9589 -> 1.9468  accuracy: 40.48% -> 40.48%     
client [45] (testset)   loss: 2.0469 -> 2.0588  accuracy: 34.78% -> 34.78%     
client [47] (testset)   loss: 1.7998 -> 1.6883  accuracy: 16.67% -> 47.22%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 2.0371 -> 2.0402  accuracy: 26.67% -> 26.67%     
client [11] (testset)   loss: 1.9926 -> 2.0004  accuracy: 30.36% -> 30.36%     
client [37] (testset)   loss: 1.9383 -> 1.9595  accuracy: 40.48% -> 40.48%     
client [41] (testset)   loss: 2.0170 -> 2.0149  accuracy: 26.92% -> 26.92%     
client [95] (testset)   loss: 2.0064 -> 2.0119  accuracy: 34.25% -> 34.25%     
client [53] (testset)   loss: 2.0991 -> 2.0986  accuracy: 38.71% -> 38.71%     
client [22] (testset)   loss: 1.8445 -> 1.8638  accuracy: 46.00% -> 46.00%     
client [25] (testset)   loss: 2.4428 -> 2.4714  accuracy: 12.00% -> 12.00%     
client [69] (testset)   loss: 2.0202 -> 2.0254  accuracy: 29.41% -> 29.41%     
client [46] (testset)   loss: 1.8375 -> 1.8478  accuracy: 48.94% -> 48.94%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 1.7063 -> 1.7399  accuracy: 47.22% -> 16.67%     
client [69] (testset)   loss: 2.0189 -> 2.0188  accuracy: 29.41% -> 29.41%     
client [82] (testset)   loss: 1.9588 -> 1.8914  accuracy: 11.94% -> 40.30%     
client [45] (testset)   loss: 2.0507 -> 2.0564  accuracy: 34.78% -> 34.78%     
client [7]  (testset)   loss: 1.9343 -> 1.9381  accuracy: 32.79% -> 32.79%     
client [50] (testset)   loss: 2.1566 -> 2.0798  accuracy: 29.87% -> 29.87%     
client [35] (testset)   loss: 2.0060 -> 1.9988  accuracy: 33.33% -> 33.33%     
client [24] (testset)   loss: 2.1954 -> 2.2015  accuracy: 36.00% -> 36.00%     
client [15] (testset)   loss: 1.4981 -> 1.4920  accuracy: 61.04% -> 61.04%     
client [58] (testset)   loss: 1.6741 -> 1.6738  accuracy: 42.47% -> 42.47%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 2.2812 -> 2.2914  accuracy: 17.39% -> 17.39%     
client [76] (testset)   loss: 1.8865 -> 1.9056  accuracy: 27.78% -> 27.78%     
client [67] (testset)   loss: 2.0887 -> 2.0629  accuracy: 17.54% -> 17.54%     
client [37] (testset)   loss: 1.9412 -> 1.9397  accuracy: 40.48% -> 40.48%     
client [58] (testset)   loss: 1.6780 -> 1.6760  accuracy: 42.47% -> 42.47%     
client [64] (testset)   loss: 2.1835 -> 2.1837  accuracy: 20.00% -> 20.00%     
client [77] (testset)   loss: 1.9828 -> 1.9752  accuracy: 30.00% -> 30.00%     
client [55] (testset)   loss: 1.9026 -> 1.9004  accuracy: 42.62% -> 42.62%     
client [12] (testset)   loss: 1.8789 -> 1.8882  accuracy: 22.03% -> 23.73%     
client [89] (testset)   loss: 1.8734 -> 1.8685  accuracy: 46.88% -> 46.88%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 1.6363 -> 1.6329  accuracy: 38.53% -> 38.53%     
client [51] (testset)   loss: 1.8199 -> 1.8015  accuracy: 47.42% -> 47.42%     
client [8]  (testset)   loss: 1.8833 -> 1.8734  accuracy: 34.17% -> 34.17%     
client [18] (testset)   loss: 2.3265 -> 2.3518  accuracy: 6.98% -> 20.93%      
client [94] (testset)   loss: 1.7906 -> 1.7755  accuracy: 31.71% -> 31.71%     
client [81] (testset)   loss: 2.0075 -> 2.0088  accuracy: 35.14% -> 35.14%     
client [3]  (testset)   loss: 2.3985 -> 2.3895  accuracy: 9.26% -> 9.26%       
client [11] (testset)   loss: 1.9881 -> 1.9890  accuracy: 30.36% -> 30.36%     
client [95] (testset)   loss: 1.9996 -> 2.0151  accuracy: 34.25% -> 34.25%     
client [67] (testset)   loss: 2.0642 -> 2.0741  accuracy: 17.54% -> 19.30%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 1.9617 -> 1.9557  accuracy: 26.32% -> 26.32%     
client [79] (testset)   loss: 2.2736 -> 2.2868  accuracy: 21.15% -> 21.15%     
client [58] (testset)   loss: 1.6774 -> 1.6760  accuracy: 42.47% -> 42.47%     
client [88] (testset)   loss: 2.1742 -> 2.1897  accuracy: 22.81% -> 22.81%     
client [46] (testset)   loss: 1.8387 -> 1.8419  accuracy: 48.94% -> 48.94%     
client [11] (testset)   loss: 1.9885 -> 1.9952  accuracy: 30.36% -> 30.36%     
client [55] (testset)   loss: 1.9028 -> 1.9067  accuracy: 42.62% -> 42.62%     
client [13] (testset)   loss: 2.4481 -> 2.4950  accuracy: 22.22% -> 22.22%     
client [31] (testset)   loss: 1.8611 -> 1.8675  accuracy: 44.44% -> 44.44%     
client [75] (testset)   loss: 2.1738 -> 2.1647  accuracy: 24.07% -> 22.22%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 2.1848 -> 2.1910  accuracy: 23.21% -> 23.21%     
client [7]  (testset)   loss: 1.9299 -> 1.9299  accuracy: 32.79% -> 32.79%     
client [57] (testset)   loss: 2.0832 -> 2.1051  accuracy: 34.78% -> 34.78%     
client [13] (testset)   loss: 2.4737 -> 2.4678  accuracy: 22.22% -> 22.22%     
client [43] (testset)   loss: 1.4870 -> 1.4924  accuracy: 57.89% -> 57.89%     
client [91] (testset)   loss: 1.9945 -> 2.0569  accuracy: 37.93% -> 13.79%     
client [10] (testset)   loss: 2.0938 -> 2.0975  accuracy: 38.89% -> 38.89%     
client [64] (testset)   loss: 2.1853 -> 2.1900  accuracy: 20.00% -> 20.00%     
client [82] (testset)   loss: 1.8891 -> 1.9043  accuracy: 40.30% -> 11.94%     
client [22] (testset)   loss: 1.8608 -> 1.8572  accuracy: 46.00% -> 46.00%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 2.1961 -> 2.1891  accuracy: 18.03% -> 18.03%     
client [23] (testset)   loss: 2.1719 -> 2.1557  accuracy: 20.59% -> 23.53%     
client [88] (testset)   loss: 2.1898 -> 2.1542  accuracy: 22.81% -> 15.79%     
client [98] (testset)   loss: 2.0555 -> 2.0551  accuracy: 37.74% -> 37.74%     
client [79] (testset)   loss: 2.2851 -> 2.2791  accuracy: 21.15% -> 21.15%     
client [21] (testset)   loss: 1.9767 -> 1.9524  accuracy: 26.32% -> 26.32%     
client [92] (testset)   loss: 2.1124 -> 2.1009  accuracy: 26.47% -> 26.47%     
client [56] (testset)   loss: 2.1072 -> 2.1520  accuracy: 7.27% -> 7.27%       
client [5]  (testset)   loss: 2.2323 -> 2.2504  accuracy: 26.09% -> 26.09%     
client [52] (testset)   loss: 1.2712 -> 1.2659  accuracy: 57.14% -> 57.14%     
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 2.0640 -> 2.0770  accuracy: 19.30% -> 19.30%     
client [54] (testset)   loss: 2.4932 -> 2.7570  accuracy: 18.75% -> 18.75%     
client [14] (testset)   loss: 2.0483 -> 2.0533  accuracy: 31.88% -> 31.88%     
client [99] (testset)   loss: 2.0842 -> 2.0662  accuracy: 10.26% -> 10.26%     
client [36] (testset)   loss: 2.0430 -> 2.0531  accuracy: 24.49% -> 24.49%     
client [30] (testset)   loss: 2.3522 -> 2.3600  accuracy: 15.15% -> 15.15%     
client [38] (testset)   loss: 2.1836 -> 2.1946  accuracy: 18.92% -> 18.92%     
client [15] (testset)   loss: 1.5020 -> 1.5165  accuracy: 61.04% -> 61.04%     
client [6]  (testset)   loss: 2.0245 -> 2.0375  accuracy: 21.54% -> 21.54%     
client [53] (testset)   loss: 2.0830 -> 2.0833  accuracy: 38.71% -> 38.71%     
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [99] (testset)   loss: 2.0617 -> 2.0806  accuracy: 20.51% -> 10.26%     
client [6]  (testset)   loss: 2.0334 -> 2.0253  accuracy: 21.54% -> 21.54%     
client [83] (testset)   loss: 2.1337 -> 2.1327  accuracy: 19.57% -> 19.57%     
client [42] (testset)   loss: 2.2854 -> 2.3033  accuracy: 17.86% -> 7.14%      
client [34] (testset)   loss: 1.9118 -> 1.9050  accuracy: 24.59% -> 24.59%     
client [15] (testset)   loss: 1.5162 -> 1.5103  accuracy: 61.04% -> 61.04%     
client [47] (testset)   loss: 1.7089 -> 1.7098  accuracy: 47.22% -> 47.22%     
client [55] (testset)   loss: 1.9009 -> 1.9028  accuracy: 42.62% -> 42.62%     
client [51] (testset)   loss: 1.8045 -> 1.8037  accuracy: 47.42% -> 47.42%     
client [95] (testset)   loss: 2.0049 -> 2.0020  accuracy: 34.25% -> 34.25%     
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 2.0204 -> 2.0062  accuracy: 23.33% -> 23.33%     
client [15] (testset)   loss: 1.5123 -> 1.4807  accuracy: 61.04% -> 61.04%     
client [33] (testset)   loss: 1.7671 -> 1.8126  accuracy: 44.44% -> 22.22%     
client [99] (testset)   loss: 2.0683 -> 2.0811  accuracy: 20.51% -> 10.26%     
client [90] (testset)   loss: 1.9783 -> 1.9738  accuracy: 25.00% -> 25.00%     
client [57] (testset)   loss: 2.0858 -> 2.0833  accuracy: 34.78% -> 34.78%     
client [27] (testset)   loss: 1.9767 -> 1.9937  accuracy: 38.75% -> 38.75%     
client [78] (testset)   loss: 1.9128 -> 1.9248  accuracy: 22.73% -> 22.73%     
client [36] (testset)   loss: 2.0574 -> 2.0552  accuracy: 24.49% -> 24.49%     
client [88] (testset)   loss: 2.1935 -> 2.1943  accuracy: 22.81% -> 15.79%     
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 2.2308 -> 2.2233  accuracy: 25.00% -> 25.00%     
client [35] (testset)   loss: 2.0320 -> 2.0189  accuracy: 33.33% -> 33.33%     
client [16] (testset)   loss: 2.0264 -> 2.0245  accuracy: 26.67% -> 26.67%     
client [80] (testset)   loss: 2.1646 -> 2.1798  accuracy: 38.18% -> 38.18%     
client [38] (testset)   loss: 2.1852 -> 2.1949  accuracy: 18.92% -> 18.92%     
client [78] (testset)   loss: 1.9094 -> 1.9204  accuracy: 22.73% -> 22.73%     
client [68] (testset)   loss: 1.7421 -> 1.7582  accuracy: 37.78% -> 37.78%     
client [11] (testset)   loss: 2.0085 -> 2.0072  accuracy: 30.36% -> 30.36%     
client [64] (testset)   loss: 2.1879 -> 2.1903  accuracy: 20.00% -> 20.00%     
client [82] (testset)   loss: 1.9076 -> 1.8880  accuracy: 40.30% -> 40.30%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 2.3434 -> 2.3478  accuracy: 15.15% -> 15.15%     
client [27] (testset)   loss: 1.9864 -> 1.9861  accuracy: 38.75% -> 38.75%     
client [74] (testset)   loss: 1.9946 -> 2.0090  accuracy: 28.07% -> 19.30%     
client [45] (testset)   loss: 2.0424 -> 2.0464  accuracy: 34.78% -> 34.78%     
client [6]  (testset)   loss: 2.0500 -> 2.0519  accuracy: 21.54% -> 21.54%     
client [36] (testset)   loss: 2.0661 -> 2.0585  accuracy: 24.49% -> 24.49%     
client [63] (testset)   loss: 1.9793 -> 1.9853  accuracy: 31.67% -> 31.67%     
client [76] (testset)   loss: 1.9071 -> 1.8789  accuracy: 27.78% -> 27.78%     
client [83] (testset)   loss: 2.1422 -> 2.1314  accuracy: 19.57% -> 19.57%     
client [86] (testset)   loss: 1.6944 -> 1.6967  accuracy: 48.44% -> 48.44%     
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 2.1298 -> 2.1304  accuracy: 19.57% -> 19.57%     
client [99] (testset)   loss: 2.0717 -> 2.0722  accuracy: 20.51% -> 10.26%     
client [74] (testset)   loss: 1.9947 -> 1.9978  accuracy: 28.07% -> 19.30%     
client [73] (testset)   loss: 2.3407 -> 2.3351  accuracy: 21.05% -> 21.05%     
client [29] (testset)   loss: 1.8136 -> 1.7619  accuracy: 37.66% -> 37.66%     
client [92] (testset)   loss: 2.1037 -> 2.1099  accuracy: 26.47% -> 26.47%     
client [6]  (testset)   loss: 2.0184 -> 2.0186  accuracy: 21.54% -> 21.54%     
client [61] (testset)   loss: 2.2064 -> 2.2629  accuracy: 26.67% -> 26.67%     
client [21] (testset)   loss: 1.9587 -> 1.9602  accuracy: 26.32% -> 26.32%     
client [67] (testset)   loss: 2.0798 -> 2.0819  accuracy: 19.30% -> 17.54%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 2.1305 -> 2.1212  accuracy: 19.57% -> 19.57%     
client [32] (testset)   loss: 2.0133 -> 1.9934  accuracy: 30.43% -> 30.43%     
client [95] (testset)   loss: 1.9947 -> 2.0058  accuracy: 34.25% -> 34.25%     
client [61] (testset)   loss: 2.2162 -> 2.2105  accuracy: 26.67% -> 26.67%     
client [27] (testset)   loss: 1.9858 -> 2.0125  accuracy: 38.75% -> 38.75%     
client [25] (testset)   loss: 2.4631 -> 2.4608  accuracy: 12.00% -> 12.00%     
client [68] (testset)   loss: 1.7677 -> 1.7520  accuracy: 37.78% -> 37.78%     
client [34] (testset)   loss: 1.9151 -> 1.9096  accuracy: 24.59% -> 24.59%     
client [71] (testset)   loss: 2.0155 -> 2.0307  accuracy: 23.33% -> 23.33%     
client [89] (testset)   loss: 1.8733 -> 1.9500  accuracy: 46.88% -> 46.88%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 1.9121 -> 1.9194  accuracy: 22.73% -> 22.73%     
client [81] (testset)   loss: 2.0119 -> 2.0149  accuracy: 35.14% -> 35.14%     
client [51] (testset)   loss: 1.7776 -> 1.7957  accuracy: 47.42% -> 47.42%     
client [54] (testset)   loss: 2.4370 -> 2.3483  accuracy: 18.75% -> 18.75%     
client [65] (testset)   loss: 2.0141 -> 2.0008  accuracy: 37.74% -> 37.74%     
client [41] (testset)   loss: 2.0152 -> 2.0166  accuracy: 26.92% -> 26.92%     
client [11] (testset)   loss: 1.9920 -> 1.9969  accuracy: 30.36% -> 30.36%     
client [85] (testset)   loss: 2.0471 -> 2.0495  accuracy: 29.33% -> 29.33%     
client [12] (testset)   loss: 1.8766 -> 1.9026  accuracy: 23.73% -> 23.73%     
client [23] (testset)   loss: 2.1970 -> 2.1941  accuracy: 20.59% -> 20.59%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 2.0311 -> 2.0329  accuracy: 26.67% -> 26.67%     
client [65] (testset)   loss: 2.0074 -> 2.0003  accuracy: 37.74% -> 37.74%     
client [53] (testset)   loss: 2.0899 -> 2.0944  accuracy: 38.71% -> 38.71%     
client [58] (testset)   loss: 1.6766 -> 1.6820  accuracy: 42.47% -> 42.47%     
client [72] (testset)   loss: 1.8092 -> 1.7802  accuracy: 53.70% -> 53.70%     
client [7]  (testset)   loss: 1.9318 -> 1.9328  accuracy: 32.79% -> 32.79%     
client [71] (testset)   loss: 2.0274 -> 2.0258  accuracy: 23.33% -> 23.33%     
client [59] (testset)   loss: 2.0983 -> 2.1050  accuracy: 24.14% -> 24.14%     
client [86] (testset)   loss: 1.6939 -> 1.6940  accuracy: 48.44% -> 48.44%     
client [39] (testset)   loss: 1.4109 -> 1.4102  accuracy: 53.77% -> 53.77%     
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 2.0725 -> 2.0752  accuracy: 10.26% -> 10.26%     
client [7]  (testset)   loss: 1.9277 -> 1.9312  accuracy: 32.79% -> 32.79%     
client [17] (testset)   loss: 2.0182 -> 2.0045  accuracy: 32.00% -> 32.00%     
client [64] (testset)   loss: 2.1890 -> 2.1877  accuracy: 20.00% -> 20.00%     
client [37] (testset)   loss: 1.9463 -> 1.9529  accuracy: 40.48% -> 40.48%     
client [29] (testset)   loss: 1.7713 -> 1.7778  accuracy: 37.66% -> 37.66%     
client [93] (testset)   loss: 1.7042 -> 1.7044  accuracy: 45.65% -> 45.65%     
client [73] (testset)   loss: 2.3396 -> 2.3349  accuracy: 12.28% -> 12.28%     
client [40] (testset)   loss: 2.1611 -> 2.1486  accuracy: 21.74% -> 21.74%     
client [76] (testset)   loss: 1.8831 -> 1.8803  accuracy: 27.78% -> 27.78%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 1.8680 -> 1.8641  accuracy: 44.44% -> 44.44%     
client [89] (testset)   loss: 1.8562 -> 1.8483  accuracy: 46.88% -> 46.88%     
client [77] (testset)   loss: 1.9819 -> 1.9778  accuracy: 30.00% -> 30.00%     
client [90] (testset)   loss: 1.9839 -> 1.9775  accuracy: 25.00% -> 25.00%     
client [26] (testset)   loss: 2.1773 -> 2.1805  accuracy: 22.81% -> 22.81%     
client [50] (testset)   loss: 2.1200 -> 2.0927  accuracy: 29.87% -> 29.87%     
client [30] (testset)   loss: 2.3523 -> 2.3520  accuracy: 15.15% -> 15.15%     
client [70] (testset)   loss: 2.2287 -> 2.2202  accuracy: 25.00% -> 25.00%     
client [41] (testset)   loss: 2.0187 -> 2.0203  accuracy: 26.92% -> 26.92%     
client [99] (testset)   loss: 2.0753 -> 2.0603  accuracy: 10.26% -> 20.51%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [68] (testset)   loss: 1.7638 -> 1.7590  accuracy: 37.78% -> 37.78%     
client [70] (testset)   loss: 2.2961 -> 2.2678  accuracy: 25.00% -> 25.00%     
client [52] (testset)   loss: 1.2810 -> 1.3407  accuracy: 57.14% -> 57.14%     
client [1]  (testset)   loss: 2.4190 -> 2.3963  accuracy: 4.17% -> 12.50%      
client [2]  (testset)   loss: 1.7886 -> 1.7760  accuracy: 49.40% -> 49.40%     
client [67] (testset)   loss: 2.0937 -> 2.0873  accuracy: 19.30% -> 19.30%     
client [92] (testset)   loss: 2.1033 -> 2.1068  accuracy: 26.47% -> 26.47%     
client [35] (testset)   loss: 2.0084 -> 2.0123  accuracy: 33.33% -> 33.33%     
client [36] (testset)   loss: 2.0554 -> 2.0566  accuracy: 24.49% -> 24.49%     
client [64] (testset)   loss: 2.1879 -> 2.1867  accuracy: 20.00% -> 20.00%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 2.1313 -> 2.1194  accuracy: 23.21% -> 23.21%     
client [6]  (testset)   loss: 2.0294 -> 2.0039  accuracy: 21.54% -> 21.54%     
client [12] (testset)   loss: 1.8827 -> 1.8822  accuracy: 22.03% -> 22.03%     
client [55] (testset)   loss: 1.9024 -> 1.9037  accuracy: 42.62% -> 42.62%     
client [29] (testset)   loss: 1.7689 -> 1.8010  accuracy: 37.66% -> 37.66%     
client [9]  (testset)   loss: 2.3469 -> 2.3683  accuracy: 13.33% -> 13.33%     
client [43] (testset)   loss: 1.4925 -> 1.4964  accuracy: 57.89% -> 57.89%     
client [77] (testset)   loss: 1.9793 -> 1.9799  accuracy: 30.00% -> 30.00%     
client [98] (testset)   loss: 2.0552 -> 2.0556  accuracy: 37.74% -> 37.74%     
client [78] (testset)   loss: 1.9267 -> 1.9261  accuracy: 22.73% -> 22.73%     
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 2.1110 -> 2.1044  accuracy: 26.47% -> 26.47%     
client [80] (testset)   loss: 2.1518 -> 2.1587  accuracy: 38.18% -> 38.18%     
client [63] (testset)   loss: 1.9902 -> 1.9760  accuracy: 31.67% -> 31.67%     
client [76] (testset)   loss: 1.8852 -> 1.8916  accuracy: 27.78% -> 27.78%     
client [78] (testset)   loss: 1.9277 -> 1.9148  accuracy: 22.73% -> 22.73%     
client [25] (testset)   loss: 2.4534 -> 2.4621  accuracy: 12.00% -> 12.00%     
client [58] (testset)   loss: 1.6747 -> 1.6763  accuracy: 42.47% -> 42.47%     
client [13] (testset)   loss: 2.5054 -> 2.5194  accuracy: 22.22% -> 22.22%     
client [17] (testset)   loss: 2.0149 -> 2.0382  accuracy: 32.00% -> 32.00%     
client [38] (testset)   loss: 2.1849 -> 2.1887  accuracy: 18.92% -> 18.92%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 1.7789 -> 1.7935  accuracy: 53.70% -> 53.70%     
client [82] (testset)   loss: 1.9622 -> 1.9274  accuracy: 11.94% -> 11.94%     
client [86] (testset)   loss: 1.6943 -> 1.6921  accuracy: 48.44% -> 48.44%     
client [51] (testset)   loss: 1.7946 -> 1.7903  accuracy: 47.42% -> 47.42%     
client [96] (testset)   loss: 2.0900 -> 2.0814  accuracy: 30.36% -> 30.36%     
client [42] (testset)   loss: 2.2767 -> 2.2801  accuracy: 7.14% -> 7.14%       
client [55] (testset)   loss: 1.9051 -> 1.9040  accuracy: 42.62% -> 42.62%     
client [13] (testset)   loss: 2.5314 -> 2.4995  accuracy: 22.22% -> 22.22%     
client [1]  (testset)   loss: 2.4044 -> 2.4249  accuracy: 12.50% -> 4.17%      
client [12] (testset)   loss: 1.8828 -> 1.8980  accuracy: 22.03% -> 23.73%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 1.7763 -> 1.7880  accuracy: 37.78% -> 37.78%     
client [23] (testset)   loss: 2.1723 -> 2.1632  accuracy: 20.59% -> 20.59%     
client [46] (testset)   loss: 1.8759 -> 1.8584  accuracy: 48.94% -> 48.94%     
client [41] (testset)   loss: 2.0218 -> 2.0186  accuracy: 26.92% -> 26.92%     
client [25] (testset)   loss: 2.4769 -> 2.4657  accuracy: 12.00% -> 12.00%     
client [58] (testset)   loss: 1.6814 -> 1.6861  accuracy: 42.47% -> 42.47%     
client [14] (testset)   loss: 2.0555 -> 2.0506  accuracy: 31.88% -> 31.88%     
client [33] (testset)   loss: 1.8270 -> 1.7605  accuracy: 22.22% -> 44.44%     
client [85] (testset)   loss: 2.0700 -> 2.0394  accuracy: 29.33% -> 29.33%     
client [62] (testset)   loss: 1.9058 -> 1.9071  accuracy: 41.38% -> 41.38%     
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 2.0553 -> 2.0562  accuracy: 37.74% -> 37.74%     
client [63] (testset)   loss: 1.9736 -> 1.9850  accuracy: 31.67% -> 31.67%     
client [70] (testset)   loss: 2.2061 -> 2.2324  accuracy: 25.00% -> 25.00%     
client [65] (testset)   loss: 2.0046 -> 2.0157  accuracy: 37.74% -> 37.74%     
client [14] (testset)   loss: 2.0474 -> 2.0539  accuracy: 31.88% -> 31.88%     
client [73] (testset)   loss: 2.3363 -> 2.3361  accuracy: 21.05% -> 21.05%     
client [34] (testset)   loss: 1.9095 -> 1.9042  accuracy: 24.59% -> 24.59%     
client [99] (testset)   loss: 2.0755 -> 2.0679  accuracy: 10.26% -> 20.51%     
client [69] (testset)   loss: 2.0192 -> 2.0193  accuracy: 29.41% -> 29.41%     
client [46] (testset)   loss: 1.8562 -> 1.8536  accuracy: 48.94% -> 48.94%     
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [99] (testset)   loss: 2.0746 -> 2.0727  accuracy: 10.26% -> 10.26%     
client [93] (testset)   loss: 1.7121 -> 1.7129  accuracy: 45.65% -> 45.65%     
client [11] (testset)   loss: 1.9978 -> 2.0072  accuracy: 30.36% -> 30.36%     
client [58] (testset)   loss: 1.6760 -> 1.6764  accuracy: 42.47% -> 42.47%     
client [81] (testset)   loss: 2.0180 -> 2.0136  accuracy: 35.14% -> 35.14%     
client [85] (testset)   loss: 2.0422 -> 2.0899  accuracy: 29.33% -> 29.33%     
client [89] (testset)   loss: 1.8438 -> 1.8860  accuracy: 46.88% -> 46.88%     
client [45] (testset)   loss: 2.0407 -> 2.0516  accuracy: 34.78% -> 34.78%     
client [8]  (testset)   loss: 1.8749 -> 1.8811  accuracy: 34.17% -> 34.17%     
client [68] (testset)   loss: 1.7222 -> 1.7389  accuracy: 37.78% -> 37.78%     
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 2.0677 -> 2.0806  accuracy: 19.30% -> 19.30%     
client [72] (testset)   loss: 1.7733 -> 1.7985  accuracy: 53.70% -> 53.70%     
client [1]  (testset)   loss: 2.4399 -> 2.4283  accuracy: 4.17% -> 4.17%       
client [78] (testset)   loss: 1.9277 -> 1.9152  accuracy: 22.73% -> 22.73%     
client [83] (testset)   loss: 2.1480 -> 2.1276  accuracy: 19.57% -> 19.57%     
client [21] (testset)   loss: 1.9460 -> 1.9611  accuracy: 26.32% -> 26.32%     
client [56] (testset)   loss: 2.1349 -> 2.1022  accuracy: 7.27% -> 7.27%       
client [44] (testset)   loss: 2.1454 -> 2.1408  accuracy: 23.21% -> 23.21%     
client [92] (testset)   loss: 2.1083 -> 2.0999  accuracy: 26.47% -> 26.47%     
client [27] (testset)   loss: 2.0008 -> 2.0268  accuracy: 38.75% -> 38.75%     
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 2.0952 -> 2.0917  accuracy: 38.89% -> 38.89%     
client [39] (testset)   loss: 1.4392 -> 1.4391  accuracy: 53.77% -> 53.77%     
client [65] (testset)   loss: 2.0240 -> 2.0098  accuracy: 37.74% -> 37.74%     
client [26] (testset)   loss: 2.1831 -> 2.1735  accuracy: 19.30% -> 22.81%     
client [19] (testset)   loss: 2.2205 -> 2.2228  accuracy: 23.21% -> 23.21%     
client [68] (testset)   loss: 1.7448 -> 1.7963  accuracy: 37.78% -> 37.78%     
client [41] (testset)   loss: 2.0183 -> 2.0179  accuracy: 26.92% -> 26.92%     
client [50] (testset)   loss: 2.1321 -> 2.0988  accuracy: 29.87% -> 29.87%     
client [75] (testset)   loss: 2.1610 -> 2.1368  accuracy: 24.07% -> 22.22%     
client [81] (testset)   loss: 2.0105 -> 2.0079  accuracy: 35.14% -> 35.14%     
Training... ---------------------------------------- 100% 0:06:51
LG-FedAvg's average time taken by each global epoch: 0 min 1.02 sec.           
LG-FedAvg's total running time: 0 h 6 m 51 s.                                  
==================== LG-FedAvg Experiment Results: ====================        
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9854 -> 0.0000",                                    
                "accuracy": "30.76% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9850 -> 0.0000",                                    
                "accuracy": "30.92% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9849 -> 0.0000",                                    
                "accuracy": "31.61% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9855 -> 0.0000",                                    
                "accuracy": "31.21% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== LG-FedAvg Max Accuracy ====================               
all_clients:                                                                   
(test) before fine-tuning: 31.61% at epoch 300                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
[0m