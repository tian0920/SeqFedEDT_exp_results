==================== APFL ====================                                 
Experiment Arguments:                                                          
{
    'method': 'apfl',
    'dataset': {
        'name': 'medmnistA',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'medmnistA-100clients-0%IID-Dir(1.0)-seed42',
        'alpha': 1.0,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'lenet5',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'serial',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': None,
        'num_gpus': None,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 400,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 0,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': False,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': False,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'apfl': {
        'alpha': 0.5,
        'adaptive_alpha': 1
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 2.2438 -> 2.0612  accuracy: 19.61% -> 24.84%     
client [81] (testset)   loss: 2.4527 -> 2.1969  accuracy: 4.17% -> 25.00%      
client [21] (testset)   loss: 2.3225 -> 2.0500  accuracy: 27.10% -> 27.10%     
client [68] (testset)   loss: 2.3141 -> 2.0869  accuracy: 16.80% -> 16.80%     
client [93] (testset)   loss: 1.4902 -> 1.1901  accuracy: 69.57% -> 69.57%     
client [31] (testset)   loss: 2.4295 -> 2.2328  accuracy: 4.12% -> 18.56%      
client [20] (testset)   loss: 2.0555 -> 1.9856  accuracy: 19.18% -> 32.42%     
client [59] (testset)   loss: 2.4118 -> 2.1218  accuracy: 7.48% -> 24.49%      
client [48] (testset)   loss: 2.1625 -> 2.1522  accuracy: 19.40% -> 21.98%     
client [34] (testset)   loss: 2.0524 -> 2.0262  accuracy: 32.74% -> 32.74%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 2.1074 -> 1.9219  accuracy: 25.64% -> 25.64%     
client [99] (testset)   loss: 2.2179 -> 2.0012  accuracy: 12.30% -> 32.79%     
client [67] (testset)   loss: 2.3501 -> 2.0708  accuracy: 7.34% -> 19.27%      
client [0]  (testset)   loss: 2.2396 -> 2.1026  accuracy: 18.85% -> 17.28%     
client [76] (testset)   loss: 2.2616 -> 2.1612  accuracy: 20.39% -> 20.39%     
client [41] (testset)   loss: 2.6478 -> 1.9191  accuracy: 4.42% -> 44.25%      
client [62] (testset)   loss: 2.3323 -> 2.0411  accuracy: 7.06% -> 33.83%      
client [2]  (testset)   loss: 2.3789 -> 2.0564  accuracy: 11.98% -> 11.98%     
client [14] (testset)   loss: 1.9714 -> 1.9663  accuracy: 35.56% -> 35.56%     
client [46] (testset)   loss: 2.0498 -> 1.9738  accuracy: 30.39% -> 30.39%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 1.8243 -> 1.7367  accuracy: 39.88% -> 39.88%     
client [68] (testset)   loss: 2.1257 -> 2.0671  accuracy: 16.80% -> 23.20%     
client [57] (testset)   loss: 2.3798 -> 2.2521  accuracy: 19.75% -> 19.75%     
client [17] (testset)   loss: 2.3210 -> 2.1510  accuracy: 20.00% -> 20.00%     
client [54] (testset)   loss: 2.1043 -> 2.0359  accuracy: 20.00% -> 20.00%     
client [23] (testset)   loss: 2.2941 -> 2.1092  accuracy: 24.23% -> 24.23%     
client [35] (testset)   loss: 2.1162 -> 2.0382  accuracy: 23.33% -> 23.33%     
client [59] (testset)   loss: 2.2601 -> 2.0600  accuracy: 24.49% -> 24.49%     
client [31] (testset)   loss: 2.1817 -> 2.1810  accuracy: 18.56% -> 18.56%     
client [9]  (testset)   loss: 2.2160 -> 2.0846  accuracy: 7.41% -> 31.11%      
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 2.1670 -> 2.1485  accuracy: 22.22% -> 15.87%     
client [33] (testset)   loss: 2.1417 -> 2.1234  accuracy: 28.82% -> 28.82%     
client [16] (testset)   loss: 1.5853 -> 1.4002  accuracy: 59.84% -> 59.84%     
client [44] (testset)   loss: 2.2619 -> 2.0682  accuracy: 28.38% -> 28.38%     
client [8]  (testset)   loss: 1.9528 -> 1.8663  accuracy: 46.10% -> 46.10%     
client [31] (testset)   loss: 2.1982 -> 2.1830  accuracy: 11.34% -> 18.56%     
client [47] (testset)   loss: 1.8917 -> 1.7660  accuracy: 27.97% -> 27.97%     
client [36] (testset)   loss: 2.1629 -> 1.8329  accuracy: 36.54% -> 36.54%     
client [20] (testset)   loss: 2.0496 -> 2.0023  accuracy: 19.18% -> 32.42%     
client [56] (testset)   loss: 2.0172 -> 1.9270  accuracy: 32.58% -> 32.58%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 1.9890 -> 1.9433  accuracy: 32.92% -> 32.92%     
client [60] (testset)   loss: 1.9909 -> 1.9191  accuracy: 28.35% -> 28.35%     
client [28] (testset)   loss: 2.2173 -> 2.1575  accuracy: 18.58% -> 18.58%     
client [25] (testset)   loss: 1.8641 -> 1.8273  accuracy: 40.30% -> 40.30%     
client [58] (testset)   loss: 1.8066 -> 1.7202  accuracy: 32.22% -> 31.11%     
client [44] (testset)   loss: 2.1433 -> 2.0607  accuracy: 28.38% -> 28.38%     
client [39] (testset)   loss: 2.1229 -> 1.9817  accuracy: 19.53% -> 20.12%     
client [29] (testset)   loss: 2.3604 -> 2.2907  accuracy: 24.04% -> 24.04%     
client [3]  (testset)   loss: 1.6627 -> 1.4246  accuracy: 62.66% -> 62.66%     
client [84] (testset)   loss: 2.1817 -> 2.2058  accuracy: 21.93% -> 21.93%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 2.1511 -> 2.0059  accuracy: 27.10% -> 27.10%     
client [84] (testset)   loss: 2.1834 -> 2.1925  accuracy: 21.93% -> 21.93%     
client [10] (testset)   loss: 1.9392 -> 1.8426  accuracy: 36.94% -> 36.94%     
client [36] (testset)   loss: 1.9764 -> 1.8416  accuracy: 36.54% -> 36.54%     
client [65] (testset)   loss: 2.0385 -> 1.9895  accuracy: 28.26% -> 28.26%     
client [81] (testset)   loss: 2.2558 -> 2.2520  accuracy: 9.38% -> 20.83%      
client [79] (testset)   loss: 2.1660 -> 2.0273  accuracy: 21.78% -> 21.78%     
client [42] (testset)   loss: 2.1139 -> 2.0712  accuracy: 20.95% -> 21.62%     
client [11] (testset)   loss: 2.1997 -> 2.0150  accuracy: 36.28% -> 36.28%     
client [96] (testset)   loss: 2.1523 -> 2.0287  accuracy: 12.93% -> 22.41%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 1.9426 -> 1.8822  accuracy: 46.10% -> 46.10%     
client [53] (testset)   loss: 1.9381 -> 1.8514  accuracy: 28.70% -> 32.41%     
client [52] (testset)   loss: 1.9684 -> 1.8866  accuracy: 28.38% -> 28.38%     
client [42] (testset)   loss: 2.0994 -> 2.0657  accuracy: 20.95% -> 20.95%     
client [69] (testset)   loss: 1.9639 -> 1.9181  accuracy: 25.64% -> 25.64%     
client [59] (testset)   loss: 2.1631 -> 2.0528  accuracy: 24.49% -> 24.49%     
client [7]  (testset)   loss: 1.9373 -> 1.8370  accuracy: 41.94% -> 41.94%     
client [26] (testset)   loss: 1.6348 -> 1.4721  accuracy: 54.98% -> 54.98%     
client [49] (testset)   loss: 1.8278 -> 1.7063  accuracy: 48.28% -> 48.28%     
client [98] (testset)   loss: 2.1549 -> 2.1574  accuracy: 28.74% -> 28.74%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 2.1776 -> 2.1979  accuracy: 18.39% -> 28.74%     
client [47] (testset)   loss: 1.8972 -> 1.7546  accuracy: 18.18% -> 27.97%     
client [21] (testset)   loss: 2.1148 -> 1.9933  accuracy: 27.10% -> 27.10%     
client [77] (testset)   loss: 2.1353 -> 2.0692  accuracy: 19.61% -> 19.61%     
client [95] (testset)   loss: 2.2614 -> 2.1737  accuracy: 12.84% -> 20.18%     
client [91] (testset)   loss: 2.3451 -> 2.2645  accuracy: 13.10% -> 13.10%     
client [14] (testset)   loss: 1.9781 -> 1.9669  accuracy: 35.56% -> 35.56%     
client [99] (testset)   loss: 1.9975 -> 1.9860  accuracy: 32.79% -> 32.79%     
client [20] (testset)   loss: 2.0572 -> 1.9956  accuracy: 19.18% -> 32.42%     
client [39] (testset)   loss: 2.1135 -> 1.9942  accuracy: 10.65% -> 19.53%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 1.9487 -> 1.8994  accuracy: 28.38% -> 28.38%     
client [62] (testset)   loss: 2.0558 -> 2.0744  accuracy: 33.83% -> 33.83%     
client [71] (testset)   loss: 1.8599 -> 1.7310  accuracy: 40.35% -> 40.35%     
client [97] (testset)   loss: 2.0174 -> 1.9669  accuracy: 21.26% -> 21.26%     
client [30] (testset)   loss: 1.9123 -> 1.7975  accuracy: 30.52% -> 32.47%     
client [88] (testset)   loss: 1.9717 -> 1.8878  accuracy: 41.42% -> 41.42%     
client [60] (testset)   loss: 1.9910 -> 1.9357  accuracy: 28.35% -> 25.77%     
client [82] (testset)   loss: 1.9164 -> 1.8452  accuracy: 38.26% -> 38.26%     
client [91] (testset)   loss: 2.2850 -> 2.2655  accuracy: 13.10% -> 10.71%     
client [57] (testset)   loss: 2.2882 -> 2.2202  accuracy: 11.11% -> 19.75%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 2.1921 -> 2.1823  accuracy: 18.56% -> 18.56%     
client [15] (testset)   loss: 1.9740 -> 1.9546  accuracy: 35.54% -> 35.54%     
client [71] (testset)   loss: 1.8521 -> 1.7260  accuracy: 40.35% -> 40.35%     
client [97] (testset)   loss: 1.9780 -> 1.9308  accuracy: 23.19% -> 21.26%     
client [53] (testset)   loss: 1.9497 -> 1.9377  accuracy: 32.41% -> 32.41%     
client [77] (testset)   loss: 2.1403 -> 2.0720  accuracy: 19.61% -> 24.84%     
client [76] (testset)   loss: 2.1693 -> 2.1301  accuracy: 20.39% -> 20.39%     
client [79] (testset)   loss: 2.0926 -> 2.0279  accuracy: 21.78% -> 21.78%     
client [28] (testset)   loss: 2.1642 -> 2.1159  accuracy: 18.58% -> 23.01%     
client [99] (testset)   loss: 1.9896 -> 1.9913  accuracy: 32.79% -> 32.79%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 1.9999 -> 1.9257  accuracy: 18.36% -> 23.19%     
client [86] (testset)   loss: 2.0507 -> 2.0043  accuracy: 22.62% -> 22.62%     
client [34] (testset)   loss: 2.0305 -> 1.9914  accuracy: 32.74% -> 32.74%     
client [73] (testset)   loss: 1.9029 -> 1.8630  accuracy: 27.18% -> 27.18%     
client [5]  (testset)   loss: 1.7734 -> 1.7419  accuracy: 51.79% -> 51.79%     
client [96] (testset)   loss: 2.0999 -> 2.0166  accuracy: 13.79% -> 22.41%     
client [22] (testset)   loss: 2.1284 -> 2.0907  accuracy: 30.86% -> 30.86%     
client [60] (testset)   loss: 1.9760 -> 1.9423  accuracy: 28.35% -> 25.77%     
client [66] (testset)   loss: 2.0887 -> 2.0434  accuracy: 20.16% -> 30.23%     
client [83] (testset)   loss: 1.8507 -> 1.7660  accuracy: 23.27% -> 30.82%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 2.1935 -> 2.1271  accuracy: 20.39% -> 20.39%     
client [65] (testset)   loss: 2.1107 -> 1.9985  accuracy: 28.26% -> 28.26%     
client [95] (testset)   loss: 2.2461 -> 2.1750  accuracy: 12.84% -> 12.84%     
client [17] (testset)   loss: 2.1967 -> 2.1076  accuracy: 20.00% -> 20.00%     
client [8]  (testset)   loss: 1.9451 -> 1.8723  accuracy: 46.10% -> 46.10%     
client [35] (testset)   loss: 2.0808 -> 2.0450  accuracy: 17.78% -> 23.33%     
client [98] (testset)   loss: 2.1860 -> 2.2079  accuracy: 28.74% -> 28.74%     
client [53] (testset)   loss: 1.9660 -> 1.9211  accuracy: 28.70% -> 32.41%     
client [43] (testset)   loss: 2.1997 -> 2.1466  accuracy: 24.17% -> 24.17%     
client [64] (testset)   loss: 2.1458 -> 2.1268  accuracy: 11.11% -> 15.87%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 2.1604 -> 2.0088  accuracy: 11.61% -> 27.10%     
client [88] (testset)   loss: 1.8989 -> 1.8792  accuracy: 41.42% -> 41.42%     
client [38] (testset)   loss: 2.1352 -> 1.9553  accuracy: 9.83% -> 39.31%      
client [3]  (testset)   loss: 1.5644 -> 1.4214  accuracy: 62.66% -> 62.66%     
client [5]  (testset)   loss: 1.9096 -> 1.6234  accuracy: 17.41% -> 51.79%     
client [41] (testset)   loss: 2.1338 -> 1.8758  accuracy: 11.50% -> 44.25%     
client [7]  (testset)   loss: 2.0460 -> 1.8493  accuracy: 12.90% -> 41.94%     
client [37] (testset)   loss: 2.3864 -> 2.2651  accuracy: 5.69% -> 13.01%      
client [45] (testset)   loss: 2.0038 -> 1.9015  accuracy: 19.58% -> 33.57%     
client [47] (testset)   loss: 1.7794 -> 1.7543  accuracy: 27.97% -> 27.97%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 1.4472 -> 1.3955  accuracy: 59.84% -> 59.84%     
client [11] (testset)   loss: 2.1120 -> 2.0131  accuracy: 36.28% -> 36.28%     
client [37] (testset)   loss: 2.3200 -> 2.2703  accuracy: 19.51% -> 13.01%     
client [41] (testset)   loss: 2.1161 -> 1.8759  accuracy: 44.25% -> 44.25%     
client [95] (testset)   loss: 2.2307 -> 2.1726  accuracy: 12.84% -> 20.18%     
client [53] (testset)   loss: 1.9123 -> 1.9208  accuracy: 32.41% -> 32.41%     
client [22] (testset)   loss: 2.1593 -> 2.0765  accuracy: 18.52% -> 30.86%     
client [25] (testset)   loss: 1.8470 -> 1.8303  accuracy: 40.30% -> 40.30%     
client [69] (testset)   loss: 1.9294 -> 1.9223  accuracy: 30.13% -> 25.64%     
client [46] (testset)   loss: 2.0297 -> 1.9569  accuracy: 30.39% -> 30.39%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 1.7860 -> 1.7625  accuracy: 27.97% -> 27.97%     
client [69] (testset)   loss: 1.9722 -> 1.9144  accuracy: 30.13% -> 25.64%     
client [82] (testset)   loss: 1.9142 -> 1.8315  accuracy: 38.26% -> 38.26%     
client [45] (testset)   loss: 1.9335 -> 1.8735  accuracy: 33.57% -> 33.57%     
client [7]  (testset)   loss: 1.9737 -> 1.8659  accuracy: 41.94% -> 41.94%     
client [50] (testset)   loss: 2.1967 -> 2.1242  accuracy: 17.09% -> 23.08%     
client [35] (testset)   loss: 2.0569 -> 2.0332  accuracy: 23.33% -> 23.33%     
client [24] (testset)   loss: 1.8293 -> 1.7371  accuracy: 39.88% -> 39.88%     
client [15] (testset)   loss: 1.9900 -> 1.9562  accuracy: 35.54% -> 35.54%     
client [58] (testset)   loss: 1.8206 -> 1.7393  accuracy: 31.11% -> 31.11%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 2.1920 -> 2.1532  accuracy: 16.38% -> 21.98%     
client [76] (testset)   loss: 2.1366 -> 2.1226  accuracy: 20.39% -> 20.39%     
client [67] (testset)   loss: 2.0016 -> 2.1805  accuracy: 19.27% -> 14.68%     
client [37] (testset)   loss: 2.3346 -> 2.2766  accuracy: 10.57% -> 13.01%     
client [58] (testset)   loss: 1.8494 -> 1.7256  accuracy: 31.11% -> 32.22%     
client [64] (testset)   loss: 2.1528 -> 2.1262  accuracy: 11.11% -> 15.87%     
client [77] (testset)   loss: 2.0969 -> 2.0716  accuracy: 24.84% -> 24.84%     
client [55] (testset)   loss: 2.1264 -> 2.1377  accuracy: 13.92% -> 13.92%     
client [12] (testset)   loss: 2.1979 -> 2.2348  accuracy: 27.27% -> 27.27%     
client [89] (testset)   loss: 2.0236 -> 2.0229  accuracy: 21.60% -> 21.60%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 2.1897 -> 2.1870  accuracy: 21.93% -> 21.93%     
client [51] (testset)   loss: 2.0548 -> 2.0329  accuracy: 36.19% -> 36.19%     
client [8]  (testset)   loss: 1.9620 -> 1.8627  accuracy: 46.10% -> 46.10%     
client [18] (testset)   loss: 1.6357 -> 1.6263  accuracy: 32.46% -> 32.46%     
client [94] (testset)   loss: 1.9104 -> 1.8876  accuracy: 38.84% -> 38.84%     
client [81] (testset)   loss: 2.2957 -> 2.2046  accuracy: 9.38% -> 20.83%      
client [3]  (testset)   loss: 1.6109 -> 1.4122  accuracy: 62.66% -> 62.66%     
client [11] (testset)   loss: 2.1436 -> 2.0153  accuracy: 36.28% -> 36.28%     
client [95] (testset)   loss: 2.2394 -> 2.1794  accuracy: 12.84% -> 20.18%     
client [67] (testset)   loss: 2.0153 -> 2.0908  accuracy: 20.18% -> 19.27%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 2.0936 -> 1.9909  accuracy: 27.10% -> 27.10%     
client [79] (testset)   loss: 2.0839 -> 2.0276  accuracy: 21.78% -> 21.78%     
client [58] (testset)   loss: 1.7665 -> 1.7424  accuracy: 32.22% -> 31.11%     
client [88] (testset)   loss: 1.9347 -> 1.8782  accuracy: 41.42% -> 41.42%     
client [46] (testset)   loss: 2.0304 -> 1.9402  accuracy: 30.39% -> 30.39%     
client [11] (testset)   loss: 2.0702 -> 2.0285  accuracy: 36.28% -> 36.28%     
client [55] (testset)   loss: 2.2102 -> 2.1298  accuracy: 13.92% -> 17.72%     
client [13] (testset)   loss: 2.1621 -> 2.1264  accuracy: 19.30% -> 19.30%     
client [31] (testset)   loss: 2.1923 -> 2.1785  accuracy: 15.46% -> 18.56%     
client [75] (testset)   loss: 1.9026 -> 1.7591  accuracy: 22.62% -> 22.62%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 2.1354 -> 2.1287  accuracy: 34.16% -> 34.16%     
client [7]  (testset)   loss: 1.9194 -> 1.8498  accuracy: 41.94% -> 41.94%     
client [57] (testset)   loss: 2.2792 -> 2.2325  accuracy: 19.75% -> 19.75%     
client [13] (testset)   loss: 2.2087 -> 2.1338  accuracy: 18.71% -> 19.30%     
client [43] (testset)   loss: 2.1813 -> 2.1502  accuracy: 24.17% -> 24.17%     
client [91] (testset)   loss: 2.2888 -> 2.2592  accuracy: 13.10% -> 16.67%     
client [10] (testset)   loss: 1.9054 -> 1.8304  accuracy: 36.94% -> 36.94%     
client [64] (testset)   loss: 2.1131 -> 2.1231  accuracy: 11.11% -> 15.87%     
client [82] (testset)   loss: 1.9113 -> 1.8423  accuracy: 38.26% -> 38.26%     
client [22] (testset)   loss: 2.1402 -> 2.0799  accuracy: 18.52% -> 30.86%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 2.1245 -> 1.9916  accuracy: 19.18% -> 32.42%     
client [23] (testset)   loss: 2.0913 -> 2.0257  accuracy: 24.23% -> 24.23%     
client [88] (testset)   loss: 1.9251 -> 1.8837  accuracy: 41.42% -> 41.42%     
client [98] (testset)   loss: 2.1150 -> 2.1615  accuracy: 28.74% -> 28.74%     
client [79] (testset)   loss: 2.0739 -> 2.0364  accuracy: 21.78% -> 21.78%     
client [21] (testset)   loss: 2.0678 -> 2.0004  accuracy: 27.10% -> 27.10%     
client [92] (testset)   loss: 2.1708 -> 2.1346  accuracy: 21.49% -> 21.49%     
client [56] (testset)   loss: 1.9540 -> 1.9119  accuracy: 32.58% -> 32.58%     
client [5]  (testset)   loss: 1.6971 -> 1.7588  accuracy: 51.79% -> 51.79%     
client [52] (testset)   loss: 1.9453 -> 1.8964  accuracy: 28.38% -> 28.38%     
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 2.0154 -> 2.0018  accuracy: 19.27% -> 19.27%     
client [54] (testset)   loss: 2.0812 -> 2.0313  accuracy: 20.00% -> 20.00%     
client [14] (testset)   loss: 1.9375 -> 1.9589  accuracy: 35.56% -> 35.56%     
client [99] (testset)   loss: 2.0022 -> 2.0019  accuracy: 32.79% -> 32.79%     
client [36] (testset)   loss: 1.9138 -> 1.8247  accuracy: 36.54% -> 36.54%     
client [30] (testset)   loss: 1.8965 -> 1.7906  accuracy: 32.47% -> 32.47%     
client [38] (testset)   loss: 2.0781 -> 1.9272  accuracy: 39.31% -> 39.31%     
client [15] (testset)   loss: 1.9545 -> 1.9471  accuracy: 35.54% -> 35.54%     
client [6]  (testset)   loss: 2.0881 -> 2.0790  accuracy: 24.72% -> 24.72%     
client [53] (testset)   loss: 1.9856 -> 1.9187  accuracy: 32.41% -> 9.26%      
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [99] (testset)   loss: 1.9956 -> 1.9814  accuracy: 32.79% -> 32.79%     
client [6]  (testset)   loss: 2.1345 -> 2.0753  accuracy: 24.72% -> 24.72%     
client [83] (testset)   loss: 1.8080 -> 1.7686  accuracy: 23.27% -> 30.82%     
client [42] (testset)   loss: 2.0758 -> 2.0655  accuracy: 20.95% -> 20.95%     
client [34] (testset)   loss: 2.0665 -> 1.9789  accuracy: 32.74% -> 32.74%     
client [15] (testset)   loss: 1.9679 -> 1.9520  accuracy: 35.54% -> 35.54%     
client [47] (testset)   loss: 1.8241 -> 1.7500  accuracy: 27.97% -> 27.97%     
client [55] (testset)   loss: 2.1933 -> 2.1135  accuracy: 13.92% -> 17.72%     
client [51] (testset)   loss: 2.1062 -> 2.0236  accuracy: 36.19% -> 36.19%     
client [95] (testset)   loss: 2.2130 -> 2.1922  accuracy: 20.18% -> 12.84%     
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 1.8208 -> 1.7707  accuracy: 40.35% -> 40.35%     
client [15] (testset)   loss: 1.9577 -> 1.9531  accuracy: 35.54% -> 35.54%     
client [33] (testset)   loss: 2.1603 -> 2.1312  accuracy: 28.82% -> 28.82%     
client [99] (testset)   loss: 1.9994 -> 1.9779  accuracy: 32.79% -> 32.79%     
client [90] (testset)   loss: 1.9201 -> 1.7998  accuracy: 30.90% -> 30.90%     
client [57] (testset)   loss: 2.2783 -> 2.2269  accuracy: 11.11% -> 19.75%     
client [27] (testset)   loss: 2.0189 -> 1.9574  accuracy: 30.83% -> 30.83%     
client [78] (testset)   loss: 2.1373 -> 2.0715  accuracy: 8.20% -> 26.23%      
client [36] (testset)   loss: 1.9450 -> 1.8400  accuracy: 36.54% -> 36.54%     
client [88] (testset)   loss: 1.9667 -> 1.8625  accuracy: 41.42% -> 41.42%     
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 1.8356 -> 1.7770  accuracy: 30.17% -> 30.17%     
client [35] (testset)   loss: 2.0847 -> 2.0387  accuracy: 17.78% -> 23.33%     
client [16] (testset)   loss: 1.4921 -> 1.4000  accuracy: 59.84% -> 59.84%     
client [80] (testset)   loss: 2.0506 -> 2.0042  accuracy: 35.71% -> 35.71%     
client [38] (testset)   loss: 2.0368 -> 1.9199  accuracy: 39.31% -> 39.31%     
client [78] (testset)   loss: 2.1335 -> 2.0571  accuracy: 17.21% -> 26.23%     
client [68] (testset)   loss: 2.0705 -> 2.0813  accuracy: 20.00% -> 16.80%     
client [11] (testset)   loss: 2.0679 -> 2.0071  accuracy: 36.28% -> 36.28%     
client [64] (testset)   loss: 2.1291 -> 2.1135  accuracy: 15.87% -> 15.87%     
client [82] (testset)   loss: 1.9377 -> 1.8447  accuracy: 38.26% -> 38.26%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 1.9514 -> 1.8448  accuracy: 32.47% -> 30.52%     
client [27] (testset)   loss: 2.0135 -> 1.9548  accuracy: 30.83% -> 30.83%     
client [74] (testset)   loss: 2.1825 -> 2.1538  accuracy: 27.37% -> 27.37%     
client [45] (testset)   loss: 1.9662 -> 1.8786  accuracy: 33.57% -> 33.57%     
client [6]  (testset)   loss: 2.1164 -> 2.0700  accuracy: 24.72% -> 24.72%     
client [36] (testset)   loss: 1.8970 -> 1.8383  accuracy: 36.54% -> 36.54%     
client [63] (testset)   loss: 2.0664 -> 2.0617  accuracy: 17.97% -> 14.84%     
client [76] (testset)   loss: 2.1927 -> 2.1362  accuracy: 20.39% -> 20.39%     
client [83] (testset)   loss: 1.8114 -> 1.7671  accuracy: 30.82% -> 30.82%     
client [86] (testset)   loss: 2.0329 -> 1.9941  accuracy: 22.62% -> 22.62%     
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 1.8086 -> 1.7663  accuracy: 30.82% -> 30.82%     
client [99] (testset)   loss: 2.0157 -> 1.9874  accuracy: 32.79% -> 32.79%     
client [74] (testset)   loss: 2.1862 -> 2.1402  accuracy: 27.37% -> 27.37%     
client [73] (testset)   loss: 1.8680 -> 1.8626  accuracy: 27.18% -> 27.18%     
client [29] (testset)   loss: 2.3297 -> 2.3010  accuracy: 24.04% -> 24.04%     
client [92] (testset)   loss: 2.1570 -> 2.1121  accuracy: 21.49% -> 17.36%     
client [6]  (testset)   loss: 2.1065 -> 2.0739  accuracy: 24.72% -> 24.72%     
client [61] (testset)   loss: 2.0466 -> 2.0078  accuracy: 15.08% -> 15.08%     
client [21] (testset)   loss: 2.1070 -> 2.0090  accuracy: 27.10% -> 27.10%     
client [67] (testset)   loss: 2.0226 -> 2.0178  accuracy: 19.27% -> 19.27%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 1.8044 -> 1.7711  accuracy: 30.82% -> 30.82%     
client [32] (testset)   loss: 1.9870 -> 1.9674  accuracy: 26.51% -> 26.51%     
client [95] (testset)   loss: 2.2172 -> 2.1886  accuracy: 12.84% -> 12.84%     
client [61] (testset)   loss: 2.0216 -> 1.9793  accuracy: 15.08% -> 31.75%     
client [27] (testset)   loss: 2.0335 -> 1.9563  accuracy: 12.78% -> 30.83%     
client [25] (testset)   loss: 1.8762 -> 1.8501  accuracy: 40.30% -> 40.30%     
client [68] (testset)   loss: 2.0842 -> 2.0762  accuracy: 23.20% -> 23.20%     
client [34] (testset)   loss: 2.0743 -> 2.0172  accuracy: 32.74% -> 32.74%     
client [71] (testset)   loss: 1.7986 -> 1.7224  accuracy: 40.35% -> 40.35%     
client [89] (testset)   loss: 2.0040 -> 2.0082  accuracy: 21.60% -> 23.46%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 2.1248 -> 2.0665  accuracy: 26.23% -> 26.23%     
client [81] (testset)   loss: 2.2394 -> 2.2735  accuracy: 9.38% -> 5.21%       
client [51] (testset)   loss: 2.0444 -> 2.0263  accuracy: 36.19% -> 36.19%     
client [54] (testset)   loss: 2.0605 -> 2.0295  accuracy: 20.00% -> 20.00%     
client [65] (testset)   loss: 2.0565 -> 1.9844  accuracy: 28.26% -> 28.26%     
client [41] (testset)   loss: 2.0117 -> 1.8873  accuracy: 44.25% -> 44.25%     
client [11] (testset)   loss: 2.0804 -> 2.0149  accuracy: 36.28% -> 36.28%     
client [85] (testset)   loss: 2.1158 -> 2.1004  accuracy: 27.76% -> 27.76%     
client [12] (testset)   loss: 2.1991 -> 2.2451  accuracy: 27.27% -> 27.27%     
client [23] (testset)   loss: 2.0878 -> 2.0464  accuracy: 24.23% -> 16.54%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 1.4508 -> 1.3974  accuracy: 59.84% -> 59.84%     
client [65] (testset)   loss: 2.0580 -> 1.9830  accuracy: 28.26% -> 28.26%     
client [53] (testset)   loss: 1.9089 -> 1.8672  accuracy: 32.41% -> 32.41%     
client [58] (testset)   loss: 1.7717 -> 1.7250  accuracy: 31.11% -> 31.11%     
client [72] (testset)   loss: 2.1223 -> 2.0983  accuracy: 26.63% -> 26.63%     
client [7]  (testset)   loss: 1.9014 -> 1.8435  accuracy: 41.94% -> 41.94%     
client [71] (testset)   loss: 1.8240 -> 1.7334  accuracy: 40.35% -> 40.35%     
client [59] (testset)   loss: 2.1533 -> 2.0519  accuracy: 24.49% -> 24.49%     
client [86] (testset)   loss: 2.0438 -> 1.9954  accuracy: 25.00% -> 22.62%     
client [39] (testset)   loss: 2.0681 -> 1.9895  accuracy: 19.53% -> 19.53%     
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 2.0154 -> 1.9795  accuracy: 32.79% -> 32.79%     
client [7]  (testset)   loss: 1.9022 -> 1.8377  accuracy: 41.94% -> 41.94%     
client [17] (testset)   loss: 2.1634 -> 2.1035  accuracy: 20.00% -> 23.08%     
client [64] (testset)   loss: 2.1381 -> 2.1080  accuracy: 11.11% -> 15.87%     
client [37] (testset)   loss: 2.3522 -> 2.2693  accuracy: 19.51% -> 13.01%     
client [29] (testset)   loss: 2.2992 -> 2.2946  accuracy: 24.04% -> 24.04%     
client [93] (testset)   loss: 1.2825 -> 1.2027  accuracy: 69.57% -> 69.57%     
client [73] (testset)   loss: 1.8839 -> 1.8451  accuracy: 26.21% -> 27.18%     
client [40] (testset)   loss: 1.9188 -> 1.8483  accuracy: 23.21% -> 31.25%     
client [76] (testset)   loss: 2.1593 -> 2.1354  accuracy: 20.39% -> 20.39%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 2.1749 -> 2.1759  accuracy: 18.56% -> 18.56%     
client [89] (testset)   loss: 2.0107 -> 2.0169  accuracy: 21.60% -> 21.60%     
client [77] (testset)   loss: 2.1086 -> 2.0633  accuracy: 24.84% -> 24.84%     
client [90] (testset)   loss: 1.8754 -> 1.7993  accuracy: 30.90% -> 30.90%     
client [26] (testset)   loss: 1.6163 -> 1.4704  accuracy: 54.98% -> 54.98%     
client [50] (testset)   loss: 2.1745 -> 2.1302  accuracy: 17.09% -> 23.08%     
client [30] (testset)   loss: 1.9761 -> 1.7976  accuracy: 30.52% -> 32.47%     
client [70] (testset)   loss: 1.8183 -> 1.7813  accuracy: 30.17% -> 30.17%     
client [41] (testset)   loss: 1.9460 -> 1.8780  accuracy: 44.25% -> 44.25%     
client [99] (testset)   loss: 2.0106 -> 1.9852  accuracy: 32.79% -> 32.79%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [68] (testset)   loss: 2.0993 -> 2.0648  accuracy: 16.80% -> 20.00%     
client [70] (testset)   loss: 1.8160 -> 1.7728  accuracy: 30.17% -> 30.17%     
client [52] (testset)   loss: 1.9609 -> 1.8987  accuracy: 28.38% -> 28.38%     
client [1]  (testset)   loss: 2.0492 -> 2.0325  accuracy: 23.66% -> 16.13%     
client [2]  (testset)   loss: 2.0336 -> 1.9540  accuracy: 33.85% -> 33.85%     
client [67] (testset)   loss: 2.0179 -> 2.0374  accuracy: 20.18% -> 19.27%     
client [92] (testset)   loss: 2.1282 -> 2.1033  accuracy: 21.49% -> 21.49%     
client [35] (testset)   loss: 2.0712 -> 2.0381  accuracy: 23.33% -> 23.33%     
client [36] (testset)   loss: 1.8883 -> 1.8436  accuracy: 36.54% -> 36.54%     
client [64] (testset)   loss: 2.0858 -> 2.1262  accuracy: 11.11% -> 15.87%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 2.0700 -> 2.0663  accuracy: 28.38% -> 28.38%     
client [6]  (testset)   loss: 2.1199 -> 2.0693  accuracy: 24.72% -> 24.72%     
client [12] (testset)   loss: 2.1943 -> 2.2190  accuracy: 27.27% -> 27.27%     
client [55] (testset)   loss: 2.1686 -> 2.1154  accuracy: 13.92% -> 13.92%     
client [29] (testset)   loss: 2.3122 -> 2.3215  accuracy: 24.04% -> 24.04%     
client [9]  (testset)   loss: 2.1050 -> 2.1024  accuracy: 31.11% -> 31.11%     
client [43] (testset)   loss: 2.1777 -> 2.1459  accuracy: 24.17% -> 24.17%     
client [77] (testset)   loss: 2.1304 -> 2.0584  accuracy: 24.84% -> 24.84%     
client [98] (testset)   loss: 2.1456 -> 2.1508  accuracy: 28.74% -> 28.74%     
client [78] (testset)   loss: 2.1371 -> 2.0656  accuracy: 8.20% -> 26.23%      
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 2.1507 -> 2.1171  accuracy: 21.49% -> 21.49%     
client [80] (testset)   loss: 2.0976 -> 2.0071  accuracy: 35.71% -> 35.71%     
client [63] (testset)   loss: 2.0635 -> 2.0295  accuracy: 16.41% -> 14.84%     
client [76] (testset)   loss: 2.1793 -> 2.1430  accuracy: 20.39% -> 20.39%     
client [78] (testset)   loss: 2.1442 -> 2.0640  accuracy: 8.20% -> 26.23%      
client [25] (testset)   loss: 1.8748 -> 1.8427  accuracy: 40.30% -> 40.30%     
client [58] (testset)   loss: 1.7700 -> 1.7188  accuracy: 31.11% -> 32.22%     
client [13] (testset)   loss: 2.1749 -> 2.1382  accuracy: 19.30% -> 19.30%     
client [17] (testset)   loss: 2.1253 -> 2.1029  accuracy: 20.00% -> 20.00%     
client [38] (testset)   loss: 2.0182 -> 1.9391  accuracy: 39.31% -> 39.31%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 2.1266 -> 2.0944  accuracy: 26.63% -> 26.63%     
client [82] (testset)   loss: 1.9637 -> 1.8341  accuracy: 38.26% -> 38.26%     
client [86] (testset)   loss: 2.0333 -> 1.9998  accuracy: 22.62% -> 22.62%     
client [51] (testset)   loss: 2.0533 -> 2.0383  accuracy: 36.19% -> 36.19%     
client [96] (testset)   loss: 2.0865 -> 2.0168  accuracy: 13.79% -> 22.41%     
client [42] (testset)   loss: 2.0643 -> 2.0620  accuracy: 20.95% -> 20.95%     
client [55] (testset)   loss: 2.1466 -> 2.1089  accuracy: 13.92% -> 13.92%     
client [13] (testset)   loss: 2.1845 -> 2.1290  accuracy: 18.71% -> 19.30%     
client [1]  (testset)   loss: 2.0412 -> 2.0343  accuracy: 23.66% -> 16.13%     
client [12] (testset)   loss: 2.2451 -> 2.2571  accuracy: 12.73% -> 27.27%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 2.0892 -> 2.0682  accuracy: 16.80% -> 23.20%     
client [23] (testset)   loss: 2.0951 -> 2.0577  accuracy: 24.23% -> 16.54%     
client [46] (testset)   loss: 2.0153 -> 1.9532  accuracy: 30.39% -> 30.39%     
client [41] (testset)   loss: 1.9488 -> 1.8745  accuracy: 44.25% -> 44.25%     
client [25] (testset)   loss: 1.8544 -> 1.8453  accuracy: 40.30% -> 40.30%     
client [58] (testset)   loss: 1.7814 -> 1.7423  accuracy: 32.22% -> 31.11%     
client [14] (testset)   loss: 1.9332 -> 1.9414  accuracy: 35.56% -> 35.56%     
client [33] (testset)   loss: 2.1823 -> 2.1283  accuracy: 17.65% -> 28.82%     
client [85] (testset)   loss: 2.1199 -> 2.0962  accuracy: 27.76% -> 27.76%     
client [62] (testset)   loss: 2.0720 -> 2.0511  accuracy: 33.83% -> 33.83%     
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 2.1518 -> 2.1243  accuracy: 28.74% -> 28.74%     
client [63] (testset)   loss: 2.0519 -> 2.0341  accuracy: 14.84% -> 14.84%     
client [70] (testset)   loss: 1.8116 -> 1.7797  accuracy: 30.17% -> 30.17%     
client [65] (testset)   loss: 2.0471 -> 1.9716  accuracy: 28.26% -> 28.26%     
client [14] (testset)   loss: 1.9673 -> 1.9518  accuracy: 35.56% -> 35.56%     
client [73] (testset)   loss: 1.8628 -> 1.8572  accuracy: 27.18% -> 27.18%     
client [34] (testset)   loss: 2.0594 -> 2.0176  accuracy: 32.74% -> 32.74%     
client [99] (testset)   loss: 2.0170 -> 1.9755  accuracy: 32.79% -> 32.79%     
client [69] (testset)   loss: 1.9411 -> 1.9287  accuracy: 25.64% -> 25.64%     
client [46] (testset)   loss: 2.0204 -> 1.9622  accuracy: 30.39% -> 30.39%     
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [99] (testset)   loss: 2.0403 -> 1.9809  accuracy: 32.79% -> 32.79%     
client [93] (testset)   loss: 1.4997 -> 1.2636  accuracy: 69.57% -> 69.57%     
client [11] (testset)   loss: 2.0977 -> 2.0113  accuracy: 36.28% -> 36.28%     
client [58] (testset)   loss: 1.7852 -> 1.7323  accuracy: 31.11% -> 31.11%     
client [81] (testset)   loss: 2.2340 -> 2.2008  accuracy: 25.00% -> 20.83%     
client [85] (testset)   loss: 2.1512 -> 2.0903  accuracy: 27.76% -> 27.76%     
client [89] (testset)   loss: 2.0033 -> 2.0379  accuracy: 23.46% -> 23.46%     
client [45] (testset)   loss: 1.9683 -> 1.8752  accuracy: 33.57% -> 33.57%     
client [8]  (testset)   loss: 1.9231 -> 1.8665  accuracy: 46.10% -> 46.10%     
client [68] (testset)   loss: 2.0799 -> 2.0667  accuracy: 23.20% -> 23.20%     
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 2.0004 -> 2.0316  accuracy: 19.27% -> 19.27%     
client [72] (testset)   loss: 2.1199 -> 2.0995  accuracy: 26.63% -> 26.63%     
client [1]  (testset)   loss: 2.0731 -> 2.0356  accuracy: 23.66% -> 16.13%     
client [78] (testset)   loss: 2.1172 -> 2.0714  accuracy: 26.23% -> 26.23%     
client [83] (testset)   loss: 1.7990 -> 1.7654  accuracy: 30.82% -> 30.82%     
client [21] (testset)   loss: 2.0541 -> 1.9930  accuracy: 27.10% -> 27.10%     
client [56] (testset)   loss: 1.9454 -> 1.9062  accuracy: 32.58% -> 32.58%     
client [44] (testset)   loss: 2.0895 -> 2.0726  accuracy: 28.38% -> 28.38%     
client [92] (testset)   loss: 2.1220 -> 2.0990  accuracy: 21.49% -> 21.49%     
client [27] (testset)   loss: 2.0199 -> 1.9644  accuracy: 30.83% -> 30.83%     
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 1.9036 -> 1.8091  accuracy: 36.94% -> 36.94%     
client [39] (testset)   loss: 2.0434 -> 1.9885  accuracy: 20.71% -> 20.12%     
client [65] (testset)   loss: 2.0295 -> 1.9909  accuracy: 28.26% -> 28.26%     
client [26] (testset)   loss: 1.6569 -> 1.4747  accuracy: 54.98% -> 54.98%     
client [19] (testset)   loss: 2.0851 -> 2.0637  accuracy: 34.16% -> 34.16%     
client [68] (testset)   loss: 2.0662 -> 2.0828  accuracy: 16.80% -> 16.80%     
client [41] (testset)   loss: 1.9389 -> 1.8824  accuracy: 44.25% -> 44.25%     
client [50] (testset)   loss: 2.1432 -> 2.1279  accuracy: 17.09% -> 23.08%     
client [75] (testset)   loss: 1.8255 -> 1.7529  accuracy: 22.62% -> 22.62%     
client [81] (testset)   loss: 2.2779 -> 2.2263  accuracy: 9.38% -> 12.50%      
APFL's average time taken by each global epoch: 0 min 3.11 sec.                
APFL's total running time: 0 h 20 m 48 s.                                      
==================== APFL Experiment Results: ====================             
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "2.0262 -> 0.0000",                                    
                "accuracy": "29.67% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "2.0118 -> 0.0000",                                    
                "accuracy": "29.54% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "2.0064 -> 0.0000",                                    
                "accuracy": "27.27% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "2.0036 -> 0.0000",                                    
                "accuracy": "29.29% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== APFL Max Accuracy ====================                    
all_clients:                                                                   
(test) before fine-tuning: 29.67% at epoch 100                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
