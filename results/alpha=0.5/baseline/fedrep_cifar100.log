==================== FedRep ====================                               
Experiment Arguments:                                                          
{
â”‚   'method': 'fedrep',
â”‚   'dataset': {
â”‚   â”‚   'name': 'cifar100',
â”‚   â”‚   'client_num': 100,
â”‚   â”‚   'test_ratio': 0.25,
â”‚   â”‚   'val_ratio': 0.0,
â”‚   â”‚   'seed': 42,
â”‚   â”‚   'split': 'sample',
â”‚   â”‚   'IID_ratio': 0.0,
â”‚   â”‚   'monitor_window_name_suffix': 'cifar100-100clients-0%IID-use20superclasses-Dir(0.5)-seed42',
â”‚   â”‚   'super_class': False,
â”‚   â”‚   'alpha': 0.5,
â”‚   â”‚   'min_samples_per_client': 10
â”‚   },
â”‚   'model': {
â”‚   â”‚   'name': 'avgcnn',
â”‚   â”‚   'use_torchvision_pretrained_weights': True,
â”‚   â”‚   'external_model_weights_path': None
â”‚   },
â”‚   'optimizer': {
â”‚   â”‚   'lr': 0.01,
â”‚   â”‚   'dampening': 0,
â”‚   â”‚   'weight_decay': 0,
â”‚   â”‚   'momentum': 0,
â”‚   â”‚   'nesterov': False,
â”‚   â”‚   'name': 'sgd'
â”‚   },
â”‚   'mode': 'serial',
â”‚   'parallel': {
â”‚   â”‚   'ray_cluster_addr': None,
â”‚   â”‚   'num_cpus': None,
â”‚   â”‚   'num_gpus': None,
â”‚   â”‚   'num_workers': 2
â”‚   },
â”‚   'common': {
â”‚   â”‚   'seed': 42,
â”‚   â”‚   'join_ratio': 0.1,
â”‚   â”‚   'global_epoch': 400,
â”‚   â”‚   'local_epoch': 5,
â”‚   â”‚   'batch_size': 32,
â”‚   â”‚   'reset_optimizer_on_global_epoch': True,
â”‚   â”‚   'straggler_ratio': 0,
â”‚   â”‚   'straggler_min_local_epoch': 0,
â”‚   â”‚   'buffers': 'global',
â”‚   â”‚   'client_side_evaluation': True,
â”‚   â”‚   'test': {
â”‚   â”‚   â”‚   'client': {
â”‚   â”‚   â”‚   â”‚   'interval': 100,
â”‚   â”‚   â”‚   â”‚   'finetune_epoch': 0,
â”‚   â”‚   â”‚   â”‚   'train': False,
â”‚   â”‚   â”‚   â”‚   'val': False,
â”‚   â”‚   â”‚   â”‚   'test': True
â”‚   â”‚   â”‚   },
â”‚   â”‚   â”‚   'server': {
â”‚   â”‚   â”‚   â”‚   'interval': -1,
â”‚   â”‚   â”‚   â”‚   'train': False,
â”‚   â”‚   â”‚   â”‚   'val': False,
â”‚   â”‚   â”‚   â”‚   'test': False,
â”‚   â”‚   â”‚   â”‚   'model_in_train_mode': False
â”‚   â”‚   â”‚   }
â”‚   â”‚   },
â”‚   â”‚   'verbose_gap': 10,
â”‚   â”‚   'monitor': None,
â”‚   â”‚   'use_cuda': True,
â”‚   â”‚   'save_log': True,
â”‚   â”‚   'save_model': False,
â”‚   â”‚   'save_learning_curve_plot': False,
â”‚   â”‚   'save_metrics': True,
â”‚   â”‚   'delete_useless_run': True
â”‚   },
â”‚   'fedrep': {
â”‚   â”‚   'train_body_epoch': 1
â”‚   }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 4.0379 -> 3.9094  accuracy: 4.90% -> 6.29%       
client [81] (testset)   loss: 4.0872 -> 4.0450  accuracy: 3.12% -> 7.81%       
client [21] (testset)   loss: 4.4557 -> 4.3027  accuracy: 2.54% -> 9.32%       
client [68] (testset)   loss: 3.9874 -> 3.9055  accuracy: 9.02% -> 9.77%       
client [93] (testset)   loss: 4.1261 -> 3.9819  accuracy: 7.25% -> 13.77%      
client [31] (testset)   loss: 4.1504 -> 3.9884  accuracy: 10.66% -> 12.30%     
client [20] (testset)   loss: 4.0561 -> 4.0120  accuracy: 9.56% -> 10.29%      
client [59] (testset)   loss: 4.7141 -> 3.9483  accuracy: 0.00% -> 11.66%      
client [48] (testset)   loss: 4.1750 -> 4.1475  accuracy: 9.63% -> 5.19%       
client [34] (testset)   loss: 3.9197 -> 3.8843  accuracy: 6.40% -> 9.60%       
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 4.7057 -> 3.6444  accuracy: 15.45% -> 18.70%     
client [99] (testset)   loss: 4.0761 -> 4.0074  accuracy: 9.74% -> 11.69%      
client [67] (testset)   loss: 3.6812 -> 3.6850  accuracy: 14.79% -> 17.75%     
client [0]  (testset)   loss: 3.7575 -> 3.8192  accuracy: 13.22% -> 14.94%     
client [76] (testset)   loss: 4.1834 -> 4.0429  accuracy: 7.32% -> 11.38%      
client [41] (testset)   loss: 3.7215 -> 3.5982  accuracy: 15.26% -> 17.89%     
client [62] (testset)   loss: 4.4769 -> 3.6131  accuracy: 1.18% -> 17.16%      
client [2]  (testset)   loss: 4.2342 -> 3.7012  accuracy: 5.59% -> 15.64%      
client [14] (testset)   loss: 3.9584 -> 3.9280  accuracy: 12.21% -> 11.63%     
client [46] (testset)   loss: 4.1783 -> 4.2357  accuracy: 9.88% -> 12.79%      
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 4.6679 -> 4.7997  accuracy: 11.72% -> 5.47%      
client [68] (testset)   loss: 3.7026 -> 3.6606  accuracy: 14.29% -> 18.05%     
client [57] (testset)   loss: 3.6447 -> 3.7005  accuracy: 10.22% -> 13.87%     
client [17] (testset)   loss: 3.9455 -> 3.8145  accuracy: 18.84% -> 15.94%     
client [54] (testset)   loss: 3.8270 -> 3.7618  accuracy: 18.75% -> 20.14%     
client [23] (testset)   loss: 4.2053 -> 3.9087  accuracy: 8.51% -> 9.22%       
client [35] (testset)   loss: 3.9067 -> 3.6308  accuracy: 7.93% -> 16.46%      
client [59] (testset)   loss: 3.7288 -> 3.8669  accuracy: 15.34% -> 13.50%     
client [31] (testset)   loss: 3.8241 -> 3.8338  accuracy: 15.57% -> 18.03%     
client [9]  (testset)   loss: 3.9322 -> 3.8289  accuracy: 9.72% -> 14.58%      
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 4.2574 -> 3.8137  accuracy: 8.20% -> 14.21%      
client [33] (testset)   loss: 3.7358 -> 4.0801  accuracy: 15.08% -> 14.29%     
client [16] (testset)   loss: 3.9420 -> 3.7235  accuracy: 18.12% -> 20.81%     
client [44] (testset)   loss: 4.8533 -> 4.3431  accuracy: 13.42% -> 5.37%      
client [8]  (testset)   loss: 3.9328 -> 4.0633  accuracy: 15.17% -> 14.48%     
client [31] (testset)   loss: 3.9819 -> 4.0702  accuracy: 18.03% -> 21.31%     
client [47] (testset)   loss: 3.8323 -> 3.7588  accuracy: 18.12% -> 17.39%     
client [36] (testset)   loss: 3.8494 -> 3.8092  accuracy: 15.04% -> 18.58%     
client [20] (testset)   loss: 3.9835 -> 3.9752  accuracy: 16.91% -> 18.38%     
client [56] (testset)   loss: 4.1989 -> 3.9430  accuracy: 11.90% -> 12.70%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 3.9524 -> 3.7904  accuracy: 14.17% -> 17.50%     
client [60] (testset)   loss: 4.2444 -> 4.2327  accuracy: 11.48% -> 10.66%     
client [28] (testset)   loss: 4.3415 -> 4.0791  accuracy: 15.15% -> 15.15%     
client [25] (testset)   loss: 4.0458 -> 3.8819  accuracy: 16.13% -> 20.97%     
client [58] (testset)   loss: 4.3464 -> 4.2878  accuracy: 12.26% -> 12.90%     
client [44] (testset)   loss: 8.9007 -> 4.9611  accuracy: 0.67% -> 8.72%       
client [39] (testset)   loss: 4.0959 -> 4.1130  accuracy: 16.79% -> 16.06%     
client [29] (testset)   loss: 4.3769 -> 4.2207  accuracy: 17.90% -> 17.28%     
client [3]  (testset)   loss: 4.6053 -> 4.1305  accuracy: 9.84% -> 12.44%      
client [84] (testset)   loss: 4.3752 -> 4.2046  accuracy: 11.98% -> 14.37%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 8.5623 -> 5.2551  accuracy: 0.85% -> 6.78%       
client [84] (testset)   loss: 4.2406 -> 4.3772  accuracy: 14.97% -> 11.98%     
client [10] (testset)   loss: 3.9559 -> 3.7683  accuracy: 14.69% -> 14.12%     
client [36] (testset)   loss: 4.4007 -> 4.4599  accuracy: 20.35% -> 14.16%     
client [65] (testset)   loss: 4.0117 -> 4.4174  accuracy: 19.31% -> 15.17%     
client [81] (testset)   loss: 4.7595 -> 4.7612  accuracy: 11.98% -> 8.85%      
client [79] (testset)   loss: 4.4490 -> 6.1596  accuracy: 17.86% -> 17.14%     
client [42] (testset)   loss: 3.9933 -> 4.1174  accuracy: 13.77% -> 18.12%     
client [11] (testset)   loss: 3.8718 -> 3.9561  accuracy: 17.60% -> 16.80%     
client [96] (testset)   loss: 4.3728 -> 4.2367  accuracy: 15.48% -> 16.13%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 5.0272 -> 4.8210  accuracy: 13.10% -> 17.93%     
client [53] (testset)   loss: 4.6525 -> 4.5438  accuracy: 18.71% -> 9.68%      
client [52] (testset)   loss: 5.0521 -> 4.5199  accuracy: 16.67% -> 13.44%     
client [42] (testset)   loss: 4.3451 -> 4.4656  accuracy: 15.22% -> 21.01%     
client [69] (testset)   loss: 4.4676 -> 4.9032  accuracy: 21.95% -> 15.45%     
client [59] (testset)   loss: 4.6436 -> 4.9020  accuracy: 12.27% -> 14.72%     
client [7]  (testset)   loss: 6.5273 -> 4.9663  accuracy: 8.63% -> 9.35%       
client [26] (testset)   loss: 4.1141 -> 4.1214  accuracy: 17.12% -> 21.23%     
client [49] (testset)   loss: 4.4991 -> 4.7688  accuracy: 15.45% -> 10.91%     
client [98] (testset)   loss: 4.5013 -> 4.8157  accuracy: 15.25% -> 15.25%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 4.8962 -> 5.0239  accuracy: 16.95% -> 13.56%     
client [47] (testset)   loss: 4.9370 -> 4.2175  accuracy: 18.12% -> 17.39%     
client [21] (testset)   loss: 6.9921 -> 6.5824  accuracy: 9.32% -> 5.93%       
client [77] (testset)   loss: 4.9952 -> 4.8791  accuracy: 16.08% -> 14.69%     
client [95] (testset)   loss: 4.8392 -> 5.3716  accuracy: 18.67% -> 15.06%     
client [91] (testset)   loss: 5.3206 -> 5.4320  accuracy: 13.07% -> 12.42%     
client [14] (testset)   loss: 4.9467 -> 4.7329  accuracy: 18.02% -> 15.70%     
client [99] (testset)   loss: 5.2530 -> 5.3291  accuracy: 16.23% -> 14.29%     
client [20] (testset)   loss: 4.9994 -> 5.3041  accuracy: 18.38% -> 11.76%     
client [39] (testset)   loss: 5.2557 -> 5.0162  accuracy: 17.52% -> 16.79%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 5.6069 -> 5.0715  accuracy: 15.05% -> 18.82%     
client [62] (testset)   loss: 5.0701 -> 5.3289  accuracy: 16.57% -> 18.34%     
client [71] (testset)   loss: 5.7699 -> 5.5994  accuracy: 18.75% -> 15.62%     
client [97] (testset)   loss: 4.8438 -> 4.9379  accuracy: 20.89% -> 17.09%     
client [30] (testset)   loss: 5.4722 -> 5.8931  accuracy: 11.66% -> 17.79%     
client [88] (testset)   loss: 4.6185 -> 4.7610  accuracy: 16.41% -> 16.41%     
client [60] (testset)   loss: 5.8663 -> 6.9372  accuracy: 13.93% -> 13.93%     
client [82] (testset)   loss: 5.1183 -> 4.9872  accuracy: 14.18% -> 17.91%     
client [91] (testset)   loss: 5.8242 -> 6.0650  accuracy: 13.73% -> 13.07%     
client [57] (testset)   loss: 4.4687 -> 4.7268  accuracy: 19.71% -> 17.52%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 6.4410 -> 6.5832  accuracy: 21.31% -> 22.13%     
client [15] (testset)   loss: 5.0030 -> 5.1911  accuracy: 17.22% -> 16.11%     
client [71] (testset)   loss: 10.4844 -> 5.9057 accuracy: 12.50% -> 17.97%     
client [97] (testset)   loss: 5.4527 -> 5.6668  accuracy: 22.78% -> 21.52%     
client [53] (testset)   loss: 6.1841 -> 5.6378  accuracy: 12.26% -> 13.55%     
client [77] (testset)   loss: 5.5261 -> 5.9382  accuracy: 13.29% -> 12.59%     
client [76] (testset)   loss: 5.8558 -> 6.2957  accuracy: 13.01% -> 9.76%      
client [79] (testset)   loss: 5.6482 -> 5.6538  accuracy: 22.86% -> 15.71%     
client [28] (testset)   loss: 6.2119 -> 6.1507  accuracy: 19.39% -> 18.18%     
client [99] (testset)   loss: 6.6405 -> 6.2535  accuracy: 14.29% -> 13.64%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 6.0292 -> 6.4860  accuracy: 18.99% -> 20.89%     
client [86] (testset)   loss: 6.0008 -> 6.3383  accuracy: 21.79% -> 17.95%     
client [34] (testset)   loss: 5.9944 -> 6.2536  accuracy: 18.40% -> 20.00%     
client [73] (testset)   loss: 6.1826 -> 6.9804  accuracy: 14.20% -> 11.36%     
client [5]  (testset)   loss: 5.8630 -> 6.0881  accuracy: 12.41% -> 19.31%     
client [96] (testset)   loss: 6.9254 -> 6.9950  accuracy: 15.48% -> 14.19%     
client [22] (testset)   loss: 6.1965 -> 6.3934  accuracy: 16.89% -> 16.22%     
client [60] (testset)   loss: 6.8743 -> 7.6431  accuracy: 21.31% -> 14.75%     
client [66] (testset)   loss: 10.6798 -> 21.3692    accuracy: 10.53% -> 2.34%  
client [83] (testset)   loss: 6.3993 -> 6.8547  accuracy: 18.40% -> 16.00%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 7.1230 -> 7.2875  accuracy: 13.82% -> 13.82%     
client [65] (testset)   loss: 6.5246 -> 6.4530  accuracy: 17.24% -> 20.69%     
client [95] (testset)   loss: 6.5690 -> 6.6845  accuracy: 16.87% -> 16.27%     
client [17] (testset)   loss: 5.9561 -> 5.9032  accuracy: 14.49% -> 10.87%     
client [8]  (testset)   loss: 7.7924 -> 7.3946  accuracy: 12.41% -> 13.10%     
client [35] (testset)   loss: 7.5750 -> 7.8263  accuracy: 14.63% -> 12.20%     
client [98] (testset)   loss: 6.7043 -> 6.7669  accuracy: 14.69% -> 15.25%     
client [53] (testset)   loss: 6.6327 -> 8.4476  accuracy: 11.61% -> 11.61%     
client [43] (testset)   loss: 7.1081 -> 6.9258  accuracy: 10.00% -> 10.00%     
client [64] (testset)   loss: 10.9780 -> 8.1531 accuracy: 18.03% -> 14.21%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 12.0473 -> 10.7808    accuracy: 5.93% -> 7.63%   
client [88] (testset)   loss: 6.4766 -> 6.4392  accuracy: 22.66% -> 20.31%     
client [38] (testset)   loss: 6.4089 -> 7.1631  accuracy: 26.26% -> 24.24%     
client [3]  (testset)   loss: 7.3399 -> 10.4204 accuracy: 18.65% -> 17.62%     
client [5]  (testset)   loss: 6.8835 -> 7.2663  accuracy: 15.17% -> 13.79%     
client [41] (testset)   loss: 6.3658 -> 7.1041  accuracy: 22.63% -> 17.89%     
client [7]  (testset)   loss: 8.4118 -> 7.9004  accuracy: 12.23% -> 10.07%     
client [37] (testset)   loss: 6.6447 -> 6.3724  accuracy: 13.55% -> 15.48%     
client [45] (testset)   loss: 6.5547 -> 6.1026  accuracy: 18.08% -> 22.60%     
client [47] (testset)   loss: 6.2471 -> 6.2848  accuracy: 17.39% -> 15.94%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 7.4762 -> 7.2826  accuracy: 19.46% -> 21.48%     
client [11] (testset)   loss: 6.6136 -> 7.0999  accuracy: 18.40% -> 15.20%     
client [37] (testset)   loss: 6.6528 -> 6.9232  accuracy: 14.84% -> 12.26%     
client [41] (testset)   loss: 6.7583 -> 6.7122  accuracy: 20.00% -> 22.63%     
client [95] (testset)   loss: 7.6022 -> 7.8610  accuracy: 18.67% -> 19.28%     
client [53] (testset)   loss: 8.2375 -> 7.8156  accuracy: 16.77% -> 12.90%     
client [22] (testset)   loss: 8.2315 -> 8.6151  accuracy: 11.49% -> 10.81%     
client [25] (testset)   loss: 6.8287 -> 7.1231  accuracy: 23.12% -> 19.35%     
client [69] (testset)   loss: 8.6000 -> 8.6267  accuracy: 17.07% -> 17.89%     
client [46] (testset)   loss: 8.8388 -> 8.5883  accuracy: 9.88% -> 11.63%      
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 6.8181 -> 7.0445  accuracy: 17.39% -> 17.39%     
client [69] (testset)   loss: 8.7438 -> 8.8764  accuracy: 17.89% -> 18.70%     
client [82] (testset)   loss: 7.7172 -> 8.0912  accuracy: 13.43% -> 11.94%     
client [45] (testset)   loss: 7.0048 -> 7.3589  accuracy: 20.34% -> 20.34%     
client [7]  (testset)   loss: 9.8482 -> 14.7678 accuracy: 8.63% -> 9.35%       
client [50] (testset)   loss: 7.2668 -> 7.3854  accuracy: 15.38% -> 14.74%     
client [35] (testset)   loss: 9.4289 -> 11.2636 accuracy: 12.20% -> 9.76%      
client [24] (testset)   loss: 9.6551 -> 14.3704 accuracy: 17.97% -> 12.50%     
client [15] (testset)   loss: 8.1574 -> 7.5395  accuracy: 17.78% -> 11.67%     
client [58] (testset)   loss: 9.0130 -> 9.3624  accuracy: 16.13% -> 15.48%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 8.4337 -> 8.7182  accuracy: 22.22% -> 20.00%     
client [76] (testset)   loss: 8.8124 -> 9.0224  accuracy: 13.01% -> 12.20%     
client [67] (testset)   loss: 7.8049 -> 8.0644  accuracy: 23.08% -> 24.26%     
client [37] (testset)   loss: 7.4278 -> 7.3062  accuracy: 12.90% -> 14.84%     
client [58] (testset)   loss: 9.4388 -> 9.4267  accuracy: 16.13% -> 16.77%     
client [64] (testset)   loss: 13.2834 -> 7.7523 accuracy: 14.75% -> 19.67%     
client [77] (testset)   loss: 7.3973 -> 7.5962  accuracy: 14.69% -> 18.18%     
client [55] (testset)   loss: 9.1393 -> 9.2718  accuracy: 18.10% -> 16.38%     
client [12] (testset)   loss: 8.4842 -> 8.7163  accuracy: 12.03% -> 13.92%     
client [89] (testset)   loss: 10.1740 -> 10.2303    accuracy: 13.57% -> 15.71% 
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 9.2655 -> 9.3792  accuracy: 15.57% -> 16.77%     
client [51] (testset)   loss: 10.1227 -> 39.7625    accuracy: 19.38% -> 14.37% 
client [8]  (testset)   loss: 9.5129 -> 9.7141  accuracy: 12.41% -> 11.72%     
client [18] (testset)   loss: 7.3210 -> 8.5412  accuracy: 17.98% -> 20.79%     
client [94] (testset)   loss: 9.5327 -> 9.4254  accuracy: 9.91% -> 9.91%       
client [81] (testset)   loss: 8.3587 -> 8.3087  accuracy: 18.23% -> 21.35%     
client [3]  (testset)   loss: 8.8048 -> 8.9443  accuracy: 19.17% -> 16.58%     
client [11] (testset)   loss: 7.5819 -> 7.7363  accuracy: 16.00% -> 17.60%     
client [95] (testset)   loss: 8.6778 -> 8.7555  accuracy: 18.67% -> 18.07%     
client [67] (testset)   loss: 8.1380 -> 8.3978  accuracy: 23.67% -> 24.26%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 10.8853 -> 11.4099    accuracy: 10.17% -> 11.86% 
client [79] (testset)   loss: 8.9915 -> 8.9595  accuracy: 21.43% -> 22.14%     
client [58] (testset)   loss: 10.2208 -> 10.2918    accuracy: 16.13% -> 16.13% 
client [88] (testset)   loss: 7.7133 -> 7.8414  accuracy: 20.31% -> 20.31%     
client [46] (testset)   loss: 10.3689 -> 10.2809    accuracy: 8.14% -> 10.47%  
client [11] (testset)   loss: 8.0685 -> 8.1451  accuracy: 17.60% -> 17.60%     
client [55] (testset)   loss: 9.9745 -> 10.1484 accuracy: 18.10% -> 17.24%     
client [13] (testset)   loss: 9.1499 -> 9.1763  accuracy: 12.59% -> 14.81%     
client [31] (testset)   loss: 10.3442 -> 10.4054    accuracy: 19.67% -> 22.13% 
client [75] (testset)   loss: 9.0897 -> 9.2369  accuracy: 10.71% -> 11.43%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 9.7401 -> 9.8273  accuracy: 18.05% -> 17.29%     
client [7]  (testset)   loss: 10.9745 -> 11.1847    accuracy: 9.35% -> 10.07%  
client [57] (testset)   loss: 8.5645 -> 8.7274  accuracy: 18.98% -> 18.98%     
client [13] (testset)   loss: 9.6644 -> 9.7363  accuracy: 15.56% -> 14.81%     
client [43] (testset)   loss: 9.8869 -> 9.9564  accuracy: 9.23% -> 9.23%       
client [91] (testset)   loss: 10.6214 -> 10.6101    accuracy: 15.03% -> 17.65% 
client [10] (testset)   loss: 9.5451 -> 9.7920  accuracy: 19.21% -> 18.64%     
client [64] (testset)   loss: 9.5352 -> 9.6235  accuracy: 18.03% -> 18.03%     
client [82] (testset)   loss: 9.4704 -> 9.5133  accuracy: 10.45% -> 11.19%     
client [22] (testset)   loss: 9.9347 -> 10.0229 accuracy: 12.16% -> 12.84%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 10.3932 -> 10.4597    accuracy: 15.44% -> 18.38% 
client [23] (testset)   loss: 10.1199 -> 10.2310    accuracy: 12.77% -> 12.77% 
client [88] (testset)   loss: 8.3187 -> 8.4038  accuracy: 22.66% -> 20.31%     
client [98] (testset)   loss: 9.3540 -> 9.5039  accuracy: 13.56% -> 14.12%     
client [79] (testset)   loss: 9.6113 -> 9.6759  accuracy: 22.86% -> 22.86%     
client [21] (testset)   loss: 12.0552 -> 12.0882    accuracy: 11.86% -> 12.71% 
client [92] (testset)   loss: 9.3006 -> 9.4493  accuracy: 15.54% -> 16.22%     
client [56] (testset)   loss: 12.1713 -> 12.2616    accuracy: 9.52% -> 10.32%  
client [5]  (testset)   loss: 9.4768 -> 9.5435  accuracy: 15.86% -> 15.17%     
client [52] (testset)   loss: 9.2235 -> 9.3081  accuracy: 20.43% -> 20.97%     
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 9.2877 -> 9.3263  accuracy: 23.08% -> 23.67%     
client [54] (testset)   loss: 10.0796 -> 10.0656    accuracy: 16.67% -> 15.97% 
client [14] (testset)   loss: 8.7578 -> 8.8636  accuracy: 22.67% -> 25.00%     
client [99] (testset)   loss: 10.3008 -> 10.3362    accuracy: 16.23% -> 16.88% 
client [36] (testset)   loss: 10.7689 -> 10.8011    accuracy: 15.04% -> 15.04% 
client [30] (testset)   loss: 10.7398 -> 10.7955    accuracy: 12.27% -> 13.50% 
client [38] (testset)   loss: 8.7372 -> 8.7523  accuracy: 24.24% -> 24.24%     
client [15] (testset)   loss: 9.5507 -> 9.7812  accuracy: 16.11% -> 17.22%     
client [6]  (testset)   loss: 12.0605 -> 12.2608    accuracy: 10.17% -> 12.71% 
client [53] (testset)   loss: 9.7036 -> 9.8268  accuracy: 15.48% -> 14.84%     
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [99] (testset)   loss: 10.9153 -> 10.9750    accuracy: 16.88% -> 17.53% 
client [6]  (testset)   loss: 13.0133 -> 13.1112    accuracy: 11.86% -> 11.86% 
client [83] (testset)   loss: 10.9203 -> 10.9259    accuracy: 15.20% -> 16.00% 
client [42] (testset)   loss: 10.4203 -> 10.4696    accuracy: 16.67% -> 17.39% 
client [34] (testset)   loss: 10.0475 -> 10.0259    accuracy: 18.40% -> 18.40% 
client [15] (testset)   loss: 10.3277 -> 10.1988    accuracy: 18.33% -> 18.89% 
client [47] (testset)   loss: 8.8496 -> 8.8798  accuracy: 15.94% -> 16.67%     
client [55] (testset)   loss: 11.5796 -> 11.4920    accuracy: 18.10% -> 17.24% 
client [51] (testset)   loss: 12.7167 -> 12.3554    accuracy: 18.75% -> 20.00% 
client [95] (testset)   loss: 10.1344 -> 10.2004    accuracy: 16.87% -> 17.47% 
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 11.6327 -> 11.6542    accuracy: 17.97% -> 17.19% 
client [15] (testset)   loss: 10.4452 -> 10.6126    accuracy: 18.33% -> 17.78% 
client [33] (testset)   loss: 10.8723 -> 10.8401    accuracy: 18.25% -> 19.84% 
client [99] (testset)   loss: 11.3701 -> 11.4337    accuracy: 16.88% -> 16.88% 
client [90] (testset)   loss: 9.2069 -> 9.1842  accuracy: 26.06% -> 25.45%     
client [57] (testset)   loss: 9.6384 -> 9.6472  accuracy: 18.25% -> 18.25%     
client [27] (testset)   loss: 10.8570 -> 10.8096    accuracy: 15.65% -> 17.39% 
client [78] (testset)   loss: 12.6196 -> 12.6205    accuracy: 16.55% -> 16.55% 
client [36] (testset)   loss: 11.9757 -> 11.9673    accuracy: 15.04% -> 14.16% 
client [88] (testset)   loss: 9.0420 -> 9.0650  accuracy: 20.31% -> 21.88%     
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 12.2393 -> 12.2585    accuracy: 15.30% -> 14.75% 
client [35] (testset)   loss: 12.7778 -> 12.8275    accuracy: 12.80% -> 12.20% 
client [16] (testset)   loss: 10.8557 -> 10.8948    accuracy: 22.82% -> 23.49% 
client [80] (testset)   loss: 10.2558 -> 10.3538    accuracy: 17.57% -> 18.24% 
client [38] (testset)   loss: 9.8376 -> 9.8588  accuracy: 24.75% -> 24.75%     
client [78] (testset)   loss: 13.0169 -> 13.0233    accuracy: 17.27% -> 17.27% 
client [68] (testset)   loss: 10.4758 -> 10.3565    accuracy: 15.04% -> 15.79% 
client [11] (testset)   loss: 9.8510 -> 9.8761  accuracy: 16.00% -> 16.00%     
client [64] (testset)   loss: 10.9138 -> 10.9485    accuracy: 17.49% -> 16.94% 
client [82] (testset)   loss: 10.9595 -> 10.9774    accuracy: 10.45% -> 11.19% 
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 11.8722 -> 11.9239    accuracy: 12.27% -> 12.88% 
client [27] (testset)   loss: 10.7260 -> 10.7879    accuracy: 18.26% -> 17.39% 
client [74] (testset)   loss: 9.4784 -> 9.5853  accuracy: 20.97% -> 20.16%     
client [45] (testset)   loss: 9.2849 -> 9.3259  accuracy: 19.77% -> 20.90%     
client [6]  (testset)   loss: 13.5340 -> 13.5652    accuracy: 11.86% -> 11.86% 
client [36] (testset)   loss: 11.8654 -> 11.8786    accuracy: 15.93% -> 15.93% 
client [63] (testset)   loss: 10.6547 -> 10.7290    accuracy: 16.09% -> 16.09% 
client [76] (testset)   loss: 11.4227 -> 11.4358    accuracy: 12.20% -> 12.20% 
client [83] (testset)   loss: 11.2037 -> 11.2946    accuracy: 14.40% -> 14.40% 
client [86] (testset)   loss: 10.7558 -> 10.8260    accuracy: 19.23% -> 19.23% 
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 11.6640 -> 11.6776    accuracy: 16.00% -> 15.20% 
client [99] (testset)   loss: 11.6880 -> 11.7634    accuracy: 17.53% -> 17.53% 
client [74] (testset)   loss: 9.8979 -> 9.9281  accuracy: 20.16% -> 20.16%     
client [73] (testset)   loss: 11.5886 -> 11.6504    accuracy: 14.77% -> 14.77% 
client [29] (testset)   loss: 12.6424 -> 12.6190    accuracy: 16.67% -> 16.05% 
client [92] (testset)   loss: 10.6073 -> 10.6616    accuracy: 15.54% -> 15.54% 
client [6]  (testset)   loss: 13.9740 -> 14.0115    accuracy: 11.86% -> 11.86% 
client [61] (testset)   loss: 10.4589 -> 10.4837    accuracy: 16.38% -> 16.38% 
client [21] (testset)   loss: 13.6058 -> 13.5971    accuracy: 11.02% -> 11.86% 
client [67] (testset)   loss: 10.5174 -> 10.5608    accuracy: 23.08% -> 23.08% 
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 11.9233 -> 11.9247    accuracy: 14.40% -> 14.40% 
client [32] (testset)   loss: 10.6485 -> 10.6724    accuracy: 23.62% -> 23.62% 
client [95] (testset)   loss: 11.1477 -> 11.1240    accuracy: 15.06% -> 17.47% 
client [61] (testset)   loss: 10.6691 -> 10.7000    accuracy: 18.08% -> 18.08% 
client [27] (testset)   loss: 11.4071 -> 11.3768    accuracy: 16.52% -> 17.39% 
client [25] (testset)   loss: 10.4720 -> 10.5593    accuracy: 20.43% -> 18.82% 
client [68] (testset)   loss: 10.5351 -> 10.6025    accuracy: 17.29% -> 17.29% 
client [34] (testset)   loss: 10.9500 -> 10.9646    accuracy: 20.80% -> 20.80% 
client [71] (testset)   loss: 12.2570 -> 12.2637    accuracy: 17.19% -> 17.97% 
client [89] (testset)   loss: 13.4626 -> 13.4548    accuracy: 14.29% -> 14.29% 
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 13.1320 -> 13.1136    accuracy: 17.99% -> 17.27% 
client [81] (testset)   loss: 10.6830 -> 10.7224    accuracy: 19.27% -> 19.27% 
client [51] (testset)   loss: 13.4386 -> 13.3363    accuracy: 18.75% -> 18.75% 
client [54] (testset)   loss: 11.4400 -> 11.5123    accuracy: 15.97% -> 16.67% 
client [65] (testset)   loss: 10.6900 -> 10.7369    accuracy: 20.69% -> 21.38% 
client [41] (testset)   loss: 9.5912 -> 9.6403  accuracy: 22.11% -> 22.11%     
client [11] (testset)   loss: 9.9208 -> 9.9688  accuracy: 16.80% -> 16.80%     
client [85] (testset)   loss: 13.1961 -> 13.2478    accuracy: 12.42% -> 12.42% 
client [12] (testset)   loss: 11.5958 -> 11.6389    accuracy: 12.66% -> 13.29% 
client [23] (testset)   loss: 11.8399 -> 11.9375    accuracy: 14.89% -> 14.18% 
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 11.2891 -> 11.7419    accuracy: 24.16% -> 18.79% 
client [65] (testset)   loss: 11.0029 -> 11.0419    accuracy: 20.69% -> 20.69% 
client [53] (testset)   loss: 11.4929 -> 11.5134    accuracy: 14.84% -> 14.84% 
client [58] (testset)   loss: 12.9571 -> 12.9682    accuracy: 14.84% -> 14.84% 
client [72] (testset)   loss: 11.4347 -> 11.4868    accuracy: 12.26% -> 12.26% 
client [7]  (testset)   loss: 12.9987 -> 13.1274    accuracy: 8.63% -> 9.35%   
client [71] (testset)   loss: 12.5075 -> 12.5010    accuracy: 17.97% -> 17.19% 
client [59] (testset)   loss: 11.6109 -> 11.6229    accuracy: 19.63% -> 19.02% 
client [86] (testset)   loss: 11.6465 -> 11.6866    accuracy: 17.95% -> 19.23% 
client [39] (testset)   loss: 12.4359 -> 12.4620    accuracy: 13.87% -> 13.87% 
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 12.4376 -> 12.4413    accuracy: 16.88% -> 16.23% 
client [7]  (testset)   loss: 13.2896 -> 13.3040    accuracy: 8.63% -> 8.63%   
client [17] (testset)   loss: 11.7253 -> 11.7438    accuracy: 14.49% -> 14.49% 
client [64] (testset)   loss: 11.6623 -> 11.6469    accuracy: 18.03% -> 17.49% 
client [37] (testset)   loss: 10.3199 -> 10.3375    accuracy: 13.55% -> 12.26% 
client [29] (testset)   loss: 13.2813 -> 13.3040    accuracy: 15.43% -> 15.43% 
client [93] (testset)   loss: 12.9685 -> 13.0167    accuracy: 12.32% -> 12.32% 
client [73] (testset)   loss: 12.4161 -> 12.4459    accuracy: 15.34% -> 15.34% 
client [40] (testset)   loss: 10.8170 -> 10.8048    accuracy: 16.67% -> 16.67% 
client [76] (testset)   loss: 12.6480 -> 12.6811    accuracy: 12.20% -> 10.57% 
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 13.5041 -> 13.5104    accuracy: 24.59% -> 23.77% 
client [89] (testset)   loss: 14.2425 -> 14.2463    accuracy: 15.00% -> 15.71% 
client [77] (testset)   loss: 10.7872 -> 10.8067    accuracy: 16.08% -> 15.38% 
client [90] (testset)   loss: 10.2596 -> 10.2941    accuracy: 27.27% -> 26.67% 
client [26] (testset)   loss: 12.1089 -> 12.1364    accuracy: 15.07% -> 15.07% 
client [50] (testset)   loss: 10.6582 -> 10.6869    accuracy: 15.38% -> 15.38% 
client [30] (testset)   loss: 13.3260 -> 13.3522    accuracy: 14.11% -> 14.11% 
client [70] (testset)   loss: 13.1377 -> 13.1574    accuracy: 15.30% -> 15.85% 
client [41] (testset)   loss: 10.2293 -> 10.2365    accuracy: 22.11% -> 22.11% 
client [99] (testset)   loss: 12.6622 -> 12.7037    accuracy: 16.23% -> 16.88% 
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [68] (testset)   loss: 11.4664 -> 11.4752    accuracy: 16.54% -> 17.29% 
client [70] (testset)   loss: 13.3410 -> 13.3734    accuracy: 15.85% -> 15.30% 
client [52] (testset)   loss: 11.3578 -> 11.3946    accuracy: 20.43% -> 19.89% 
client [1]  (testset)   loss: 12.6037 -> 12.6321    accuracy: 14.60% -> 14.60% 
client [2]  (testset)   loss: 11.4990 -> 11.5368    accuracy: 18.44% -> 18.99% 
client [67] (testset)   loss: 11.6533 -> 11.6768    accuracy: 23.08% -> 23.08% 
client [92] (testset)   loss: 11.7982 -> 11.8178    accuracy: 15.54% -> 15.54% 
client [35] (testset)   loss: 14.0317 -> 14.0563    accuracy: 12.80% -> 12.80% 
client [36] (testset)   loss: 13.4957 -> 13.4950    accuracy: 16.81% -> 16.81% 
client [64] (testset)   loss: 12.0442 -> 12.0511    accuracy: 18.03% -> 17.49% 
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 10.8181 -> 10.7880    accuracy: 22.15% -> 22.82% 
client [6]  (testset)   loss: 15.6115 -> 15.6319    accuracy: 11.02% -> 11.02% 
client [12] (testset)   loss: 12.7060 -> 12.7293    accuracy: 13.29% -> 13.29% 
client [55] (testset)   loss: 13.7325 -> 13.7406    accuracy: 17.24% -> 17.24% 
client [29] (testset)   loss: 13.9062 -> 13.9222    accuracy: 15.43% -> 15.43% 
client [9]  (testset)   loss: 13.4729 -> 13.4865    accuracy: 9.72% -> 9.72%   
client [43] (testset)   loss: 12.6818 -> 12.6961    accuracy: 8.46% -> 8.46%   
client [77] (testset)   loss: 11.1123 -> 11.1272    accuracy: 15.38% -> 15.38% 
client [98] (testset)   loss: 11.8462 -> 11.8712    accuracy: 15.82% -> 15.25% 
client [78] (testset)   loss: 14.4527 -> 14.4527    accuracy: 16.55% -> 16.55% 
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 12.1239 -> 12.1457    accuracy: 14.86% -> 14.19% 
client [80] (testset)   loss: 11.6484 -> 11.6531    accuracy: 18.24% -> 18.24% 
client [63] (testset)   loss: 12.3915 -> 12.4163    accuracy: 17.24% -> 17.24% 
client [76] (testset)   loss: 13.5069 -> 13.5214    accuracy: 10.57% -> 10.57% 
client [78] (testset)   loss: 14.6537 -> 14.5987    accuracy: 16.55% -> 16.55% 
client [25] (testset)   loss: 11.6311 -> 11.6762    accuracy: 19.35% -> 19.89% 
client [58] (testset)   loss: 14.0278 -> 14.0298    accuracy: 14.84% -> 14.19% 
client [13] (testset)   loss: 12.3468 -> 12.3652    accuracy: 14.81% -> 14.81% 
client [17] (testset)   loss: 12.4598 -> 12.4762    accuracy: 14.49% -> 13.77% 
client [38] (testset)   loss: 11.1081 -> 11.1166    accuracy: 24.75% -> 23.74% 
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 12.5815 -> 12.6058    accuracy: 11.61% -> 11.61% 
client [82] (testset)   loss: 12.5209 -> 12.5175    accuracy: 10.45% -> 10.45% 
client [86] (testset)   loss: 12.8321 -> 12.8411    accuracy: 17.95% -> 17.95% 
client [51] (testset)   loss: 15.0553 -> 15.0605    accuracy: 18.75% -> 18.75% 
client [96] (testset)   loss: 13.9996 -> 14.0112    accuracy: 13.55% -> 13.55% 
client [42] (testset)   loss: 12.6613 -> 12.6736    accuracy: 17.39% -> 17.39% 
client [55] (testset)   loss: 14.1021 -> 14.1099    accuracy: 17.24% -> 17.24% 
client [13] (testset)   loss: 12.4960 -> 12.5152    accuracy: 14.81% -> 14.81% 
client [1]  (testset)   loss: 13.1044 -> 13.1203    accuracy: 14.60% -> 14.60% 
client [12] (testset)   loss: 13.0142 -> 13.0233    accuracy: 13.29% -> 13.29% 
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 12.0522 -> 12.0770    accuracy: 16.54% -> 16.54% 
client [23] (testset)   loss: 13.6573 -> 13.7092    accuracy: 14.18% -> 14.18% 
client [46] (testset)   loss: 14.3846 -> 14.4310    accuracy: 8.72% -> 8.72%   
client [41] (testset)   loss: 10.8696 -> 10.8961    accuracy: 21.58% -> 21.58% 
client [25] (testset)   loss: 11.9011 -> 11.9346    accuracy: 19.89% -> 19.89% 
client [58] (testset)   loss: 14.3339 -> 14.3372    accuracy: 14.84% -> 14.19% 
client [14] (testset)   loss: 11.5271 -> 11.5380    accuracy: 22.09% -> 20.93% 
client [33] (testset)   loss: 13.1221 -> 13.1262    accuracy: 20.63% -> 20.63% 
client [85] (testset)   loss: 15.0789 -> 15.0979    accuracy: 13.04% -> 13.04% 
client [62] (testset)   loss: 12.7585 -> 12.7702    accuracy: 17.75% -> 17.75% 
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 12.4033 -> 12.4201    accuracy: 15.25% -> 14.69% 
client [63] (testset)   loss: 12.8001 -> 12.7932    accuracy: 16.09% -> 16.67% 
client [70] (testset)   loss: 14.1937 -> 14.1810    accuracy: 15.85% -> 16.39% 
client [65] (testset)   loss: 12.3539 -> 12.3714    accuracy: 21.38% -> 21.38% 
client [14] (testset)   loss: 11.6426 -> 11.6606    accuracy: 21.51% -> 22.09% 
client [73] (testset)   loss: 13.6101 -> 13.6285    accuracy: 15.34% -> 15.34% 
client [34] (testset)   loss: 12.5046 -> 12.5050    accuracy: 20.80% -> 20.80% 
client [99] (testset)   loss: 13.6584 -> 13.6691    accuracy: 16.88% -> 16.88% 
client [69] (testset)   loss: 13.8838 -> 13.8879    accuracy: 17.07% -> 17.07% 
client [46] (testset)   loss: 14.5377 -> 14.5649    accuracy: 8.72% -> 8.72%   
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [99] (testset)   loss: 13.8075 -> 13.7898    accuracy: 16.23% -> 16.88% 
client [93] (testset)   loss: 14.4480 -> 14.4569    accuracy: 11.59% -> 11.59% 
client [11] (testset)   loss: 11.5437 -> 11.5583    accuracy: 15.20% -> 15.20% 
client [58] (testset)   loss: 14.5988 -> 14.6011    accuracy: 14.19% -> 14.19% 
client [81] (testset)   loss: 12.4552 -> 12.4629    accuracy: 19.79% -> 19.79% 
client [85] (testset)   loss: 15.3745 -> 15.3796    accuracy: 13.04% -> 13.04% 
client [89] (testset)   loss: 15.4521 -> 15.4648    accuracy: 15.71% -> 15.71% 
client [45] (testset)   loss: 11.2659 -> 11.2739    accuracy: 22.03% -> 22.03% 
client [8]  (testset)   loss: 14.4245 -> 14.4267    accuracy: 10.34% -> 10.34% 
client [68] (testset)   loss: 12.2980 -> 12.3122    accuracy: 15.04% -> 15.04% 
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 12.5884 -> 12.5929    accuracy: 22.49% -> 22.49% 
client [72] (testset)   loss: 13.0756 -> 13.0974    accuracy: 10.97% -> 10.97% 
client [1]  (testset)   loss: 13.6226 -> 13.6258    accuracy: 14.60% -> 14.60% 
client [78] (testset)   loss: 15.3580 -> 15.3506    accuracy: 16.55% -> 16.55% 
client [83] (testset)   loss: 13.9368 -> 13.9517    accuracy: 15.20% -> 15.20% 
client [21] (testset)   loss: 16.3643 -> 16.3827    accuracy: 10.17% -> 10.17% 
client [56] (testset)   loss: 16.4405 -> 16.4481    accuracy: 9.52% -> 9.52%   
client [44] (testset)   loss: 11.4767 -> 11.4869    accuracy: 21.48% -> 22.82% 
client [92] (testset)   loss: 12.7506 -> 12.7642    accuracy: 14.19% -> 14.19% 
client [27] (testset)   loss: 13.2413 -> 13.2491    accuracy: 17.39% -> 17.39% 
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 13.0349 -> 13.0516    accuracy: 21.47% -> 20.90% 
client [39] (testset)   loss: 14.4053 -> 14.4033    accuracy: 13.87% -> 13.87% 
client [65] (testset)   loss: 12.6598 -> 12.6750    accuracy: 21.38% -> 21.38% 
client [26] (testset)   loss: 13.4211 -> 13.4373    accuracy: 15.07% -> 15.07% 
client [19] (testset)   loss: 13.5756 -> 13.5805    accuracy: 18.05% -> 18.05% 
client [68] (testset)   loss: 12.4994 -> 12.5136    accuracy: 14.29% -> 14.29% 
client [41] (testset)   loss: 11.2440 -> 11.2472    accuracy: 21.58% -> 21.58% 
client [50] (testset)   loss: 11.8210 -> 11.8317    accuracy: 15.38% -> 15.38% 
client [75] (testset)   loss: 13.1959 -> 13.2003    accuracy: 11.43% -> 11.43% 
client [81] (testset)   loss: 12.6636 -> 12.6840    accuracy: 19.79% -> 19.79% 
Training... ---------------------------------------- 100% 0:13:28
FedRep's average time taken by each global epoch: 0 min 2.01 sec.              
FedRep's total running time: 0 h 13 m 28 s.                                    
==================== FedRep Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "6.0614 -> 0.0000",                                    
                "accuracy": "15.47% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "10.1153 -> 0.0000",                                   
                "accuracy": "16.84% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "11.9867 -> 0.0000",                                   
                "accuracy": "16.80% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "13.4620 -> 0.0000",                                   
                "accuracy": "16.52% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedRep Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 16.84% at epoch 200                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
[0m