==================== FedAvg ====================                               
Experiment Arguments:                                                          
{
â”‚   'method': 'fedavg',
â”‚   'dataset': {
â”‚   â”‚   'name': 'cifar100',
â”‚   â”‚   'client_num': 100,
â”‚   â”‚   'test_ratio': 0.25,
â”‚   â”‚   'val_ratio': 0.0,
â”‚   â”‚   'seed': 42,
â”‚   â”‚   'split': 'sample',
â”‚   â”‚   'IID_ratio': 0.0,
â”‚   â”‚   'monitor_window_name_suffix': 'cifar100-100clients-0%IID-use20superclasses-Dir(0.5)-seed42',
â”‚   â”‚   'super_class': False,
â”‚   â”‚   'alpha': 0.5,
â”‚   â”‚   'min_samples_per_client': 10
â”‚   },
â”‚   'model': {
â”‚   â”‚   'name': 'avgcnn',
â”‚   â”‚   'use_torchvision_pretrained_weights': True,
â”‚   â”‚   'external_model_weights_path': None
â”‚   },
â”‚   'optimizer': {
â”‚   â”‚   'lr': 0.01,
â”‚   â”‚   'dampening': 0,
â”‚   â”‚   'weight_decay': 0,
â”‚   â”‚   'momentum': 0,
â”‚   â”‚   'nesterov': False,
â”‚   â”‚   'name': 'sgd'
â”‚   },
â”‚   'mode': 'serial',
â”‚   'parallel': {
â”‚   â”‚   'ray_cluster_addr': None,
â”‚   â”‚   'num_cpus': None,
â”‚   â”‚   'num_gpus': None,
â”‚   â”‚   'num_workers': 2
â”‚   },
â”‚   'common': {
â”‚   â”‚   'seed': 42,
â”‚   â”‚   'join_ratio': 0.1,
â”‚   â”‚   'global_epoch': 400,
â”‚   â”‚   'local_epoch': 5,
â”‚   â”‚   'batch_size': 32,
â”‚   â”‚   'reset_optimizer_on_global_epoch': True,
â”‚   â”‚   'straggler_ratio': 0,
â”‚   â”‚   'straggler_min_local_epoch': 0,
â”‚   â”‚   'buffers': 'global',
â”‚   â”‚   'client_side_evaluation': True,
â”‚   â”‚   'test': {
â”‚   â”‚   â”‚   'client': {
â”‚   â”‚   â”‚   â”‚   'interval': 100,
â”‚   â”‚   â”‚   â”‚   'finetune_epoch': 0,
â”‚   â”‚   â”‚   â”‚   'train': False,
â”‚   â”‚   â”‚   â”‚   'val': False,
â”‚   â”‚   â”‚   â”‚   'test': True
â”‚   â”‚   â”‚   },
â”‚   â”‚   â”‚   'server': {
â”‚   â”‚   â”‚   â”‚   'interval': -1,
â”‚   â”‚   â”‚   â”‚   'train': False,
â”‚   â”‚   â”‚   â”‚   'val': False,
â”‚   â”‚   â”‚   â”‚   'test': False,
â”‚   â”‚   â”‚   â”‚   'model_in_train_mode': False
â”‚   â”‚   â”‚   }
â”‚   â”‚   },
â”‚   â”‚   'verbose_gap': 10,
â”‚   â”‚   'monitor': None,
â”‚   â”‚   'use_cuda': True,
â”‚   â”‚   'save_log': True,
â”‚   â”‚   'save_model': False,
â”‚   â”‚   'save_learning_curve_plot': False,
â”‚   â”‚   'save_metrics': True,
â”‚   â”‚   'delete_useless_run': True
â”‚   }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 3.9566 -> 3.6565  accuracy: 7.69% -> 11.19%      
client [81] (testset)   loss: 3.7580 -> 4.4479  accuracy: 14.58% -> 9.38%      
client [21] (testset)   loss: 3.9053 -> 4.8457  accuracy: 10.17% -> 7.63%      
client [68] (testset)   loss: 3.8289 -> 3.5057  accuracy: 12.03% -> 19.55%     
client [93] (testset)   loss: 4.0651 -> 3.6778  accuracy: 8.70% -> 18.12%      
client [31] (testset)   loss: 3.8813 -> 3.6311  accuracy: 10.66% -> 16.39%     
client [20] (testset)   loss: 3.6274 -> 3.5615  accuracy: 14.71% -> 19.12%     
client [59] (testset)   loss: 4.0862 -> 3.6584  accuracy: 9.20% -> 15.95%      
client [48] (testset)   loss: 3.9532 -> 3.7629  accuracy: 7.41% -> 11.11%      
client [34] (testset)   loss: 3.8904 -> 3.5604  accuracy: 12.00% -> 20.00%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 3.3947 -> 3.3869  accuracy: 21.95% -> 26.02%     
client [99] (testset)   loss: 3.6879 -> 3.9929  accuracy: 16.88% -> 12.99%     
client [67] (testset)   loss: 3.5374 -> 3.5908  accuracy: 17.16% -> 16.57%     
client [0]  (testset)   loss: 3.5240 -> 5.0893  accuracy: 18.39% -> 13.22%     
client [76] (testset)   loss: 3.5379 -> 3.7425  accuracy: 21.14% -> 14.63%     
client [41] (testset)   loss: 3.5899 -> 3.2994  accuracy: 15.26% -> 23.68%     
client [62] (testset)   loss: 3.8430 -> 3.4795  accuracy: 10.65% -> 20.12%     
client [2]  (testset)   loss: 3.5421 -> 3.6029  accuracy: 18.99% -> 14.53%     
client [14] (testset)   loss: 3.3546 -> 4.5647  accuracy: 25.00% -> 12.79%     
client [46] (testset)   loss: 3.7109 -> 4.5868  accuracy: 15.12% -> 12.21%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 3.7347 -> 6.5563  accuracy: 17.97% -> 7.81%      
client [68] (testset)   loss: 3.3590 -> 3.5487  accuracy: 18.80% -> 27.07%     
client [57] (testset)   loss: 3.4691 -> 3.5794  accuracy: 21.17% -> 21.17%     
client [17] (testset)   loss: 3.4295 -> 3.4935  accuracy: 18.84% -> 22.46%     
client [54] (testset)   loss: 3.5302 -> 3.5730  accuracy: 19.44% -> 24.31%     
client [23] (testset)   loss: 3.6807 -> 4.5777  accuracy: 19.15% -> 13.48%     
client [35] (testset)   loss: 3.6125 -> 3.9989  accuracy: 16.46% -> 19.51%     
client [59] (testset)   loss: 3.4735 -> 4.0823  accuracy: 26.99% -> 22.70%     
client [31] (testset)   loss: 3.0897 -> 3.5038  accuracy: 28.69% -> 24.59%     
client [9]  (testset)   loss: 3.9053 -> 4.0056  accuracy: 13.19% -> 21.53%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 3.7139 -> 3.7452  accuracy: 25.14% -> 20.77%     
client [33] (testset)   loss: 3.6224 -> 3.6563  accuracy: 22.22% -> 23.02%     
client [16] (testset)   loss: 3.7037 -> 3.6457  accuracy: 15.44% -> 26.85%     
client [44] (testset)   loss: 3.3587 -> 7.0006  accuracy: 22.82% -> 13.42%     
client [8]  (testset)   loss: 3.7898 -> 4.1276  accuracy: 22.76% -> 22.07%     
client [31] (testset)   loss: 3.4034 -> 3.4150  accuracy: 25.41% -> 30.33%     
client [47] (testset)   loss: 3.5521 -> 3.4197  accuracy: 18.84% -> 26.09%     
client [36] (testset)   loss: 3.2947 -> 3.9630  accuracy: 24.78% -> 25.66%     
client [20] (testset)   loss: 3.4426 -> 3.9261  accuracy: 24.26% -> 22.79%     
client [56] (testset)   loss: 3.6864 -> 4.0397  accuracy: 21.43% -> 26.19%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 3.2477 -> 4.2850  accuracy: 30.83% -> 21.67%     
client [60] (testset)   loss: 3.6063 -> 4.1443  accuracy: 20.49% -> 29.51%     
client [28] (testset)   loss: 3.9025 -> 4.0924  accuracy: 20.61% -> 27.27%     
client [25] (testset)   loss: 3.8793 -> 4.1557  accuracy: 20.97% -> 23.12%     
client [58] (testset)   loss: 3.8296 -> 4.2821  accuracy: 20.00% -> 23.87%     
client [44] (testset)   loss: 3.4436 -> 3.7537  accuracy: 21.48% -> 20.81%     
client [39] (testset)   loss: 3.6497 -> 3.9562  accuracy: 18.98% -> 27.01%     
client [29] (testset)   loss: 3.6825 -> 4.2658  accuracy: 20.99% -> 26.54%     
client [3]  (testset)   loss: 3.7756 -> 4.0399  accuracy: 19.17% -> 26.94%     
client [84] (testset)   loss: 3.7819 -> 4.2161  accuracy: 25.75% -> 25.75%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 3.6321 -> 4.3976  accuracy: 25.42% -> 24.58%     
client [84] (testset)   loss: 3.8237 -> 4.1919  accuracy: 20.36% -> 27.54%     
client [10] (testset)   loss: 3.6181 -> 3.6399  accuracy: 21.47% -> 31.07%     
client [36] (testset)   loss: 3.3576 -> 3.7394  accuracy: 25.66% -> 25.66%     
client [65] (testset)   loss: 3.6132 -> 4.2545  accuracy: 24.14% -> 29.66%     
client [81] (testset)   loss: 3.5966 -> 4.7105  accuracy: 23.44% -> 22.92%     
client [79] (testset)   loss: 3.4323 -> 3.7859  accuracy: 23.57% -> 29.29%     
client [42] (testset)   loss: 3.6006 -> 3.4794  accuracy: 26.09% -> 32.61%     
client [11] (testset)   loss: 3.5413 -> 3.4619  accuracy: 25.60% -> 28.80%     
client [96] (testset)   loss: 3.6706 -> 3.9988  accuracy: 26.45% -> 27.10%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 4.0211 -> 4.2201  accuracy: 20.69% -> 22.76%     
client [53] (testset)   loss: 3.9581 -> 3.8703  accuracy: 17.42% -> 23.87%     
client [52] (testset)   loss: 3.7439 -> 3.7587  accuracy: 22.04% -> 30.65%     
client [42] (testset)   loss: 3.6076 -> 3.4286  accuracy: 24.64% -> 31.88%     
client [69] (testset)   loss: 3.3183 -> 4.0749  accuracy: 29.27% -> 28.46%     
client [59] (testset)   loss: 3.5479 -> 3.8868  accuracy: 29.45% -> 32.52%     
client [7]  (testset)   loss: 3.7680 -> 4.2428  accuracy: 20.86% -> 24.46%     
client [26] (testset)   loss: 3.9815 -> 3.7715  accuracy: 16.44% -> 32.19%     
client [49] (testset)   loss: 3.5312 -> 3.6319  accuracy: 25.45% -> 27.27%     
client [98] (testset)   loss: 3.5826 -> 3.8250  accuracy: 22.03% -> 27.12%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 3.9561 -> 3.8264  accuracy: 19.21% -> 29.94%     
client [47] (testset)   loss: 3.6890 -> 3.6807  accuracy: 22.46% -> 23.91%     
client [21] (testset)   loss: 3.6610 -> 4.3565  accuracy: 27.97% -> 27.12%     
client [77] (testset)   loss: 3.9288 -> 4.0437  accuracy: 19.58% -> 20.28%     
client [95] (testset)   loss: 3.7619 -> 4.0686  accuracy: 18.67% -> 23.49%     
client [91] (testset)   loss: 3.7199 -> 4.2142  accuracy: 26.14% -> 28.76%     
client [14] (testset)   loss: 3.6423 -> 3.9369  accuracy: 27.91% -> 26.74%     
client [99] (testset)   loss: 3.8989 -> 4.1613  accuracy: 16.23% -> 23.38%     
client [20] (testset)   loss: 3.5123 -> 4.1985  accuracy: 25.74% -> 22.79%     
client [39] (testset)   loss: 3.4705 -> 3.9553  accuracy: 21.90% -> 27.01%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 3.7237 -> 3.9546  accuracy: 22.04% -> 28.49%     
client [62] (testset)   loss: 3.7734 -> 3.8609  accuracy: 19.53% -> 28.99%     
client [71] (testset)   loss: 3.3708 -> 6.7193  accuracy: 28.12% -> 14.84%     
client [97] (testset)   loss: 3.8280 -> 3.6276  accuracy: 21.52% -> 31.65%     
client [30] (testset)   loss: 3.4759 -> 3.9954  accuracy: 25.77% -> 27.61%     
client [88] (testset)   loss: 3.3051 -> 3.3088  accuracy: 25.00% -> 32.81%     
client [60] (testset)   loss: 3.4457 -> 3.9599  accuracy: 21.31% -> 37.70%     
client [82] (testset)   loss: 3.8104 -> 3.9665  accuracy: 23.13% -> 29.85%     
client [91] (testset)   loss: 3.6418 -> 4.2393  accuracy: 29.41% -> 29.41%     
client [57] (testset)   loss: 3.5977 -> 3.6433  accuracy: 22.63% -> 27.01%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 3.3390 -> 3.3896  accuracy: 29.51% -> 37.70%     
client [15] (testset)   loss: 3.6870 -> 4.0226  accuracy: 20.56% -> 27.78%     
client [71] (testset)   loss: 3.4082 -> 3.9864  accuracy: 29.69% -> 25.00%     
client [97] (testset)   loss: 3.8926 -> 3.7908  accuracy: 20.89% -> 31.01%     
client [53] (testset)   loss: 4.1249 -> 4.0348  accuracy: 12.90% -> 25.16%     
client [77] (testset)   loss: 3.8849 -> 3.9351  accuracy: 22.38% -> 20.98%     
client [76] (testset)   loss: 3.4803 -> 3.8442  accuracy: 28.46% -> 21.95%     
client [79] (testset)   loss: 3.4662 -> 3.6925  accuracy: 30.00% -> 33.57%     
client [28] (testset)   loss: 3.9342 -> 4.2475  accuracy: 22.42% -> 32.73%     
client [99] (testset)   loss: 3.9548 -> 4.1799  accuracy: 18.83% -> 25.32%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 3.7236 -> 3.8028  accuracy: 25.32% -> 31.01%     
client [86] (testset)   loss: 3.5861 -> 3.9499  accuracy: 27.56% -> 33.97%     
client [34] (testset)   loss: 3.9959 -> 4.4282  accuracy: 22.40% -> 31.20%     
client [73] (testset)   loss: 3.5889 -> 4.1970  accuracy: 25.57% -> 26.14%     
client [5]  (testset)   loss: 3.6878 -> 3.9405  accuracy: 22.07% -> 26.90%     
client [96] (testset)   loss: 3.9118 -> 4.0721  accuracy: 25.81% -> 26.45%     
client [22] (testset)   loss: 4.3339 -> 4.3747  accuracy: 18.92% -> 18.92%     
client [60] (testset)   loss: 3.5600 -> 3.9271  accuracy: 25.41% -> 33.61%     
client [66] (testset)   loss: 3.9401 -> 4.3134  accuracy: 20.47% -> 22.81%     
client [83] (testset)   loss: 4.0229 -> 4.1342  accuracy: 22.40% -> 28.00%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 3.7877 -> 3.7967  accuracy: 23.58% -> 25.20%     
client [65] (testset)   loss: 4.0205 -> 4.3322  accuracy: 22.07% -> 32.41%     
client [95] (testset)   loss: 3.8506 -> 4.0195  accuracy: 22.29% -> 24.10%     
client [17] (testset)   loss: 3.7641 -> 3.7809  accuracy: 20.29% -> 34.78%     
client [8]  (testset)   loss: 4.1495 -> 4.4251  accuracy: 19.31% -> 27.59%     
client [35] (testset)   loss: 4.1669 -> 4.1987  accuracy: 23.17% -> 28.66%     
client [98] (testset)   loss: 3.7970 -> 3.7013  accuracy: 24.86% -> 31.07%     
client [53] (testset)   loss: 4.1249 -> 4.0728  accuracy: 13.55% -> 26.45%     
client [43] (testset)   loss: 4.1199 -> 4.3738  accuracy: 23.08% -> 26.15%     
client [64] (testset)   loss: 4.0841 -> 3.6898  accuracy: 25.14% -> 30.60%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 3.6985 -> 4.4733  accuracy: 29.66% -> 27.97%     
client [88] (testset)   loss: 3.3799 -> 3.1699  accuracy: 33.59% -> 32.81%     
client [38] (testset)   loss: 3.8404 -> 3.7868  accuracy: 22.73% -> 34.85%     
client [3]  (testset)   loss: 4.0427 -> 4.3867  accuracy: 24.35% -> 26.94%     
client [5]  (testset)   loss: 3.7861 -> 3.8786  accuracy: 22.07% -> 26.90%     
client [41] (testset)   loss: 3.5624 -> 3.5764  accuracy: 31.58% -> 34.21%     
client [7]  (testset)   loss: 3.9778 -> 4.4236  accuracy: 23.02% -> 25.18%     
client [37] (testset)   loss: 4.2268 -> 3.8664  accuracy: 22.58% -> 29.03%     
client [45] (testset)   loss: 3.6752 -> 3.6783  accuracy: 22.03% -> 33.90%     
client [47] (testset)   loss: 3.4718 -> 3.5457  accuracy: 28.26% -> 31.88%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 3.8919 -> 4.0651  accuracy: 23.49% -> 31.54%     
client [11] (testset)   loss: 3.6490 -> 3.6167  accuracy: 28.00% -> 34.40%     
client [37] (testset)   loss: 4.0306 -> 3.9775  accuracy: 23.23% -> 27.10%     
client [41] (testset)   loss: 3.4726 -> 3.5125  accuracy: 28.42% -> 33.68%     
client [95] (testset)   loss: 3.9284 -> 3.9882  accuracy: 21.69% -> 27.11%     
client [53] (testset)   loss: 4.1530 -> 3.9068  accuracy: 14.19% -> 26.45%     
client [22] (testset)   loss: 4.3899 -> 4.4216  accuracy: 20.27% -> 22.97%     
client [25] (testset)   loss: 3.9402 -> 4.2541  accuracy: 24.73% -> 34.41%     
client [69] (testset)   loss: 3.7356 -> 4.0465  accuracy: 26.83% -> 30.08%     
client [46] (testset)   loss: 3.5996 -> 4.3657  accuracy: 28.49% -> 26.74%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 3.6166 -> 3.5681  accuracy: 26.81% -> 31.16%     
client [69] (testset)   loss: 3.8065 -> 3.9961  accuracy: 25.20% -> 30.89%     
client [82] (testset)   loss: 4.1995 -> 4.3290  accuracy: 20.90% -> 29.85%     
client [45] (testset)   loss: 3.8239 -> 3.8643  accuracy: 24.29% -> 30.51%     
client [7]  (testset)   loss: 3.9441 -> 3.9900  accuracy: 22.30% -> 29.50%     
client [50] (testset)   loss: 3.8344 -> 3.9331  accuracy: 27.56% -> 32.69%     
client [35] (testset)   loss: 4.0887 -> 4.2510  accuracy: 25.00% -> 25.61%     
client [24] (testset)   loss: 4.4818 -> 4.4002  accuracy: 24.22% -> 25.78%     
client [15] (testset)   loss: 3.7516 -> 3.9969  accuracy: 27.22% -> 27.78%     
client [58] (testset)   loss: 3.6542 -> 4.0183  accuracy: 23.87% -> 33.55%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 4.1034 -> 4.0301  accuracy: 25.19% -> 31.85%     
client [76] (testset)   loss: 3.7872 -> 4.1203  accuracy: 26.02% -> 27.64%     
client [67] (testset)   loss: 3.4215 -> 3.7307  accuracy: 33.14% -> 37.28%     
client [37] (testset)   loss: 4.0132 -> 3.8655  accuracy: 23.87% -> 29.68%     
client [58] (testset)   loss: 3.6653 -> 4.1114  accuracy: 23.23% -> 31.61%     
client [64] (testset)   loss: 4.0591 -> 3.9719  accuracy: 24.59% -> 32.79%     
client [77] (testset)   loss: 4.2359 -> 4.0369  accuracy: 22.38% -> 25.17%     
client [55] (testset)   loss: 3.8751 -> 3.9941  accuracy: 29.31% -> 31.90%     
client [12] (testset)   loss: 4.6089 -> 4.7278  accuracy: 16.46% -> 24.05%     
client [89] (testset)   loss: 4.0752 -> 4.2185  accuracy: 21.43% -> 26.43%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 3.9489 -> 4.0743  accuracy: 23.95% -> 31.14%     
client [51] (testset)   loss: 4.0752 -> 4.0100  accuracy: 17.50% -> 32.50%     
client [8]  (testset)   loss: 4.1326 -> 4.3306  accuracy: 25.52% -> 29.66%     
client [18] (testset)   loss: 3.7927 -> 3.7092  accuracy: 25.84% -> 34.83%     
client [94] (testset)   loss: 3.6821 -> 3.9548  accuracy: 21.62% -> 19.82%     
client [81] (testset)   loss: 3.8426 -> 4.2775  accuracy: 27.08% -> 28.65%     
client [3]  (testset)   loss: 4.2375 -> 4.3592  accuracy: 20.73% -> 28.50%     
client [11] (testset)   loss: 3.6298 -> 3.6850  accuracy: 27.20% -> 36.00%     
client [95] (testset)   loss: 3.8259 -> 3.9117  accuracy: 22.89% -> 29.52%     
client [67] (testset)   loss: 3.4682 -> 3.7277  accuracy: 32.54% -> 39.64%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 3.6772 -> 4.7424  accuracy: 32.20% -> 28.81%     
client [79] (testset)   loss: 4.0133 -> 4.1376  accuracy: 26.43% -> 35.71%     
client [58] (testset)   loss: 3.7620 -> 3.8844  accuracy: 26.45% -> 36.77%     
client [88] (testset)   loss: 3.5889 -> 3.3832  accuracy: 28.12% -> 29.69%     
client [46] (testset)   loss: 4.0566 -> 4.7465  accuracy: 26.74% -> 24.42%     
client [11] (testset)   loss: 3.8701 -> 3.7719  accuracy: 21.60% -> 33.60%     
client [55] (testset)   loss: 3.7522 -> 3.9025  accuracy: 25.86% -> 32.76%     
client [13] (testset)   loss: 4.7601 -> 4.5567  accuracy: 17.78% -> 25.93%     
client [31] (testset)   loss: 3.7159 -> 3.6673  accuracy: 27.05% -> 39.34%     
client [75] (testset)   loss: 4.4807 -> 4.5786  accuracy: 21.43% -> 27.14%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 4.3798 -> 4.4808  accuracy: 21.05% -> 20.30%     
client [7]  (testset)   loss: 4.0134 -> 4.0435  accuracy: 19.42% -> 31.65%     
client [57] (testset)   loss: 3.4854 -> 3.5683  accuracy: 29.93% -> 31.39%     
client [13] (testset)   loss: 4.7684 -> 4.6920  accuracy: 17.04% -> 28.15%     
client [43] (testset)   loss: 4.1800 -> 4.5211  accuracy: 23.08% -> 25.38%     
client [91] (testset)   loss: 4.0019 -> 4.0934  accuracy: 30.72% -> 32.68%     
client [10] (testset)   loss: 4.0204 -> 3.7535  accuracy: 23.16% -> 29.94%     
client [64] (testset)   loss: 3.8288 -> 3.7640  accuracy: 25.68% -> 34.43%     
client [82] (testset)   loss: 4.1753 -> 4.5147  accuracy: 23.13% -> 22.39%     
client [22] (testset)   loss: 4.6591 -> 4.7380  accuracy: 19.59% -> 25.68%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 3.9676 -> 4.2250  accuracy: 27.94% -> 25.74%     
client [23] (testset)   loss: 4.3333 -> 4.7497  accuracy: 28.37% -> 24.11%     
client [88] (testset)   loss: 3.5836 -> 3.4135  accuracy: 32.03% -> 34.38%     
client [98] (testset)   loss: 4.1588 -> 4.0565  accuracy: 25.42% -> 32.20%     
client [79] (testset)   loss: 4.0357 -> 4.1258  accuracy: 29.29% -> 35.00%     
client [21] (testset)   loss: 3.8101 -> 4.5047  accuracy: 33.90% -> 31.36%     
client [92] (testset)   loss: 4.4521 -> 4.3886  accuracy: 22.97% -> 29.05%     
client [56] (testset)   loss: 4.4954 -> 4.5547  accuracy: 26.98% -> 34.92%     
client [5]  (testset)   loss: 3.8684 -> 3.9172  accuracy: 22.76% -> 27.59%     
client [52] (testset)   loss: 4.1767 -> 4.1961  accuracy: 27.42% -> 31.18%     
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 3.4512 -> 3.6946  accuracy: 35.50% -> 37.28%     
client [54] (testset)   loss: 3.7417 -> 3.3501  accuracy: 26.39% -> 36.11%     
client [14] (testset)   loss: 4.0671 -> 4.1191  accuracy: 25.58% -> 30.23%     
client [99] (testset)   loss: 4.1500 -> 4.4119  accuracy: 24.03% -> 27.92%     
client [36] (testset)   loss: 3.3352 -> 3.6318  accuracy: 31.86% -> 35.40%     
client [30] (testset)   loss: 3.8378 -> 3.9843  accuracy: 25.15% -> 30.67%     
client [38] (testset)   loss: 4.3768 -> 4.0034  accuracy: 22.22% -> 32.32%     
client [15] (testset)   loss: 4.0827 -> 4.1825  accuracy: 26.11% -> 31.67%     
client [6]  (testset)   loss: 3.7771 -> 4.0786  accuracy: 22.88% -> 22.88%     
client [53] (testset)   loss: 4.7183 -> 4.2934  accuracy: 14.19% -> 27.74%     
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [99] (testset)   loss: 4.2209 -> 4.4021  accuracy: 25.97% -> 28.57%     
client [6]  (testset)   loss: 3.9174 -> 4.4065  accuracy: 21.19% -> 22.88%     
client [83] (testset)   loss: 4.5007 -> 4.2553  accuracy: 23.20% -> 35.20%     
client [42] (testset)   loss: 4.2096 -> 3.6191  accuracy: 23.91% -> 34.06%     
client [34] (testset)   loss: 4.4888 -> 4.8010  accuracy: 27.20% -> 31.20%     
client [15] (testset)   loss: 4.2454 -> 4.3412  accuracy: 25.56% -> 30.56%     
client [47] (testset)   loss: 3.9217 -> 3.8353  accuracy: 27.54% -> 29.71%     
client [55] (testset)   loss: 3.7454 -> 3.8363  accuracy: 30.17% -> 35.34%     
client [51] (testset)   loss: 4.3978 -> 4.3473  accuracy: 22.50% -> 25.62%     
client [95] (testset)   loss: 4.2257 -> 4.1615  accuracy: 22.29% -> 29.52%     
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 3.9846 -> 4.0840  accuracy: 28.12% -> 29.69%     
client [15] (testset)   loss: 4.3406 -> 4.2230  accuracy: 23.89% -> 28.89%     
client [33] (testset)   loss: 3.9412 -> 3.6202  accuracy: 26.98% -> 35.71%     
client [99] (testset)   loss: 4.3294 -> 4.5685  accuracy: 27.27% -> 25.32%     
client [90] (testset)   loss: 3.8965 -> 3.5819  accuracy: 28.48% -> 35.15%     
client [57] (testset)   loss: 3.8132 -> 3.4769  accuracy: 25.55% -> 30.66%     
client [27] (testset)   loss: 3.3243 -> 3.2839  accuracy: 35.65% -> 40.00%     
client [78] (testset)   loss: 3.9876 -> 3.9374  accuracy: 23.74% -> 28.78%     
client [36] (testset)   loss: 3.4818 -> 3.6452  accuracy: 28.32% -> 33.63%     
client [88] (testset)   loss: 3.5847 -> 3.4451  accuracy: 32.81% -> 33.59%     
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 4.4217 -> 4.2876  accuracy: 21.86% -> 29.51%     
client [35] (testset)   loss: 4.6290 -> 4.5765  accuracy: 25.00% -> 28.66%     
client [16] (testset)   loss: 4.1702 -> 4.1641  accuracy: 24.83% -> 31.54%     
client [80] (testset)   loss: 4.8264 -> 4.4000  accuracy: 16.89% -> 25.68%     
client [38] (testset)   loss: 4.2849 -> 3.9909  accuracy: 28.28% -> 35.35%     
client [78] (testset)   loss: 4.1851 -> 4.1952  accuracy: 25.18% -> 30.22%     
client [68] (testset)   loss: 3.8569 -> 4.0086  accuracy: 29.32% -> 29.32%     
client [11] (testset)   loss: 4.0387 -> 4.1023  accuracy: 28.00% -> 34.40%     
client [64] (testset)   loss: 4.3074 -> 4.0156  accuracy: 24.59% -> 35.52%     
client [82] (testset)   loss: 4.3815 -> 4.6461  accuracy: 22.39% -> 26.87%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 3.8709 -> 4.3045  accuracy: 25.77% -> 28.22%     
client [27] (testset)   loss: 3.6377 -> 3.1541  accuracy: 28.70% -> 38.26%     
client [74] (testset)   loss: 4.8754 -> 4.3100  accuracy: 20.16% -> 25.81%     
client [45] (testset)   loss: 4.0432 -> 4.1297  accuracy: 29.38% -> 31.64%     
client [6]  (testset)   loss: 3.9897 -> 4.4524  accuracy: 21.19% -> 22.03%     
client [36] (testset)   loss: 3.5097 -> 3.5291  accuracy: 32.74% -> 36.28%     
client [63] (testset)   loss: 4.6009 -> 5.2516  accuracy: 29.31% -> 31.61%     
client [76] (testset)   loss: 4.0227 -> 4.0952  accuracy: 26.83% -> 26.02%     
client [83] (testset)   loss: 4.5457 -> 4.5143  accuracy: 24.00% -> 30.40%     
client [86] (testset)   loss: 4.0365 -> 4.3265  accuracy: 28.85% -> 37.18%     
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 4.4721 -> 4.4896  accuracy: 23.20% -> 31.20%     
client [99] (testset)   loss: 4.5510 -> 4.5531  accuracy: 25.32% -> 27.27%     
client [74] (testset)   loss: 4.9255 -> 4.6202  accuracy: 20.16% -> 27.42%     
client [73] (testset)   loss: 4.0734 -> 4.5145  accuracy: 22.73% -> 30.11%     
client [29] (testset)   loss: 4.6874 -> 4.6424  accuracy: 23.46% -> 28.40%     
client [92] (testset)   loss: 4.3328 -> 4.4913  accuracy: 22.97% -> 27.03%     
client [6]  (testset)   loss: 4.0482 -> 4.5135  accuracy: 22.03% -> 22.88%     
client [61] (testset)   loss: 3.8996 -> 4.2394  accuracy: 28.25% -> 30.51%     
client [21] (testset)   loss: 4.0449 -> 4.7939  accuracy: 33.05% -> 33.90%     
client [67] (testset)   loss: 3.5441 -> 3.7177  accuracy: 32.54% -> 38.46%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 4.6014 -> 4.3221  accuracy: 25.60% -> 36.80%     
client [32] (testset)   loss: 3.8879 -> 3.6357  accuracy: 29.13% -> 40.16%     
client [95] (testset)   loss: 4.3118 -> 4.3417  accuracy: 21.08% -> 28.31%     
client [61] (testset)   loss: 3.7739 -> 4.3452  accuracy: 30.51% -> 28.81%     
client [27] (testset)   loss: 3.5547 -> 3.2698  accuracy: 29.57% -> 39.13%     
client [25] (testset)   loss: 4.4597 -> 4.5237  accuracy: 29.57% -> 33.33%     
client [68] (testset)   loss: 4.2384 -> 4.0519  accuracy: 25.56% -> 31.58%     
client [34] (testset)   loss: 4.9922 -> 4.9222  accuracy: 21.60% -> 31.20%     
client [71] (testset)   loss: 4.2034 -> 4.0795  accuracy: 31.25% -> 31.25%     
client [89] (testset)   loss: 4.7632 -> 4.8350  accuracy: 22.14% -> 25.71%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 4.4077 -> 4.1782  accuracy: 25.18% -> 33.81%     
client [81] (testset)   loss: 4.3143 -> 4.5219  accuracy: 28.12% -> 30.73%     
client [51] (testset)   loss: 4.6336 -> 4.3194  accuracy: 21.88% -> 29.38%     
client [54] (testset)   loss: 4.0819 -> 3.6402  accuracy: 24.31% -> 33.33%     
client [65] (testset)   loss: 4.6124 -> 4.6594  accuracy: 26.21% -> 33.10%     
client [41] (testset)   loss: 4.0575 -> 3.7796  accuracy: 28.95% -> 34.74%     
client [11] (testset)   loss: 3.8887 -> 4.0778  accuracy: 28.80% -> 32.00%     
client [85] (testset)   loss: 4.6004 -> 5.0015  accuracy: 24.84% -> 29.19%     
client [12] (testset)   loss: 5.1334 -> 5.1768  accuracy: 21.52% -> 24.05%     
client [23] (testset)   loss: 4.3282 -> 4.8226  accuracy: 27.66% -> 24.11%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 4.5176 -> 4.2879  accuracy: 22.82% -> 31.54%     
client [65] (testset)   loss: 4.6511 -> 4.6361  accuracy: 25.52% -> 33.10%     
client [53] (testset)   loss: 5.1399 -> 4.5594  accuracy: 14.19% -> 28.39%     
client [58] (testset)   loss: 3.9498 -> 4.0402  accuracy: 29.03% -> 36.77%     
client [72] (testset)   loss: 4.3537 -> 4.6441  accuracy: 29.68% -> 27.74%     
client [7]  (testset)   loss: 4.3626 -> 4.6451  accuracy: 23.74% -> 31.65%     
client [71] (testset)   loss: 4.0451 -> 4.4958  accuracy: 30.47% -> 32.03%     
client [59] (testset)   loss: 4.1688 -> 4.1830  accuracy: 26.38% -> 34.36%     
client [86] (testset)   loss: 4.3025 -> 4.5783  accuracy: 25.00% -> 36.54%     
client [39] (testset)   loss: 4.2269 -> 4.4506  accuracy: 27.74% -> 27.01%     
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 4.4742 -> 4.9971  accuracy: 25.97% -> 28.57%     
client [7]  (testset)   loss: 4.4618 -> 4.4294  accuracy: 23.02% -> 29.50%     
client [17] (testset)   loss: 4.7106 -> 4.3732  accuracy: 18.84% -> 30.43%     
client [64] (testset)   loss: 4.5696 -> 4.2022  accuracy: 26.78% -> 35.52%     
client [37] (testset)   loss: 4.7233 -> 4.3101  accuracy: 25.16% -> 28.39%     
client [29] (testset)   loss: 4.5830 -> 4.8333  accuracy: 27.16% -> 30.86%     
client [93] (testset)   loss: 4.7612 -> 4.5667  accuracy: 23.91% -> 28.26%     
client [73] (testset)   loss: 4.3482 -> 4.6519  accuracy: 22.73% -> 32.95%     
client [40] (testset)   loss: 4.8208 -> 4.5240  accuracy: 20.24% -> 30.36%     
client [76] (testset)   loss: 4.1759 -> 4.4334  accuracy: 25.20% -> 27.64%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 4.4627 -> 4.3994  accuracy: 27.05% -> 34.43%     
client [89] (testset)   loss: 5.0560 -> 5.0295  accuracy: 21.43% -> 22.86%     
client [77] (testset)   loss: 4.6846 -> 4.3947  accuracy: 23.78% -> 31.47%     
client [90] (testset)   loss: 4.4661 -> 3.9362  accuracy: 29.09% -> 36.97%     
client [26] (testset)   loss: 4.6911 -> 4.4612  accuracy: 26.03% -> 33.56%     
client [50] (testset)   loss: 4.5337 -> 4.3266  accuracy: 25.64% -> 30.77%     
client [30] (testset)   loss: 4.2267 -> 4.5193  accuracy: 25.15% -> 30.67%     
client [70] (testset)   loss: 4.8461 -> 4.5531  accuracy: 19.67% -> 26.23%     
client [41] (testset)   loss: 4.2827 -> 4.1423  accuracy: 30.53% -> 32.63%     
client [99] (testset)   loss: 4.8765 -> 4.7236  accuracy: 22.73% -> 28.57%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [68] (testset)   loss: 4.2170 -> 4.1769  accuracy: 27.82% -> 30.83%     
client [70] (testset)   loss: 4.7865 -> 4.8364  accuracy: 20.77% -> 24.04%     
client [52] (testset)   loss: 4.8107 -> 4.6462  accuracy: 26.34% -> 32.80%     
client [1]  (testset)   loss: 4.1540 -> 4.1118  accuracy: 29.93% -> 36.50%     
client [2]  (testset)   loss: 3.6620 -> 3.8317  accuracy: 35.20% -> 37.99%     
client [67] (testset)   loss: 3.8893 -> 3.9343  accuracy: 34.32% -> 40.24%     
client [92] (testset)   loss: 4.7063 -> 4.6358  accuracy: 21.62% -> 31.08%     
client [35] (testset)   loss: 4.8924 -> 4.9129  accuracy: 25.00% -> 31.71%     
client [36] (testset)   loss: 3.8677 -> 4.0567  accuracy: 32.74% -> 30.97%     
client [64] (testset)   loss: 4.6663 -> 4.4556  accuracy: 26.78% -> 33.33%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 4.0762 -> 3.8203  accuracy: 26.17% -> 36.24%     
client [6]  (testset)   loss: 4.5063 -> 4.6499  accuracy: 21.19% -> 26.27%     
client [12] (testset)   loss: 5.6615 -> 5.6149  accuracy: 20.25% -> 24.68%     
client [55] (testset)   loss: 4.0974 -> 4.3878  accuracy: 31.90% -> 27.59%     
client [29] (testset)   loss: 5.0205 -> 5.0686  accuracy: 24.07% -> 33.33%     
client [9]  (testset)   loss: 5.1164 -> 5.1636  accuracy: 20.14% -> 24.31%     
client [43] (testset)   loss: 4.9770 -> 5.2198  accuracy: 25.38% -> 24.62%     
client [77] (testset)   loss: 4.9223 -> 4.4701  accuracy: 22.38% -> 26.57%     
client [98] (testset)   loss: 4.9440 -> 4.4697  accuracy: 21.47% -> 31.07%     
client [78] (testset)   loss: 4.4986 -> 4.7206  accuracy: 25.18% -> 35.25%     
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 5.0340 -> 4.7642  accuracy: 25.00% -> 27.70%     
client [80] (testset)   loss: 5.2247 -> 4.7495  accuracy: 18.24% -> 33.11%     
client [63] (testset)   loss: 5.3391 -> 5.5382  accuracy: 26.44% -> 31.61%     
client [76] (testset)   loss: 4.4833 -> 4.5877  accuracy: 22.76% -> 22.76%     
client [78] (testset)   loss: 4.5634 -> 4.6918  accuracy: 26.62% -> 30.94%     
client [25] (testset)   loss: 4.6746 -> 4.7797  accuracy: 27.96% -> 34.41%     
client [58] (testset)   loss: 4.5183 -> 4.5904  accuracy: 25.81% -> 32.26%     
client [13] (testset)   loss: 5.6740 -> 5.5375  accuracy: 15.56% -> 23.70%     
client [17] (testset)   loss: 4.5954 -> 4.4266  accuracy: 19.57% -> 31.88%     
client [38] (testset)   loss: 4.5270 -> 4.2839  accuracy: 24.24% -> 35.35%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 4.6954 -> 4.7173  accuracy: 27.10% -> 31.61%     
client [82] (testset)   loss: 5.1064 -> 5.0471  accuracy: 23.88% -> 29.10%     
client [86] (testset)   loss: 4.7836 -> 4.7218  accuracy: 23.72% -> 35.26%     
client [51] (testset)   loss: 4.6854 -> 4.4462  accuracy: 24.38% -> 33.12%     
client [96] (testset)   loss: 4.7613 -> 4.8684  accuracy: 29.03% -> 35.48%     
client [42] (testset)   loss: 4.8333 -> 4.0964  accuracy: 26.09% -> 33.33%     
client [55] (testset)   loss: 4.3603 -> 4.2251  accuracy: 28.45% -> 31.90%     
client [13] (testset)   loss: 5.7472 -> 5.5984  accuracy: 18.52% -> 22.22%     
client [1]  (testset)   loss: 4.2480 -> 4.3821  accuracy: 29.93% -> 34.31%     
client [12] (testset)   loss: 5.7135 -> 5.7379  accuracy: 17.09% -> 21.52%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 4.2435 -> 4.2774  accuracy: 30.08% -> 33.83%     
client [23] (testset)   loss: 4.9133 -> 5.2950  accuracy: 27.66% -> 25.53%     
client [46] (testset)   loss: 4.9963 -> 4.9945  accuracy: 27.33% -> 27.91%     
client [41] (testset)   loss: 4.5223 -> 4.4012  accuracy: 27.37% -> 36.84%     
client [25] (testset)   loss: 4.6761 -> 4.7982  accuracy: 30.11% -> 39.78%     
client [58] (testset)   loss: 4.6633 -> 4.6217  accuracy: 23.87% -> 30.32%     
client [14] (testset)   loss: 4.9428 -> 4.7258  accuracy: 22.09% -> 31.40%     
client [33] (testset)   loss: 4.5359 -> 4.3430  accuracy: 28.57% -> 36.51%     
client [85] (testset)   loss: 5.1039 -> 5.6402  accuracy: 22.36% -> 26.71%     
client [62] (testset)   loss: 5.2514 -> 4.7217  accuracy: 17.75% -> 24.85%     
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 4.7020 -> 4.5186  accuracy: 25.42% -> 29.38%     
client [63] (testset)   loss: 5.5825 -> 5.8161  accuracy: 28.74% -> 31.61%     
client [70] (testset)   loss: 4.9175 -> 4.6920  accuracy: 19.67% -> 24.59%     
client [65] (testset)   loss: 5.2399 -> 5.1711  accuracy: 24.14% -> 35.17%     
client [14] (testset)   loss: 4.8863 -> 4.6515  accuracy: 22.09% -> 33.14%     
client [73] (testset)   loss: 4.8976 -> 5.1026  accuracy: 25.00% -> 31.82%     
client [34] (testset)   loss: 5.7450 -> 5.6133  accuracy: 24.80% -> 32.00%     
client [99] (testset)   loss: 4.9375 -> 5.1456  accuracy: 27.27% -> 31.82%     
client [69] (testset)   loss: 4.5382 -> 4.7267  accuracy: 33.33% -> 37.40%     
client [46] (testset)   loss: 4.8039 -> 5.2705  accuracy: 27.33% -> 30.23%     
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [99] (testset)   loss: 5.1544 -> 5.2673  accuracy: 24.03% -> 25.97%     
client [93] (testset)   loss: 5.4685 -> 5.0684  accuracy: 23.19% -> 31.16%     
client [11] (testset)   loss: 4.5832 -> 4.8413  accuracy: 28.00% -> 35.20%     
client [58] (testset)   loss: 4.6457 -> 4.5274  accuracy: 27.10% -> 30.97%     
client [81] (testset)   loss: 4.7804 -> 4.8091  accuracy: 26.04% -> 33.33%     
client [85] (testset)   loss: 5.3665 -> 5.8858  accuracy: 26.09% -> 29.19%     
client [89] (testset)   loss: 5.4054 -> 5.5553  accuracy: 20.00% -> 24.29%     
client [45] (testset)   loss: 4.9739 -> 4.8395  accuracy: 26.55% -> 34.46%     
client [8]  (testset)   loss: 5.6388 -> 5.3919  accuracy: 20.69% -> 33.10%     
client [68] (testset)   loss: 4.5361 -> 4.3143  accuracy: 30.08% -> 34.59%     
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 4.0933 -> 4.4248  accuracy: 33.73% -> 31.36%     
client [72] (testset)   loss: 4.9250 -> 4.7569  accuracy: 27.74% -> 30.97%     
client [1]  (testset)   loss: 4.4308 -> 4.2682  accuracy: 32.85% -> 39.42%     
client [78] (testset)   loss: 4.9211 -> 5.0057  accuracy: 25.90% -> 28.06%     
client [83] (testset)   loss: 5.1429 -> 4.9856  accuracy: 25.60% -> 28.80%     
client [21] (testset)   loss: 4.6034 -> 5.3440  accuracy: 33.05% -> 30.51%     
client [56] (testset)   loss: 5.3857 -> 5.3526  accuracy: 26.98% -> 30.16%     
client [44] (testset)   loss: 4.3985 -> 4.0824  accuracy: 28.19% -> 36.91%     
client [92] (testset)   loss: 5.2191 -> 5.1292  accuracy: 25.68% -> 29.05%     
client [27] (testset)   loss: 4.0264 -> 3.9244  accuracy: 30.43% -> 32.17%     
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 4.7578 -> 4.5264  accuracy: 28.81% -> 31.07%     
client [39] (testset)   loss: 5.0661 -> 5.2943  accuracy: 26.28% -> 29.20%     
client [65] (testset)   loss: 5.1395 -> 5.0407  accuracy: 28.97% -> 37.24%     
client [26] (testset)   loss: 5.7321 -> 4.8849  accuracy: 19.18% -> 34.25%     
client [19] (testset)   loss: 5.3551 -> 5.3383  accuracy: 23.31% -> 24.81%     
client [68] (testset)   loss: 4.4249 -> 4.3996  accuracy: 33.83% -> 36.84%     
client [41] (testset)   loss: 4.5894 -> 4.7296  accuracy: 27.37% -> 33.16%     
client [50] (testset)   loss: 4.8256 -> 4.4928  accuracy: 26.92% -> 34.62%     
client [75] (testset)   loss: 5.8020 -> 5.6153  accuracy: 22.86% -> 25.00%     
client [81] (testset)   loss: 4.7854 -> 4.7758  accuracy: 27.60% -> 32.29%     
Training... ---------------------------------------- 100% 0:11:29
FedAvg's average time taken by each global epoch: 0 min 1.71 sec.              
FedAvg's total running time: 0 h 11 m 29 s.                                    
==================== FedAvg Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "3.7053 -> 0.0000",                                    
                "accuracy": "24.74% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "4.0857 -> 0.0000",                                    
                "accuracy": "25.29% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "4.4974 -> 0.0000",                                    
                "accuracy": "25.56% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "5.0996 -> 0.0000",                                    
                "accuracy": "25.48% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedAvg Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 25.56% at epoch 300                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
[0m