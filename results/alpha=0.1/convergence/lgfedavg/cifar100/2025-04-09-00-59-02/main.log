==================== LG-FedAvg ====================                             
Experiment Arguments:                                                           
{
│   'method': 'lgfedavg',
│   'dataset': {
│   │   'name': 'cifar100',
│   │   'client_num': 100,
│   │   'test_ratio': 0.25,
│   │   'val_ratio': 0.0,
│   │   'seed': 42,
│   │   'split': 'sample',
│   │   'IID_ratio': 0.0,
│   │   'monitor_window_name_suffix': 'cifar100-100clients-0%IID-use20superclasses-Dir(0.1)-seed42',
│   │   'super_class': False,
│   │   'alpha': 0.1,
│   │   'min_samples_per_client': 10
│   },
│   'model': {
│   │   'name': 'avgcnn',
│   │   'use_torchvision_pretrained_weights': True,
│   │   'external_model_weights_path': None
│   },
│   'optimizer': {
│   │   'lr': 0.01,
│   │   'dampening': 0,
│   │   'weight_decay': 0,
│   │   'momentum': 0,
│   │   'nesterov': False,
│   │   'name': 'sgd'
│   },
│   'mode': 'serial',
│   'parallel': {
│   │   'ray_cluster_addr': None,
│   │   'num_cpus': None,
│   │   'num_gpus': None,
│   │   'num_workers': 2
│   },
│   'common': {
│   │   'seed': 42,
│   │   'join_ratio': 0.1,
│   │   'global_epoch': 400,
│   │   'local_epoch': 5,
│   │   'batch_size': 32,
│   │   'reset_optimizer_on_global_epoch': True,
│   │   'straggler_ratio': 0,
│   │   'straggler_min_local_epoch': 0,
│   │   'buffers': 'global',
│   │   'client_side_evaluation': True,
│   │   'test': {
│   │   │   'client': {
│   │   │   │   'interval': 100,
│   │   │   │   'finetune_epoch': 0,
│   │   │   │   'train': False,
│   │   │   │   'val': False,
│   │   │   │   'test': True
│   │   │   },
│   │   │   'server': {
│   │   │   │   'interval': -1,
│   │   │   │   'train': False,
│   │   │   │   'val': False,
│   │   │   │   'test': False,
│   │   │   │   'model_in_train_mode': False
│   │   │   }
│   │   },
│   │   'verbose_gap': 10,
│   │   'monitor': None,
│   │   'use_cuda': True,
│   │   'save_log': True,
│   │   'save_model': False,
│   │   'save_learning_curve_plot': False,
│   │   'save_metrics': True,
│   │   'delete_useless_run': True
│   },
│   'lgfedavg': {
│   │   'num_global_layers': 1
│   }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------    
client [77] (testset)   loss: 2.0907 -> 2.1570  accuracy: 43.82% -> 45.51%      
client [81] (testset)   loss: 3.2533 -> 4.5207  accuracy: 28.48% -> 22.52%      
client [21] (testset)   loss: 4.2824 -> 2.2823  accuracy: 10.20% -> 34.69%      
client [68] (testset)   loss: 2.7199 -> 2.3101  accuracy: 28.57% -> 40.34%      
client [93] (testset)   loss: 3.4570 -> 2.6718  accuracy: 23.20% -> 32.80%      
client [31] (testset)   loss: 3.1650 -> 2.2954  accuracy: 20.00% -> 38.95%      
client [20] (testset)   loss: 2.3512 -> 2.3337  accuracy: 35.15% -> 41.09%      
client [59] (testset)   loss: 4.4859 -> 2.4065  accuracy: 4.72% -> 30.04%       
client [48] (testset)   loss: 2.8419 -> 2.8767  accuracy: 29.70% -> 27.27%      
client [34] (testset)   loss: 2.6992 -> 2.8174  accuracy: 25.41% -> 28.18%      
---------------------------- TRAINING EPOCH: 20 ----------------------------    
client [69] (testset)   loss: 2.4842 -> 1.9112  accuracy: 45.13% -> 50.90%      
client [99] (testset)   loss: 3.3735 -> 3.7183  accuracy: 26.28% -> 16.79%      
client [67] (testset)   loss: 4.0980 -> 3.3191  accuracy: 12.64% -> 23.08%      
client [0]  (testset)   loss: 2.2588 -> 2.3640  accuracy: 40.20% -> 37.25%      
client [76] (testset)   loss: 2.4306 -> 2.6854  accuracy: 33.52% -> 32.96%      
client [41] (testset)   loss: 2.9381 -> 2.7904  accuracy: 20.97% -> 24.19%      
client [62] (testset)   loss: 4.6358 -> 2.4626  accuracy: 2.91% -> 37.86%       
client [2]  (testset)   loss: 4.5926 -> 2.7942  accuracy: 3.57% -> 21.43%       
client [14] (testset)   loss: 3.1650 -> 3.5081  accuracy: 31.17% -> 25.97%      
client [46] (testset)   loss: 2.8934 -> 2.3898  accuracy: 26.67% -> 49.52%      
---------------------------- TRAINING EPOCH: 30 ----------------------------    
client [24] (testset)   loss: 2.2570 -> 2.3994  accuracy: 38.79% -> 41.38%      
client [68] (testset)   loss: 3.7410 -> 3.1249  accuracy: 33.61% -> 36.13%      
client [57] (testset)   loss: 2.2531 -> 2.3645  accuracy: 36.20% -> 40.49%      
client [17] (testset)   loss: 3.5241 -> 2.9003  accuracy: 30.08% -> 31.58%      
client [54] (testset)   loss: 4.3117 -> 4.4040  accuracy: 27.50% -> 32.50%      
client [23] (testset)   loss: 4.2871 -> 2.5519  accuracy: 6.36% -> 36.36%       
client [35] (testset)   loss: 2.5485 -> 2.9968  accuracy: 34.18% -> 28.57%      
client [59] (testset)   loss: 2.3749 -> 2.4358  accuracy: 37.34% -> 38.63%      
client [31] (testset)   loss: 2.5527 -> 2.8590  accuracy: 44.21% -> 41.05%      
client [9]  (testset)   loss: 2.5052 -> 2.7030  accuracy: 36.91% -> 39.60%      
---------------------------- TRAINING EPOCH: 40 ----------------------------    
client [64] (testset)   loss: 2.3952 -> 2.6189  accuracy: 47.97% -> 45.27%      
client [33] (testset)   loss: 3.9919 -> 4.3191  accuracy: 24.77% -> 24.77%      
client [16] (testset)   loss: 3.3729 -> 3.4018  accuracy: 23.97% -> 35.54%      
client [44] (testset)   loss: 4.5544 -> 3.0538  accuracy: 20.92% -> 24.18%      
client [8]  (testset)   loss: 3.6812 -> 3.7147  accuracy: 40.20% -> 43.72%      
client [31] (testset)   loss: 3.0651 -> 2.9913  accuracy: 45.26% -> 45.79%      
client [47] (testset)   loss: 3.7654 -> 3.1518  accuracy: 33.04% -> 41.74%      
client [36] (testset)   loss: 2.9870 -> 3.0301  accuracy: 24.78% -> 24.78%      
client [20] (testset)   loss: 2.7151 -> 2.6239  accuracy: 46.04% -> 50.50%      
client [56] (testset)   loss: 2.7534 -> 3.5244  accuracy: 34.52% -> 28.57%      
---------------------------- TRAINING EPOCH: 50 ----------------------------    
client [4]  (testset)   loss: 2.2001 -> 2.1975  accuracy: 45.95% -> 45.27%      
client [60] (testset)   loss: 3.8804 -> 3.4204  accuracy: 27.27% -> 25.76%      
client [28] (testset)   loss: 3.1011 -> 2.8475  accuracy: 40.32% -> 39.52%      
client [25] (testset)   loss: 3.1268 -> 2.8818  accuracy: 43.75% -> 41.67%      
client [58] (testset)   loss: 4.7139 -> 6.4361  accuracy: 30.00% -> 26.15%      
client [44] (testset)   loss: 3.2784 -> 3.0184  accuracy: 23.53% -> 30.07%      
client [39] (testset)   loss: 3.1111 -> 3.1711  accuracy: 32.34% -> 34.13%      
client [29] (testset)   loss: 6.6838 -> 4.0922  accuracy: 24.67% -> 30.67%      
client [3]  (testset)   loss: 2.6292 -> 2.5106  accuracy: 35.94% -> 38.28%      
client [84] (testset)   loss: 8.7726 -> 4.7216  accuracy: 16.53% -> 30.51%      
---------------------------- TRAINING EPOCH: 60 ----------------------------    
client [21] (testset)   loss: 2.9199 -> 2.8799  accuracy: 31.29% -> 38.78%      
client [84] (testset)   loss: 4.7013 -> 4.8963  accuracy: 35.59% -> 36.02%      
client [10] (testset)   loss: 4.4309 -> 3.6092  accuracy: 21.15% -> 36.54%      
client [36] (testset)   loss: 2.9294 -> 3.2110  accuracy: 32.74% -> 36.28%      
client [65] (testset)   loss: 3.3790 -> 3.6402  accuracy: 30.91% -> 31.82%      
client [81] (testset)   loss: 3.2724 -> 3.4221  accuracy: 41.06% -> 41.72%      
client [79] (testset)   loss: 2.4914 -> 2.7941  accuracy: 53.07% -> 46.93%      
client [42] (testset)   loss: 3.1806 -> 3.2502  accuracy: 47.26% -> 46.58%      
client [11] (testset)   loss: 2.5501 -> 2.5689  accuracy: 40.68% -> 40.68%      
client [96] (testset)   loss: 6.7590 -> 3.7259  accuracy: 28.32% -> 39.31%      
---------------------------- TRAINING EPOCH: 70 ----------------------------    
client [8]  (testset)   loss: 4.9256 -> 4.9976  accuracy: 38.19% -> 40.70%      
client [53] (testset)   loss: 4.8945 -> 4.5320  accuracy: 24.82% -> 30.50%      
client [52] (testset)   loss: 4.4515 -> 4.6085  accuracy: 41.04% -> 40.30%      
client [42] (testset)   loss: 3.5223 -> 3.5629  accuracy: 45.89% -> 47.26%      
client [69] (testset)   loss: 3.3627 -> 3.5533  accuracy: 50.18% -> 50.90%      
client [59] (testset)   loss: 3.6844 -> 3.8312  accuracy: 37.77% -> 31.76%      
client [7]  (testset)   loss: 4.8888 -> 4.9919  accuracy: 32.89% -> 34.21%      
client [26] (testset)   loss: 3.4600 -> 3.3978  accuracy: 39.82% -> 41.59%      
client [49] (testset)   loss: 3.2403 -> 3.4763  accuracy: 40.74% -> 40.74%      
client [98] (testset)   loss: 4.4504 -> 4.6421  accuracy: 35.92% -> 32.39%      
---------------------------- TRAINING EPOCH: 80 ----------------------------    
client [98] (testset)   loss: 4.8079 -> 4.9229  accuracy: 32.39% -> 33.80%      
client [47] (testset)   loss: 3.6259 -> 3.4193  accuracy: 43.48% -> 46.09%      
client [21] (testset)   loss: 2.4566 -> 2.7630  accuracy: 38.78% -> 40.14%      
client [77] (testset)   loss: 3.1590 -> 3.3573  accuracy: 46.63% -> 47.19%      
client [95] (testset)   loss: 5.2172 -> 5.3266  accuracy: 36.14% -> 35.54%      
client [91] (testset)   loss: 3.9755 -> 4.1049  accuracy: 32.89% -> 33.55%      
client [14] (testset)   loss: 4.8430 -> 5.0055  accuracy: 33.77% -> 28.57%      
client [99] (testset)   loss: 5.5177 -> 5.9386  accuracy: 21.90% -> 23.36%      
client [20] (testset)   loss: 4.2486 -> 4.2338  accuracy: 47.03% -> 48.02%      
client [39] (testset)   loss: 3.6901 -> 3.8672  accuracy: 39.52% -> 39.52%      
---------------------------- TRAINING EPOCH: 90 ----------------------------    
client [52] (testset)   loss: 4.9710 -> 5.0430  accuracy: 40.30% -> 37.31%      
client [62] (testset)   loss: 4.7799 -> 4.8815  accuracy: 42.23% -> 41.75%      
client [71] (testset)   loss: 5.0658 -> 5.3112  accuracy: 22.90% -> 22.90%      
client [97] (testset)   loss: 3.9836 -> 4.2309  accuracy: 29.52% -> 28.57%      
client [30] (testset)   loss: 5.7324 -> 5.7987  accuracy: 23.20% -> 22.65%      
client [88] (testset)   loss: 3.3015 -> 3.8849  accuracy: 36.87% -> 39.11%      
client [60] (testset)   loss: 4.8886 -> 4.9301  accuracy: 40.91% -> 39.39%      
client [82] (testset)   loss: 4.2812 -> 4.7430  accuracy: 32.56% -> 29.07%      
client [91] (testset)   loss: 4.3717 -> 4.4936  accuracy: 34.21% -> 31.58%      
client [57] (testset)   loss: 2.8261 -> 3.2324  accuracy: 49.69% -> 46.63%      
---------------------------- TRAINING EPOCH: 100 ----------------------------   
client [31] (testset)   loss: 4.8904 -> 4.9168  accuracy: 45.26% -> 45.26%      
client [15] (testset)   loss: 4.3475 -> 4.4711  accuracy: 31.39% -> 35.04%      
client [71] (testset)   loss: 5.4188 -> 5.5495  accuracy: 22.90% -> 23.66%      
client [97] (testset)   loss: 4.9087 -> 5.1235  accuracy: 30.48% -> 27.62%      
client [53] (testset)   loss: 4.3669 -> 4.5969  accuracy: 37.59% -> 36.17%      
client [77] (testset)   loss: 3.5381 -> 3.6346  accuracy: 47.19% -> 47.75%      
client [76] (testset)   loss: 4.6387 -> 4.7448  accuracy: 31.84% -> 32.96%      
client [79] (testset)   loss: 3.4793 -> 3.5681  accuracy: 51.96% -> 55.87%      
client [28] (testset)   loss: 3.9591 -> 4.0345  accuracy: 41.94% -> 41.94%      
client [99] (testset)   loss: 6.3732 -> 6.7317  accuracy: 22.63% -> 21.90%      
---------------------------- TRAINING EPOCH: 110 ----------------------------   
client [97] (testset)   loss: 5.2841 -> 5.4408  accuracy: 27.62% -> 27.62%      
client [86] (testset)   loss: 4.8534 -> 4.8299  accuracy: 37.29% -> 38.14%      
client [34] (testset)   loss: 5.4446 -> 5.5338  accuracy: 35.91% -> 35.91%      
client [73] (testset)   loss: 4.7677 -> 4.8232  accuracy: 32.37% -> 30.22%      
client [5]  (testset)   loss: 4.9784 -> 5.1053  accuracy: 39.26% -> 39.26%      
client [96] (testset)   loss: 5.7114 -> 5.7403  accuracy: 41.04% -> 40.46%      
client [22] (testset)   loss: 4.8823 -> 5.0554  accuracy: 28.95% -> 26.97%      
client [60] (testset)   loss: 5.3438 -> 5.3809  accuracy: 37.88% -> 37.88%      
client [66] (testset)   loss: 4.2067 -> 4.2781  accuracy: 38.83% -> 38.83%      
client [83] (testset)   loss: 5.2534 -> 4.4024  accuracy: 32.24% -> 40.13%      
---------------------------- TRAINING EPOCH: 120 ----------------------------   
client [76] (testset)   loss: 5.1223 -> 5.1717  accuracy: 31.84% -> 32.40%      
client [65] (testset)   loss: 4.4720 -> 4.5352  accuracy: 30.00% -> 30.91%      
client [95] (testset)   loss: 6.0692 -> 6.1432  accuracy: 35.54% -> 35.54%      
client [17] (testset)   loss: 4.7015 -> 4.9278  accuracy: 34.59% -> 35.34%      
client [8]  (testset)   loss: 5.8472 -> 5.8699  accuracy: 40.20% -> 40.20%      
client [35] (testset)   loss: 5.4584 -> 5.4803  accuracy: 34.69% -> 35.20%      
client [98] (testset)   loss: 5.5106 -> 5.5706  accuracy: 33.80% -> 33.10%      
client [53] (testset)   loss: 4.7883 -> 4.9129  accuracy: 36.17% -> 36.17%      
client [43] (testset)   loss: 5.7586 -> 5.8470  accuracy: 29.63% -> 29.63%      
client [64] (testset)   loss: 4.2875 -> 4.4031  accuracy: 39.86% -> 39.19%      
---------------------------- TRAINING EPOCH: 130 ----------------------------   
client [21] (testset)   loss: 3.1287 -> 3.2364  accuracy: 36.05% -> 39.46%      
client [88] (testset)   loss: 4.6559 -> 4.7599  accuracy: 39.11% -> 40.22%      
client [38] (testset)   loss: 4.4441 -> 4.5088  accuracy: 43.58% -> 43.58%      
client [3]  (testset)   loss: 3.9990 -> 4.0217  accuracy: 40.62% -> 39.84%      
client [5]  (testset)   loss: 5.1677 -> 5.3449  accuracy: 38.04% -> 38.04%      
client [41] (testset)   loss: 4.8966 -> 4.9594  accuracy: 29.03% -> 29.03%      
client [7]  (testset)   loss: 5.7537 -> 5.8281  accuracy: 34.21% -> 34.21%      
client [37] (testset)   loss: 5.2767 -> 5.4854  accuracy: 34.62% -> 36.54%      
client [45] (testset)   loss: 3.1579 -> 3.1494  accuracy: 42.92% -> 45.13%      
client [47] (testset)   loss: 4.3325 -> 4.4600  accuracy: 46.96% -> 42.61%      
---------------------------- TRAINING EPOCH: 140 ----------------------------   
client [16] (testset)   loss: 5.8086 -> 5.8345  accuracy: 33.88% -> 34.71%      
client [11] (testset)   loss: 4.0083 -> 4.0899  accuracy: 42.94% -> 42.94%      
client [37] (testset)   loss: 5.8269 -> 5.8508  accuracy: 37.50% -> 36.54%      
client [41] (testset)   loss: 5.0012 -> 5.0694  accuracy: 29.03% -> 29.03%      
client [95] (testset)   loss: 6.3704 -> 6.4197  accuracy: 35.54% -> 35.54%      
client [53] (testset)   loss: 5.0070 -> 5.0858  accuracy: 35.46% -> 38.30%      
client [22] (testset)   loss: 5.2787 -> 5.3442  accuracy: 28.29% -> 27.63%      
client [25] (testset)   loss: 4.3542 -> 4.5015  accuracy: 40.62% -> 39.58%      
client [69] (testset)   loss: 4.5865 -> 4.6086  accuracy: 51.26% -> 50.90%      
client [46] (testset)   loss: 3.9907 -> 4.0560  accuracy: 58.10% -> 59.05%      
---------------------------- TRAINING EPOCH: 150 ----------------------------   
client [47] (testset)   loss: 4.8400 -> 4.9025  accuracy: 42.61% -> 40.87%      
client [69] (testset)   loss: 4.6729 -> 4.6938  accuracy: 51.26% -> 51.26%      
client [82] (testset)   loss: 5.6640 -> 5.6852  accuracy: 32.56% -> 33.72%      
client [45] (testset)   loss: 3.5190 -> 3.6160  accuracy: 44.69% -> 44.69%      
client [7]  (testset)   loss: 5.9266 -> 5.9915  accuracy: 33.77% -> 34.21%      
client [50] (testset)   loss: 3.3989 -> 3.4661  accuracy: 46.00% -> 47.00%      
client [35] (testset)   loss: 5.7417 -> 5.7886  accuracy: 34.69% -> 35.20%      
client [24] (testset)   loss: 4.5688 -> 4.5591  accuracy: 37.07% -> 37.07%      
client [15] (testset)   loss: 5.0790 -> 5.2022  accuracy: 34.31% -> 35.04%      
client [58] (testset)   loss: 6.1589 -> 6.2004  accuracy: 33.85% -> 33.08%      
---------------------------- TRAINING EPOCH: 160 ----------------------------   
client [48] (testset)   loss: 5.7426 -> 5.7721  accuracy: 36.36% -> 36.36%      
client [76] (testset)   loss: 5.4333 -> 5.4787  accuracy: 31.84% -> 31.84%      
client [67] (testset)   loss: 4.4154 -> 4.5315  accuracy: 37.91% -> 38.46%      
client [37] (testset)   loss: 6.0445 -> 6.1241  accuracy: 35.58% -> 36.54%      
client [58] (testset)   loss: 6.2559 -> 6.2904  accuracy: 33.85% -> 33.08%      
client [64] (testset)   loss: 4.7797 -> 4.8654  accuracy: 37.84% -> 37.84%      
client [77] (testset)   loss: 4.2412 -> 4.2796  accuracy: 46.63% -> 48.31%      
client [55] (testset)   loss: 3.9646 -> 3.9826  accuracy: 46.38% -> 46.38%      
client [12] (testset)   loss: 4.4904 -> 4.5230  accuracy: 53.79% -> 53.79%      
client [89] (testset)   loss: 7.0625 -> 7.0967  accuracy: 30.57% -> 30.57%      
---------------------------- TRAINING EPOCH: 170 ----------------------------   
client [84] (testset)   loss: 6.7574 -> 6.7732  accuracy: 35.59% -> 35.59%      
client [51] (testset)   loss: 5.6086 -> 5.6328  accuracy: 38.51% -> 38.51%      
client [8]  (testset)   loss: 6.2163 -> 6.2303  accuracy: 40.20% -> 40.20%      
client [18] (testset)   loss: 3.7665 -> 3.8084  accuracy: 49.22% -> 49.22%      
client [94] (testset)   loss: 5.7639 -> 5.7968  accuracy: 36.92% -> 36.92%      
client [81] (testset)   loss: 5.0697 -> 5.0684  accuracy: 41.72% -> 40.40%      
client [3]  (testset)   loss: 4.2683 -> 4.2960  accuracy: 38.28% -> 39.06%      
client [11] (testset)   loss: 4.3083 -> 4.3530  accuracy: 43.50% -> 42.94%      
client [95] (testset)   loss: 6.7323 -> 6.7649  accuracy: 35.54% -> 35.54%      
client [67] (testset)   loss: 4.5521 -> 4.6643  accuracy: 38.46% -> 37.91%      
---------------------------- TRAINING EPOCH: 180 ----------------------------   
client [21] (testset)   loss: 3.4883 -> 3.5568  accuracy: 38.78% -> 39.46%      
client [79] (testset)   loss: 4.3163 -> 4.3502  accuracy: 54.19% -> 53.07%      
client [58] (testset)   loss: 6.4310 -> 6.4581  accuracy: 33.08% -> 33.08%      
client [88] (testset)   loss: 5.0296 -> 5.0976  accuracy: 39.11% -> 38.55%      
client [46] (testset)   loss: 4.2939 -> 4.3401  accuracy: 59.05% -> 59.05%      
client [11] (testset)   loss: 4.3720 -> 4.4130  accuracy: 42.94% -> 42.94%      
client [55] (testset)   loss: 4.0875 -> 4.0925  accuracy: 46.38% -> 46.38%      
client [13] (testset)   loss: 5.1896 -> 5.2078  accuracy: 36.26% -> 36.26%      
client [31] (testset)   loss: 5.3635 -> 5.3735  accuracy: 45.26% -> 45.26%      
client [75] (testset)   loss: 5.2540 -> 5.2965  accuracy: 39.62% -> 39.62%      
---------------------------- TRAINING EPOCH: 190 ----------------------------   
client [19] (testset)   loss: 5.7766 -> 5.8087  accuracy: 39.02% -> 39.02%      
client [7]  (testset)   loss: 6.3159 -> 6.3458  accuracy: 34.65% -> 34.65%      
client [57] (testset)   loss: 4.1788 -> 4.2348  accuracy: 47.85% -> 48.47%      
client [13] (testset)   loss: 5.2365 -> 5.3156  accuracy: 36.26% -> 36.84%      
client [43] (testset)   loss: 6.5091 -> 6.5546  accuracy: 28.89% -> 28.89%      
client [91] (testset)   loss: 5.2551 -> 5.3171  accuracy: 32.89% -> 30.92%      
client [10] (testset)   loss: 6.0808 -> 6.1192  accuracy: 39.42% -> 39.42%      
client [64] (testset)   loss: 5.1175 -> 5.1599  accuracy: 37.84% -> 37.84%      
client [82] (testset)   loss: 6.1778 -> 6.2063  accuracy: 32.56% -> 33.72%      
client [22] (testset)   loss: 5.7877 -> 5.8219  accuracy: 26.97% -> 27.63%      
---------------------------- TRAINING EPOCH: 200 ----------------------------   
client [20] (testset)   loss: 5.0804 -> 5.0950  accuracy: 47.03% -> 46.53%      
client [23] (testset)   loss: 4.5964 -> 4.6217  accuracy: 38.18% -> 39.09%      
client [88] (testset)   loss: 5.1407 -> 5.1414  accuracy: 38.55% -> 38.55%      
client [98] (testset)   loss: 6.1026 -> 6.1196  accuracy: 33.10% -> 33.80%      
client [79] (testset)   loss: 4.4275 -> 4.4555  accuracy: 53.07% -> 54.19%      
client [21] (testset)   loss: 3.6387 -> 3.6805  accuracy: 40.14% -> 38.78%      
client [92] (testset)   loss: 6.4626 -> 6.4789  accuracy: 35.71% -> 34.69%      
client [56] (testset)   loss: 4.7651 -> 4.7835  accuracy: 42.86% -> 42.86%      
client [5]  (testset)   loss: 5.8261 -> 5.9138  accuracy: 37.42% -> 38.65%      
client [52] (testset)   loss: 6.0699 -> 6.0903  accuracy: 38.06% -> 38.06%      
---------------------------- TRAINING EPOCH: 210 ----------------------------   
client [67] (testset)   loss: 5.0570 -> 5.0887  accuracy: 39.01% -> 39.56%      
client [54] (testset)   loss: 8.9665 -> 8.9895  accuracy: 32.50% -> 32.50%      
client [14] (testset)   loss: 6.9295 -> 6.9636  accuracy: 28.57% -> 28.57%      
client [99] (testset)   loss: 8.0734 -> 8.1412  accuracy: 22.63% -> 22.63%      
client [36] (testset)   loss: 4.4898 -> 4.5044  accuracy: 38.05% -> 38.05%      
client [30] (testset)   loss: 7.0247 -> 7.0595  accuracy: 23.20% -> 23.20%      
client [38] (testset)   loss: 4.9302 -> 4.9575  accuracy: 44.13% -> 44.13%      
client [15] (testset)   loss: 5.5483 -> 5.5957  accuracy: 33.58% -> 34.31%      
client [6]  (testset)   loss: 7.4515 -> 7.4656  accuracy: 25.37% -> 25.37%      
client [53] (testset)   loss: 5.7300 -> 5.7571  accuracy: 37.59% -> 37.59%      
---------------------------- TRAINING EPOCH: 220 ----------------------------   
client [99] (testset)   loss: 8.2443 -> 8.2947  accuracy: 22.63% -> 22.63%      
client [6]  (testset)   loss: 7.4945 -> 7.5217  accuracy: 25.37% -> 25.37%      
client [83] (testset)   loss: 5.5398 -> 5.5829  accuracy: 40.79% -> 40.13%      
client [42] (testset)   loss: 4.6282 -> 4.6449  accuracy: 45.21% -> 45.21%      
client [34] (testset)   loss: 6.3231 -> 6.3563  accuracy: 35.91% -> 35.36%      
client [15] (testset)   loss: 5.6139 -> 5.6567  accuracy: 34.31% -> 34.31%      
client [47] (testset)   loss: 5.3926 -> 5.4159  accuracy: 41.74% -> 41.74%      
client [55] (testset)   loss: 4.1659 -> 4.1786  accuracy: 46.38% -> 46.38%      
client [51] (testset)   loss: 5.7885 -> 5.8143  accuracy: 38.51% -> 38.51%      
client [95] (testset)   loss: 6.9906 -> 7.0073  accuracy: 35.54% -> 35.54%      
---------------------------- TRAINING EPOCH: 230 ----------------------------   
client [71] (testset)   loss: 6.6035 -> 6.6488  accuracy: 22.14% -> 22.14%      
client [15] (testset)   loss: 5.6736 -> 5.7170  accuracy: 34.31% -> 34.31%      
client [33] (testset)   loss: 7.1574 -> 7.1683  accuracy: 21.10% -> 21.10%      
client [99] (testset)   loss: 8.3487 -> 8.3888  accuracy: 22.63% -> 23.36%      
client [90] (testset)   loss: 5.5543 -> 5.5725  accuracy: 43.38% -> 42.65%      
client [57] (testset)   loss: 4.4956 -> 4.5266  accuracy: 47.85% -> 47.85%      
client [27] (testset)   loss: 6.2216 -> 6.2522  accuracy: 39.38% -> 37.50%      
client [78] (testset)   loss: 4.0911 -> 4.1162  accuracy: 44.65% -> 44.65%      
client [36] (testset)   loss: 4.5476 -> 4.5650  accuracy: 38.05% -> 38.05%      
client [88] (testset)   loss: 5.2663 -> 5.2921  accuracy: 38.55% -> 38.55%      
---------------------------- TRAINING EPOCH: 240 ----------------------------   
client [70] (testset)   loss: 5.9516 -> 5.9737  accuracy: 43.48% -> 43.48%      
client [35] (testset)   loss: 6.2337 -> 6.2611  accuracy: 34.69% -> 34.69%      
client [16] (testset)   loss: 6.4407 -> 6.4419  accuracy: 33.06% -> 33.06%      
client [80] (testset)   loss: 3.1657 -> 3.1747  accuracy: 63.35% -> 63.35%      
client [38] (testset)   loss: 5.0495 -> 5.0692  accuracy: 44.13% -> 44.13%      
client [78] (testset)   loss: 4.1349 -> 4.1571  accuracy: 44.65% -> 44.65%      
client [68] (testset)   loss: 5.9042 -> 5.9121  accuracy: 40.34% -> 39.92%      
client [11] (testset)   loss: 4.6321 -> 4.6677  accuracy: 42.94% -> 42.94%      
client [64] (testset)   loss: 5.3887 -> 5.4121  accuracy: 37.84% -> 37.84%      
client [82] (testset)   loss: 6.5510 -> 6.6072  accuracy: 32.56% -> 33.72%      
---------------------------- TRAINING EPOCH: 250 ----------------------------   
client [30] (testset)   loss: 7.2558 -> 7.2718  accuracy: 23.76% -> 23.20%      
client [27] (testset)   loss: 6.2889 -> 6.3188  accuracy: 37.50% -> 38.12%      
client [74] (testset)   loss: 6.0286 -> 6.0372  accuracy: 40.31% -> 40.31%      
client [45] (testset)   loss: 4.1758 -> 4.2063  accuracy: 43.81% -> 43.81%      
client [6]  (testset)   loss: 7.6133 -> 7.6181  accuracy: 25.37% -> 25.37%      
client [36] (testset)   loss: 4.6008 -> 4.6074  accuracy: 38.05% -> 38.05%      
client [63] (testset)   loss: 5.9928 -> 6.0337  accuracy: 33.65% -> 33.65%      
client [76] (testset)   loss: 5.8933 -> 5.9194  accuracy: 32.40% -> 32.40%      
client [83] (testset)   loss: 5.6859 -> 5.7217  accuracy: 40.13% -> 40.13%      
client [86] (testset)   loss: 6.0852 -> 6.1136  accuracy: 38.14% -> 38.14%      
---------------------------- TRAINING EPOCH: 260 ----------------------------   
client [83] (testset)   loss: 5.7354 -> 5.7463  accuracy: 40.13% -> 40.13%      
client [99] (testset)   loss: 8.4906 -> 8.5291  accuracy: 22.63% -> 22.63%      
client [74] (testset)   loss: 6.0674 -> 6.0900  accuracy: 40.82% -> 40.31%      
client [73] (testset)   loss: 5.4920 -> 5.5579  accuracy: 34.53% -> 33.81%      
client [29] (testset)   loss: 5.1803 -> 5.2319  accuracy: 36.00% -> 35.33%      
client [92] (testset)   loss: 6.7098 -> 6.7453  accuracy: 33.67% -> 35.71%      
client [6]  (testset)   loss: 7.6602 -> 7.6791  accuracy: 25.37% -> 25.37%      
client [61] (testset)   loss: 5.8476 -> 5.8893  accuracy: 31.85% -> 31.85%      
client [21] (testset)   loss: 3.8691 -> 3.8986  accuracy: 38.78% -> 38.78%      
client [67] (testset)   loss: 5.2607 -> 5.2742  accuracy: 39.01% -> 39.56%      
---------------------------- TRAINING EPOCH: 270 ----------------------------   
client [83] (testset)   loss: 5.7609 -> 5.7907  accuracy: 40.13% -> 40.13%      
client [32] (testset)   loss: 6.5993 -> 6.6237  accuracy: 37.89% -> 37.89%      
client [95] (testset)   loss: 7.1361 -> 7.1504  accuracy: 35.54% -> 35.54%      
client [61] (testset)   loss: 5.9912 -> 6.0185  accuracy: 31.85% -> 32.59%      
client [27] (testset)   loss: 6.3513 -> 6.3711  accuracy: 38.12% -> 38.12%      
client [25] (testset)   loss: 5.2129 -> 5.2610  accuracy: 39.58% -> 39.58%      
client [68] (testset)   loss: 5.9994 -> 6.0095  accuracy: 40.34% -> 39.92%      
client [34] (testset)   loss: 6.5100 -> 6.5324  accuracy: 35.36% -> 35.91%      
client [71] (testset)   loss: 6.8658 -> 6.8950  accuracy: 22.90% -> 22.90%      
client [89] (testset)   loss: 7.5996 -> 7.6201  accuracy: 29.94% -> 29.94%      
---------------------------- TRAINING EPOCH: 280 ----------------------------   
client [78] (testset)   loss: 4.3059 -> 4.3134  accuracy: 44.65% -> 44.65%      
client [81] (testset)   loss: 5.5527 -> 5.5557  accuracy: 40.40% -> 40.40%      
client [51] (testset)   loss: 5.9952 -> 6.0125  accuracy: 38.51% -> 38.51%      
client [54] (testset)   loss: 9.2593 -> 9.2729  accuracy: 32.50% -> 32.50%      
client [65] (testset)   loss: 5.3125 -> 5.3373  accuracy: 31.82% -> 31.82%      
client [41] (testset)   loss: 5.8581 -> 5.8765  accuracy: 27.42% -> 27.42%      
client [11] (testset)   loss: 4.7583 -> 4.7775  accuracy: 42.94% -> 42.94%      
client [85] (testset)   loss: 6.7434 -> 6.7482  accuracy: 43.28% -> 43.28%      
client [12] (testset)   loss: 5.0380 -> 5.0672  accuracy: 55.30% -> 55.30%      
client [23] (testset)   loss: 5.0052 -> 5.0331  accuracy: 40.00% -> 40.00%      
---------------------------- TRAINING EPOCH: 290 ----------------------------   
client [16] (testset)   loss: 6.5586 -> 6.5675  accuracy: 33.06% -> 33.06%      
client [65] (testset)   loss: 5.3639 -> 5.3807  accuracy: 31.82% -> 31.82%      
client [53] (testset)   loss: 6.0981 -> 6.1135  accuracy: 38.30% -> 38.30%      
client [58] (testset)   loss: 6.8362 -> 6.8510  accuracy: 33.85% -> 33.85%      
client [72] (testset)   loss: 6.4381 -> 6.4517  accuracy: 29.10% -> 29.10%      
client [7]  (testset)   loss: 6.7114 -> 6.7264  accuracy: 34.65% -> 34.65%      
client [71] (testset)   loss: 6.9251 -> 6.9547  accuracy: 22.90% -> 22.90%      
client [59] (testset)   loss: 5.9789 -> 6.0044  accuracy: 40.77% -> 40.77%      
client [86] (testset)   loss: 6.2731 -> 6.3342  accuracy: 38.98% -> 38.98%      
client [39] (testset)   loss: 5.3766 -> 5.3914  accuracy: 40.12% -> 39.52%      
---------------------------- TRAINING EPOCH: 300 ----------------------------   
client [99] (testset)   loss: 8.6582 -> 8.6873  accuracy: 22.63% -> 22.63%      
client [7]  (testset)   loss: 6.7527 -> 6.7713  accuracy: 35.09% -> 34.65%      
client [17] (testset)   loss: 7.0833 -> 7.1196  accuracy: 33.83% -> 33.83%      
client [64] (testset)   loss: 5.6415 -> 5.6644  accuracy: 37.84% -> 37.84%      
client [37] (testset)   loss: 6.9491 -> 6.9831  accuracy: 35.58% -> 34.62%      
client [29] (testset)   loss: 5.3898 -> 5.4082  accuracy: 36.00% -> 36.00%      
client [93] (testset)   loss: 6.5492 -> 6.5885  accuracy: 37.60% -> 37.60%      
client [73] (testset)   loss: 5.7668 -> 5.7964  accuracy: 34.53% -> 33.09%      
client [40] (testset)   loss: 6.5446 -> 6.5444  accuracy: 26.92% -> 28.21%      
client [76] (testset)   loss: 6.0439 -> 6.0584  accuracy: 31.84% -> 32.40%      
---------------------------- TRAINING EPOCH: 310 ----------------------------   
client [31] (testset)   loss: 5.7217 -> 5.7302  accuracy: 45.26% -> 45.26%      
client [89] (testset)   loss: 7.7441 -> 7.7642  accuracy: 29.94% -> 29.94%      
client [77] (testset)   loss: 5.0156 -> 5.0351  accuracy: 45.51% -> 47.19%      
client [90] (testset)   loss: 5.9397 -> 5.9613  accuracy: 42.65% -> 42.65%      
client [26] (testset)   loss: 4.8496 -> 4.8715  accuracy: 42.48% -> 41.59%      
client [50] (testset)   loss: 4.1918 -> 4.2204  accuracy: 48.00% -> 47.00%      
client [30] (testset)   loss: 7.4782 -> 7.4820  accuracy: 22.10% -> 22.65%      
client [70] (testset)   loss: 6.1380 -> 6.1453  accuracy: 44.10% -> 44.10%      
client [41] (testset)   loss: 5.9633 -> 5.9834  accuracy: 27.42% -> 27.42%      
client [99] (testset)   loss: 8.7032 -> 8.7407  accuracy: 22.63% -> 22.63%      
---------------------------- TRAINING EPOCH: 320 ----------------------------   
client [68] (testset)   loss: 6.1892 -> 6.2036  accuracy: 40.34% -> 40.34%      
client [70] (testset)   loss: 6.1701 -> 6.1861  accuracy: 43.48% -> 43.48%      
client [52] (testset)   loss: 6.4491 -> 6.4577  accuracy: 37.31% -> 37.31%      
client [1]  (testset)   loss: 6.1567 -> 6.1799  accuracy: 36.46% -> 36.46%      
client [2]  (testset)   loss: 6.6731 -> 6.7109  accuracy: 29.46% -> 29.46%      
client [67] (testset)   loss: 5.4786 -> 5.5006  accuracy: 39.01% -> 39.56%      
client [92] (testset)   loss: 7.0081 -> 7.0197  accuracy: 34.69% -> 34.69%      
client [35] (testset)   loss: 6.4730 -> 6.5053  accuracy: 34.69% -> 34.69%      
client [36] (testset)   loss: 4.7771 -> 4.7800  accuracy: 38.05% -> 37.17%      
client [64] (testset)   loss: 5.6955 -> 5.7117  accuracy: 37.84% -> 37.84%      
---------------------------- TRAINING EPOCH: 330 ----------------------------   
client [44] (testset)   loss: 6.3343 -> 6.3541  accuracy: 26.14% -> 26.14%      
client [6]  (testset)   loss: 7.8841 -> 7.8947  accuracy: 25.37% -> 25.37%      
client [12] (testset)   loss: 5.1869 -> 5.2040  accuracy: 54.55% -> 53.79%      
client [55] (testset)   loss: 4.3404 -> 4.3486  accuracy: 46.38% -> 46.38%      
client [29] (testset)   loss: 5.5095 -> 5.5525  accuracy: 36.00% -> 34.67%      
client [9]  (testset)   loss: 6.0323 -> 6.0466  accuracy: 39.60% -> 39.60%      
client [43] (testset)   loss: 7.1731 -> 7.1917  accuracy: 28.15% -> 28.15%      
client [77] (testset)   loss: 5.0538 -> 5.0705  accuracy: 47.19% -> 45.51%      
client [98] (testset)   loss: 6.5783 -> 6.5954  accuracy: 34.51% -> 34.51%      
client [78] (testset)   loss: 4.3908 -> 4.4045  accuracy: 44.65% -> 44.65%      
---------------------------- TRAINING EPOCH: 340 ----------------------------   
client [92] (testset)   loss: 7.0691 -> 7.0879  accuracy: 34.69% -> 34.69%      
client [80] (testset)   loss: 3.3420 -> 3.3380  accuracy: 63.35% -> 63.35%      
client [63] (testset)   loss: 6.3232 -> 6.3516  accuracy: 33.65% -> 33.65%      
client [76] (testset)   loss: 6.1319 -> 6.1485  accuracy: 32.40% -> 32.40%      
client [78] (testset)   loss: 4.4111 -> 4.4331  accuracy: 44.65% -> 44.65%      
client [25] (testset)   loss: 5.4412 -> 5.4645  accuracy: 39.58% -> 39.58%      
client [58] (testset)   loss: 6.9558 -> 6.9727  accuracy: 33.08% -> 33.08%      
client [13] (testset)   loss: 5.7408 -> 5.7137  accuracy: 35.67% -> 36.26%      
client [17] (testset)   loss: 7.2856 -> 7.3161  accuracy: 33.83% -> 33.83%      
client [38] (testset)   loss: 5.4449 -> 5.4550  accuracy: 44.69% -> 44.13%      
---------------------------- TRAINING EPOCH: 350 ----------------------------   
client [72] (testset)   loss: 6.6162 -> 6.6265  accuracy: 28.36% -> 28.36%      
client [82] (testset)   loss: 7.0171 -> 7.0228  accuracy: 32.56% -> 32.56%      
client [86] (testset)   loss: 6.4995 -> 6.5337  accuracy: 38.98% -> 38.98%      
client [51] (testset)   loss: 6.1546 -> 6.1689  accuracy: 38.51% -> 38.51%      
client [96] (testset)   loss: 6.8322 -> 6.8456  accuracy: 39.88% -> 40.46%      
client [42] (testset)   loss: 4.9196 -> 4.9295  accuracy: 45.21% -> 45.21%      
client [55] (testset)   loss: 4.3880 -> 4.3959  accuracy: 46.38% -> 46.38%      
client [13] (testset)   loss: 5.7635 -> 5.7536  accuracy: 35.67% -> 36.26%      
client [1]  (testset)   loss: 6.2682 -> 6.2960  accuracy: 36.46% -> 36.46%      
client [12] (testset)   loss: 5.2221 -> 5.2385  accuracy: 53.79% -> 53.79%      
---------------------------- TRAINING EPOCH: 360 ----------------------------   
client [68] (testset)   loss: 6.2754 -> 6.2858  accuracy: 39.92% -> 39.92%      
client [23] (testset)   loss: 5.2363 -> 5.2679  accuracy: 39.09% -> 39.09%      
client [46] (testset)   loss: 5.0137 -> 5.0308  accuracy: 57.14% -> 57.14%      
client [41] (testset)   loss: 6.0943 -> 6.1049  accuracy: 27.42% -> 26.61%      
client [25] (testset)   loss: 5.5778 -> 5.5990  accuracy: 39.58% -> 39.58%      
client [58] (testset)   loss: 7.0039 -> 7.0216  accuracy: 33.85% -> 33.85%      
client [14] (testset)   loss: 7.5048 -> 7.5268  accuracy: 28.57% -> 28.57%      
client [33] (testset)   loss: 7.4559 -> 7.4640  accuracy: 21.10% -> 21.10%      
client [85] (testset)   loss: 6.9243 -> 6.9316  accuracy: 43.28% -> 43.28%      
client [62] (testset)   loss: 6.1289 -> 6.1363  accuracy: 40.78% -> 40.78%      
---------------------------- TRAINING EPOCH: 370 ----------------------------   
client [98] (testset)   loss: 6.6930 -> 6.7023  accuracy: 34.51% -> 34.51%      
client [63] (testset)   loss: 6.4242 -> 6.4464  accuracy: 33.65% -> 33.65%      
client [70] (testset)   loss: 6.2846 -> 6.2958  accuracy: 44.10% -> 44.10%      
client [65] (testset)   loss: 5.5220 -> 5.5539  accuracy: 31.82% -> 31.82%      
client [14] (testset)   loss: 7.5628 -> 7.5825  accuracy: 28.57% -> 27.27%      
client [73] (testset)   loss: 6.0000 -> 6.0123  accuracy: 33.09% -> 33.09%      
client [34] (testset)   loss: 6.8457 -> 6.8620  accuracy: 35.91% -> 35.91%      
client [99] (testset)   loss: 8.9024 -> 8.9228  accuracy: 22.63% -> 22.63%      
client [69] (testset)   loss: 5.2731 -> 5.2809  accuracy: 50.18% -> 50.18%      
client [46] (testset)   loss: 5.0383 -> 5.0518  accuracy: 57.14% -> 57.14%      
---------------------------- TRAINING EPOCH: 380 ----------------------------   
client [99] (testset)   loss: 8.9506 -> 8.9780  accuracy: 22.63% -> 22.63%      
client [93] (testset)   loss: 6.7625 -> 6.7838  accuracy: 37.60% -> 37.60%      
client [11] (testset)   loss: 4.9946 -> 5.0121  accuracy: 42.94% -> 42.94%      
client [58] (testset)   loss: 7.0550 -> 7.0683  accuracy: 33.08% -> 33.08%      
client [81] (testset)   loss: 5.8276 -> 5.8458  accuracy: 40.40% -> 40.40%      
client [85] (testset)   loss: 6.9549 -> 6.9644  accuracy: 43.28% -> 43.28%      
client [89] (testset)   loss: 7.9550 -> 7.9718  accuracy: 29.94% -> 29.94%      
client [45] (testset)   loss: 4.4796 -> 4.5085  accuracy: 44.25% -> 43.81%      
client [8]  (testset)   loss: 6.7733 -> 6.7817  accuracy: 40.70% -> 40.70%      
client [68] (testset)   loss: 6.3462 -> 6.3569  accuracy: 39.92% -> 39.92%      
---------------------------- TRAINING EPOCH: 390 ----------------------------   
client [67] (testset)   loss: 5.6199 -> 5.6304  accuracy: 39.56% -> 39.01%      
client [72] (testset)   loss: 6.7082 -> 6.7214  accuracy: 28.36% -> 28.36%      
client [1]  (testset)   loss: 6.3866 -> 6.4115  accuracy: 35.91% -> 35.91%      
client [78] (testset)   loss: 4.5210 -> 4.5250  accuracy: 44.65% -> 44.65%      
client [83] (testset)   loss: 6.1722 -> 6.1940  accuracy: 40.13% -> 40.13%      
client [21] (testset)   loss: 4.2467 -> 4.2638  accuracy: 38.10% -> 38.78%      
client [56] (testset)   loss: 5.2382 -> 5.2472  accuracy: 42.86% -> 42.86%      
client [44] (testset)   loss: 6.5517 -> 6.5630  accuracy: 26.14% -> 26.80%      
client [92] (testset)   loss: 7.1667 -> 7.1796  accuracy: 34.69% -> 34.69%      
client [27] (testset)   loss: 6.6950 -> 6.7207  accuracy: 37.50% -> 36.88%      
---------------------------- TRAINING EPOCH: 400 ----------------------------   
client [10] (testset)   loss: 7.0105 -> 7.0225  accuracy: 39.42% -> 39.42%      
client [39] (testset)   loss: 5.5500 -> 5.5594  accuracy: 40.72% -> 40.12%      
client [65] (testset)   loss: 5.6046 -> 5.6255  accuracy: 31.82% -> 31.82%      
client [26] (testset)   loss: 5.1149 -> 5.1311  accuracy: 41.59% -> 43.36%      
client [19] (testset)   loss: 6.4560 -> 6.4688  accuracy: 39.63% -> 39.02%      
client [68] (testset)   loss: 6.3798 -> 6.3962  accuracy: 39.92% -> 39.92%      
client [41] (testset)   loss: 6.1889 -> 6.2014  accuracy: 26.61% -> 27.42%      
client [50] (testset)   loss: 4.4780 -> 4.4792  accuracy: 47.00% -> 47.00%      
client [75] (testset)   loss: 5.9496 -> 5.9659  accuracy: 40.09% -> 40.09%      
client [81] (testset)   loss: 5.8792 -> 5.8851  accuracy: 40.40% -> 40.40%      
LG-FedAvg's average time taken by each global epoch: 0 min 1.12 sec.            
LG-FedAvg's total running time: 0 h 7 m 33 s.                                   
==================== LG-FedAvg Experiment Results: ====================         
Display format: (before local fine-tuning) -> (after local fine-tuning)         
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                            
 Centralized testing ONLY happens after model aggregation, so the stats between 
'->' are the same.                                                              
{                                                                               
    "100": {                                                                    
        "all_clients": {                                                        
            "test": {                                                           
                "loss": "4.6474 -> 0.0000",                                     
                "accuracy": "38.43% -> 0.00%"                                   
            }                                                                   
        }                                                                       
    },                                                                          
    "200": {                                                                    
        "all_clients": {                                                        
            "test": {                                                           
                "loss": "5.5345 -> 0.0000",                                     
                "accuracy": "38.64% -> 0.00%"                                   
            }                                                                   
        }                                                                       
    },                                                                          
    "300": {                                                                    
        "all_clients": {                                                        
            "test": {                                                           
                "loss": "5.9195 -> 0.0000",                                     
                "accuracy": "38.58% -> 0.00%"                                   
            }                                                                   
        }                                                                       
    },                                                                          
    "400": {                                                                    
        "all_clients": {                                                        
            "test": {                                                           
                "loss": "6.1636 -> 0.0000",                                     
                "accuracy": "38.56% -> 0.00%"                                   
            }                                                                   
        }                                                                       
    }                                                                           
}                                                                               
==================== LG-FedAvg Max Accuracy ====================                
all_clients:                                                                    
(test) before fine-tuning: 38.64% at epoch 200                                  
(test) after fine-tuning: 0.00% at epoch 100                                    
